# INTRODUZIONE: STORIA DI CLOUDERA E EVOLUZIONE VERSO CDP

## Pre-Cloudera: Il contesto tecnologico (2003-2008)

### Tecnologie pre-big data

Prima dell'avvento di Hadoop e Cloudera, il panorama del data management era dominato da soluzioni tradizionali.

**Data Warehouse tradizionali (anni '90-2000):**
- **Oracle Database** - leader enterprise RDBMS
- **IBM DB2** - mainframe e enterprise
- **Teradata** - appliance per analytics
- **Microsoft SQL Server** - piattaforma Windows

**Limitazioni critiche:**
- âŒ **ScalabilitÃ  verticale** - solo scale-up, hardware costoso
- âŒ **Gestione dati non strutturati** - difficile gestire log, testo come documenti articoli e commenti sui social media
- âŒ **Costi proibitivi** - milioni di dollari per petabyte
- âŒ **Schema rigido** - schema-on-write, no flessibilitÃ 
- âŒ **Vendor lock-in** - dipendenza da fornitori proprietari

## Differenza tra dati relazionali e non relazionali

### **Dati Relazionali**
I dati relazionali sono organizzati in un formato strutturato, seguendo uno schema rigido.

#### **Caratteristiche principali:**
1. **Struttura**:
   - Organizzati in tabelle con righe e colonne.
   - Ogni tabella ha uno schema predefinito (schema-on-write).
   - Le relazioni tra i dati sono definite tramite chiavi primarie e chiavi esterne.

2. **Esempi di dati**:
   - Informazioni su clienti (nome, cognome, email, telefono).
   - Transazioni finanziarie (ID transazione, importo, data).
   - Inventari di prodotti (ID prodotto, quantitÃ , prezzo).

3. **Database relazionali (RDBMS)**:
   - MySQL, PostgreSQL, Oracle Database, Microsoft SQL Server.

4. **Vantaggi**:
   - **IntegritÃ  dei dati**: Garantita da vincoli (es. chiavi primarie, univocitÃ ).
   - **Query potenti**: Linguaggio SQL per interrogare i dati.
   - **Adatto a dati strutturati**: Ideale per applicazioni aziendali tradizionali.

5. **Svantaggi**:
   - **ScalabilitÃ  verticale**: Difficile scalare orizzontalmente (richiede hardware piÃ¹ potente).
   - **Schema rigido**: Cambiare lo schema puÃ² essere complesso.
   - **Non adatto a dati non strutturati**: Come immagini, video, log.

---

### **Dati Non Relazionali**
I dati non relazionali sono piÃ¹ flessibili e non seguono uno schema rigido.

#### **Caratteristiche principali:**
1. **Struttura**:
   - Non organizzati in tabelle (IMP).
   - Possono essere archiviati in formati come documenti, grafi, colonne o chiavi-valori.
   - Schema dinamico o assente (schema-on-read).

2. **Esempi di dati**:
   - Log di sistema (timestamp, messaggio di errore).
   - Post sui social media (testo, immagini, video).
   - Dati IoT (sensori, eventi in tempo reale).

3. **Database non relazionali (NoSQL)**:
   - MongoDB (documenti), Cassandra (colonne), Redis (chiavi-valori), Neo4j (grafi).

4. **Vantaggi**:
   - **ScalabilitÃ  orizzontale**: Aggiungere nodi per gestire piÃ¹ dati.
   - **FlessibilitÃ **: Adatto a dati non strutturati o semi-strutturati.
   - **Performance**: Ottimizzato per specifici casi d'uso (es. letture/scritture rapide).

5. **Svantaggi**:
   - **Meno consistenza**: Non sempre garantisce transazioni ACID.
   - **Query limitate**: Non sempre supporta SQL.
   - **Meno adatto a dati strutturati**: Non ideale per applicazioni tradizionali.

---

HDFS (Hadoop Distributed File System) non Ã¨ un database relazionale. Ãˆ un file system distribuito progettato per archiviare grandi quantitÃ  di dati su cluster di computer. HDFS gestisce file e directory, non tabelle relazionali, e non impone uno schema rigido ai dati. Quindi, HDFS Ã¨ considerato un sistema di archiviazione non relazionale.
Hive e Impala non sono database relazionali in senso stretto, ma sono motori di query che permettono di eseguire interrogazioni SQL su dati archiviati in HDFS (o altri file system distribuiti). Tuttavia, forniscono unâ€™interfaccia relazionale: i dati sono organizzati in tabelle e si usa SQL per interrogarli, quindi si comportano come sistemi relazionali dal punto di vista dellâ€™utente, pur non essendo veri e propri RDBMS tradizionali.

La differenza principale tra database e filesystem Ã¨ la seguente:

Un filesystem gestisce lâ€™archiviazione e lâ€™organizzazione di file e cartelle su un disco. Permette di salvare, leggere, modificare e cancellare file, ma non offre funzionalitÃ  avanzate per la gestione strutturata dei dati.
Un database, invece, Ã¨ progettato per archiviare, organizzare e gestire dati strutturati (ad esempio, in tabelle) e offre funzionalitÃ  come query, transazioni, integritÃ  dei dati e sicurezza. Permette di cercare e manipolare i dati in modo efficiente tramite linguaggi come SQL.
In sintesi: il filesystem gestisce file, il database gestisce dati strutturati.


### **Confronto Tabellare**

| **Caratteristica**       | **Relazionale**                     | **Non Relazionale**               |
|---------------------------|-------------------------------------|----------------------------------|
| **Struttura**             | Tabelle (righe e colonne)          | Documenti, grafi, colonne, chiavi-valori |
| **Schema**                | Rigido (schema-on-write)*           | Flessibile (schema-on-read)       |
| **ScalabilitÃ **           | Verticale                          | Orizzontale                       |
| **Adatto per**            | Dati strutturati                   | Dati non strutturati/semi-strutturati |
| **Esempi di database**    | MySQL, PostgreSQL, Oracle          | MongoDB, Cassandra, Neo4j         |
| **Query**                 | SQL                                | API specifiche o linguaggi NoSQL  |

* "Schema rigido on write" significa che, quando si scrivono dati in un database, questi devono rispettare una struttura (schema) predefinita e obbligatoria. Ogni record deve avere i campi, i tipi di dati e le regole stabilite dallo schema, altrimenti la scrittura viene rifiutata

In pratica:
- Prima di inserire dati, lo schema (ad esempio tabelle e colonne in SQL) deve essere giÃ  definito.
- Non puoi aggiungere dati con campi diversi o mancanti rispetto allo schema.
- Questo garantisce coerenza e integritÃ  dei dati, ma riduce la flessibilitÃ  rispetto a sistemi con schema dinamico (come MongoDB).

---

In sintesi, i dati relazionali sono ideali per applicazioni aziendali tradizionali con dati strutturati, mentre i dati non relazionali sono piÃ¹ adatti per scenari moderni che richiedono flessibilitÃ  e scalabilitÃ .

---

### **Concetto fondamentale: Database vs Schema**

#### **Spesso confusi, ma sono diversi:**

**Database (DB):**
- Ãˆ l'**intero contenitore** di dati e metadati
- Ãˆ il **livello piÃ¹ alto di organizzazione**
- Raggruppa piÃ¹ tabelle correlate (namespace Hive)
- Esempio: `hive_warehouse`, `analytics_db`

**Schema:**
- Ãˆ la **struttura** di una singola tabella
- Definisce colonne, tipi di dati, vincoli
- Ãˆ l'**intestazione** di una tabella
- Esempio: `(id INT, name STRING, salary DECIMAL)`

#### **Analogia visiva:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Database: hive_warehouse               â”‚  â† Intero cassetto
â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Table: employees                  â”‚ â”‚
â”‚  â”‚ Schema: id INT, name STRING,      â”‚ â”‚  â† Struttura colonne
â”‚  â”‚         salary DECIMAL            â”‚ â”‚
â”‚  â”‚                                   â”‚ â”‚
â”‚  â”‚ Data (rows):                      â”‚ â”‚  â† Dati effettivi
â”‚  â”‚ 1, John, 50000                    â”‚ â”‚
â”‚  â”‚ 2, Jane, 60000                    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Table: departments                â”‚ â”‚
â”‚  â”‚ Schema: dept_id INT,              â”‚ â”‚
â”‚  â”‚         dept_name STRING          â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### **In SQL/Hive:**

```sql
-- Creare un DATABASE (contenitore)
CREATE DATABASE hive_warehouse;

-- Creare una TABELLA con SCHEMA definito (struttura)
CREATE TABLE hive_warehouse.employees (
    id INT,                    -- â†“ Questo Ã¨ lo SCHEMA
    name STRING,               -- Definisce la struttura
    salary DECIMAL             -- della tabella
);

-- Inserire DATA (dati effettivi)
INSERT INTO employees VALUES (1, 'John', 50000);
```

#### **Differenze chiave:**

| **Aspetto**        | **Database**                      | **Schema**                          |
|-------------------|-----------------------------------|-------------------------------------|
| **Cos'Ã¨?**        | Contenitore/namespace            | Struttura di una singola tabella    |
| **Livello**       | Alto (raggruppa tabelle)         | Basso (singola tabella)             |
| **Comando SQL**   | `CREATE DATABASE mydb;`          | `CREATE TABLE mydb.mytable (...)`  |
| **Contiene**      | Molteplici tabelle               | Definizione colonne + tipi + vincoli |
| **Esempio**       | `analytics_db`, `sales_db`       | `(id INT, name STRING, date DATE)` |
| **Modifica**      | Raro (cambio struttura db)       | PiÃ¹ frequente (ALTER TABLE)        |

#### **Nel contesto Cloudera/Hive:**

- **Hive Database** = Namespace che raggruppa tabelle correlate
  ```sql
  CREATE DATABASE sales;  -- database per dati vendite
  CREATE TABLE sales.transactions (...);
  CREATE TABLE sales.customers (...);
  ```

- **Hive Schema** = Definizione della tabella (colonne + tipi)
  ```sql
  CREATE TABLE sales.transactions (
      transaction_id INT,
      customer_id INT,
      amount DECIMAL(10,2),
      transaction_date DATE
  );
  -- â†‘ Questa Ã¨ la struttura (schema) della tabella
  ```

#### **Per l'esame CDP:**

âš ï¸ Assicurati di capire:
- **Database**: namespace logico che organizza tabelle correlate
- **Schema**: la struttura fisica di una tabella (colonne + tipi)
- **Metastore Hive**: dove vengono archiviati i metadati (info su database e schema)
- **Atlas**: catalogo che documenta database, schema, lineage, ownership

---

### Google: La rivoluzione (2003-2004)

#### **Timeline chiara: Da Google a Hadoop**

**2003â€“2004: Google pubblica i paper rivoluzionari**

**Google File System (GFS) - 2003**
Google pubblicÃ² un paper rivoluzionario sul **Google File System**.

**âš ï¸ Importante:** Nel 2003 **Hadoop non esisteva ancora**. Non si "parlava di Hadoop" mentre Google creava GFS.

**Problemi che GFS risolveva:**
- Storage distribuito su migliaia di server commodity
- Fault tolerance automatica
- Alta throughput per grandi file
- Gestione petabyte di dati web

**Paper:** "The Google File System" - Ghemawat, Gobioff, Leung (SOSP 2003)


**MapReduce (Google, 2004)**
- Google pubblica il paper "MapReduce: Simplified Data Processing on Large Clusters" (Dean, Ghemawat).
- Concetti chiave:
   - Map: elaborazione parallela dei dati
   - Reduce: aggregazione dei risultati
   - ScalabilitÃ  lineare: piÃ¹ nodi = piÃ¹ performance
   - Fault tolerance: retry automatico dei task falliti
- Google non rilascia codice open source, solo paper.

**2005â€“2006: Nasce Hadoop**
- Doug Cutting (su Apache Nutch) crea lâ€™implementazione open source ispirata ai paper di Google:
   - HDFS (da GFS)
   - MapReduce (da Google MapReduce)
- Nel 2003 non esisteva Hadoop, ma si discutevano giÃ  i problemi di Big Data e scalabilitÃ .
- GFS (Google File System) viene prima (2003), Hadoop nasce dopo (2006) come reimplementazione open source.

**Apache Hadoop: La nascita 2006**
- Doug Cutting e Mike Cafarella (ex Yahoo!) implementano Hadoop per creare un motore di ricerca web scalabile.
- Nome "Hadoop": elefante di peluche del figlio di Doug Cutting.
- Componenti iniziali: HDFS e MapReduce.
- 2006: Hadoop come sottoprogetto di Apache Nutch.
- 2008: Hadoop diventa progetto Apache top-level.

Def. attuale di Hadoop:  Ã¨ un framework open source per lâ€™archiviazione e lâ€™elaborazione distribuita di grandi quantitÃ  di dati (Big Data) su cluster di computer. Ãˆ composto principalmente da:

HDFS (Hadoop Distributed File System): file system distribuito che memorizza i dati su piÃ¹ nodi.
MapReduce: modello di programmazione per elaborare dati in parallelo.
Altri componenti: YARN (gestione delle risorse), Hive, Pig, ecc.
---

### Yahoo!: Il primo grande utilizzatore (2006-2008)

**Yahoo! assunse Doug Cutting nel 2006** per sviluppare Hadoop internamente.

**Motivi:**
- Indicizzare miliardi di pagine web
- Competere con Google nella ricerca web
- Ridurre costi infrastrutturali

**Investimenti Yahoo! in Hadoop:**
- Team dedicato di sviluppo
- Cluster da migliaia di nodi
- Contributi open source massicci
- Test in produzione su scala web

**Risultato:** Yahoo! dimostrÃ² che Hadoop poteva scalare a livelli enterprise.

---

### Facebook: Big data sociale (2007-2008)

**Facebook** iniziÃ² ad usare Hadoop per analytics sui dati utenti.

**Contributi di Facebook:**
- **Apache Hive** (2008) - SQL su Hadoop
- Processing di log massivi
- Analytics comportamentali utenti
- Data warehouse distribuito

**Jeff Hammerbacher** (co-fondatore di Cloudera) era il data team lead di Facebook.

---

### Il problema che Hadoop risolse

**Prima di Hadoop (2003-2006):**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Aziende con big data (Google, Yahoo!)   â”‚
â”‚                                         â”‚
â”‚ Opzioni:                                â”‚
â”‚ 1. Build custom distributed systems     â”‚
â”‚    â†’ Costi: milioni $, anni sviluppo    â”‚
â”‚                                         â”‚
â”‚ 2. Buy expensive appliance              â”‚
â”‚    â†’ Costi: $$$, no flessibilitÃ         â”‚
â”‚                                         â”‚
â”‚ 3. Non fare analytics                   â”‚
â”‚    â†’ Perdere insights business          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Dopo Hadoop (2006-2008):**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Hadoop open source                      â”‚
â”‚                                         â”‚
â”‚ âœ… Commodity hardware (economico)       â”‚
â”‚ âœ… ScalabilitÃ  orizzontale infinita     â”‚
â”‚ âœ… Fault tolerance nativa               â”‚
â”‚ âœ… Open source (no vendor lock-in)      â”‚
â”‚ âœ… Dati non strutturati (log, testo)    â”‚
â”‚ âœ… Schema-on-read (flessibilitÃ )        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### La sfida: Hadoop era difficile (2006-2008)

**Problemi di Hadoop "raw":**
- âŒ No gestione centralizzata (manuale)
- âŒ Installazione complessa
- âŒ Security minima (no autenticazione/autorizzazione)
- âŒ No monitoring/alerting
- âŒ No supporto enterprise
- âŒ Solo per esperti Linux/Java
- âŒ No governance/auditing

**OpportunitÃ  per Cloudera:**
Rendere Hadoop **enterprise-ready** con:
- Manager centralizzato
- Distribuzione pacchettizzata
- Security integrata
- monitoring/alerting
- Supporto professionale
- Governance e compliance

---

## 0.0 Come Ã¨ nata Cloudera

### 0.0.1 Le origini (2008)

**Cloudera** Ã¨ stata fondata nel 2008 da:
- Doug Cutting (creatore di Hadoop)
- Christophe Bisciglia (ex-Google)
- Amr Awadallah (ex-Yahoo!)
- Jeff Hammerbacher (ex-Facebook)

**Missione originale:** commercializzare Apache Hadoop e renderlo enterprise-ready.

---

## 0.1 Prima di CDP: CDH e HDP

### 0.1.1 Cloudera Distribution for Hadoop (CDH)

**CDH** (2009-2020) era la distribuzione Hadoop di Cloudera.

**Caratteristiche:**
- Componenti: Hadoop, HDFS, MapReduce, YARN, Hive, Impala, HBase, Spark
- Versioni: CDH 4, CDH 5, CDH 6
- Manager: Cloudera Manager (GUI per gestione cluster)
- Security: Cloudera Navigator (audit/lineage), Sentry (authorization)
- Deployment: on-premise (bare metal)

**Limitazioni:**
- Solo on-premise
- Architettura monolitica
- Scaling verticale/orizzontale limitato
- Sicurezza frammentata (tool separati)

---

### 0.1.2 Hortonworks Data Platform (HDP)

**Hortonworks** (fondata 2011) era il competitor principale di Cloudera.

**HDP** caratteristiche:
- 100% open source (no codice proprietario)
- Componenti: Hadoop, YARN, Hive, HBase, Kafka, Storm, Ranger, Atlas
- Manager: Ambari (GUI cluster management)
- Security: Ranger (authorization), Knox (gateway), Atlas (metadata)
- Philosophy: "enterprise Hadoop without vendor lock-in"

**Differenze CDH vs HDP:**

| Aspetto | CDH (Cloudera) | --------------------------| HDP (Hortonworks) |
|---------|----------------|-------------------------- |-------------------|
| Filosofia | Enterprise + alcune feature proprietarie | 100% open source |
| SQL Engine | Impala (proprietario, veloce)           | Hive + Tez |
| Manager | Cloudera Manager                           | Ambari |
| Security | Sentry + Navigator                        | Ranger + Knox + Atlas |
| Target | Enterprise con budget                       | Open source enthusiast |
| Support | Subscription commerciale                   | Subscription + community |

---

## 0.2 La fusione Cloudera (CDH) + Hortonworks (HDP) (2019)

### 0.2.1 Merger announcement (Ottobre 2018)

**Motivo della fusione:**
- Competizione cloud (AWS, Azure, GCP stavano dominando)
- NecessitÃ  di unire forze contro cloud provider
- Combinare best-of-breed di entrambe le piattaforme

**Nuovo nome:** Cloudera (mantiene il brand)

**Valore:** ~$5.2 miliardi USD

---

### 0.2.2 Cosa Ã¨ cambiato dopo la fusione

âœ… **Combinazione tecnologie:**
- Impala (da CDH) + Ranger/Atlas (da HDP)
- Cloudera Manager + features di Ambari
- Best security/governance di entrambe

âœ… **Nuova vision:**
- Hybrid/multi-cloud (non solo on-premise)
- Enterprise Data Cloud
- Data lifecycle completo (ingest â†’ process â†’ serve â†’ protect)

---

## 0.3 Nascita di CDP (Cloudera Data Platform)

### 0.3.1 Lancio CDP (2019-2020)

**CDP** Ã¨ la piattaforma unificata che sostituisce CDH e HDP (Che prima erano unite).

**NovitÃ  rispetto a CDH/HDP:**
- âœ… **Hybrid cloud** (on-premise + AWS + Azure + GCP)
- âœ… **SDX integrato** (Shared Data Experience: security + governance unificate)
- âœ… **Containerizzazione** (Kubernetes per Data Services)
- âœ… **Separation of storage and compute** (invece di tight coupling)
- âœ… **Cloud-native architecture** (auto-scaling, serverless)
- âœ… **Data Services modulari** (CDE, CDW, COD, CML, CDF)

---

### 0.3.2 Versioni CDP

**CDP Private Cloud Base** (ex-CDH/HDP on-premise)
- Deployment: on-premise, bare metal
- Componenti: Cloudera Runtime (Hadoop, Spark, Hive, Impala, ecc.)
- Manager: Cloudera Manager
- Security: SDX (Ranger + Atlas integrati)
- Target: aziende con data center esistenti, compliance strict

**CDP Private Cloud Data Services** (nuovo, containerizzato, microservizi)
- Deployment: on-premise Kubernetes (OpenShift, ECS)
- Architettura: containerized, microservices
- Data Services: CDE, CDW, CML
- Target: aziende on-premise che vogliono cloud-like experience

**CDP Public Cloud** (cloud-native)
- Deployment: AWS, Azure, GCP
- Managed service (Cloudera gestisce control plane)
- Auto-scaling, elastic, pay-as-you-go
- Data Services: CDE, CDW, COD, CML, CDF
- Target: aziende cloud-first, workload variabili

---

## 0.4 Differenze architetturali: CDH/HDP â†’ CDP

### 0.4.1 Differenze fisiche (infrastruttura)

| Aspetto | CDH/HDP (legacy) | CDP |
|---------|------------------|-----|
| **Deployment** | Bare metal on-premise | Hybrid: on-premise + cloud |
| **Architettura** | Monolitica (tutto su un cluster) | Modulare (Data Services separati) |
| **Storage/Compute** | Tightly coupled (HDFS locale) | Separated (S3/ADLS + compute elastico) |
| **Scaling** | Verticale/orizzontale hardware | Elastic cloud-native (auto-scaling) |
| **Containers** | No (bare metal JVMs) | SÃ¬ (Kubernetes) |
| **Hardware** | Commodity servers permanenti | Cloud VMs ephemeral |
| **Network** | Intra-cluster (rack-local) | Cloud VPC + cross-region |

---

### 0.4.2 Differenze logiche (software/architettura)

**Sicurezza e governance:**

| Aspetto | CDH | HDP | CDP |
|---------|-----|-----|-----|
| **Authorization** | Sentry | Ranger | Ranger (unified) |
| **Metadata/Lineage** | Navigator | Atlas | Atlas (unified) |
| **Gateway** | Knox (add-on) | Knox | Knox (integrated) |
| **Encryption** | Navigator Encrypt + HDFS TDE | HDFS TDE | HDFS TDE + cloud KMS |
| **Integrazione** | Tool separati | Tool separati | **SDX (tutto integrato)** |

**Management:**

| Aspetto | CDH | HDP | CDP |
|---------|-----|-----|-----|
| **Cluster manager** | Cloudera Manager | Ambari | Cloudera Manager (enhanced) |
| **Monitoring** | Cloudera Manager | Ambari + external | Cloudera Manager + Workload XM |
| **Replication** | Cloudera Manager | Ambari + Falcon | Replication Manager (unified) |

**Data Services (nuovo in CDP):**

CDH/HDP non avevano servizi modulari cloud-native.

CDP introduce:
- **CDE** (Cloudera Data Engineering) - Spark as a Service
- **CDW** (Cloudera Data Warehouse) - Hive/Impala virtual warehouses
- **COD** (Cloudera Operational DB) - HBase as a Service
- **CML** (Cloudera Machine Learning) - ML workspace unificato
- **CDF** (Cloudera DataFlow) - NiFi as a Service

Questi sono **containerizzati**, **auto-scaling**, **indipendenti**.

---

### 0.4.3 Storage: da HDFS locale a object storage

**CDH/HDP:**
```
Cluster on-premise
â”‚
â”œâ”€â”€ Nodo 1: HDFS DataNode + YARN NodeManager + Compute
â”œâ”€â”€ Nodo 2: HDFS DataNode + YARN NodeManager + Compute
â””â”€â”€ Nodo 3: HDFS DataNode + YARN NodeManager + Compute

Storage e compute sono ACCOPPIATI (tightly coupled)
```

**CDP Public Cloud:**
```
Cloud Storage (S3/ADLS/GCS) â†’ Storage separato, persistente
          â†“
Ephemeral Compute Cluster (auto-scaling)
- Spark executors
- Hive/Impala workers
- Containers Kubernetes

Storage e compute sono SEPARATI (decoupled)
```

**Vantaggi separation of storage/compute:**
- âœ… Scale storage e compute indipendentemente
- âœ… Compute ephemeral (crea/distruggi cluster on-demand)
- âœ… Storage persistente (dati rimangono su S3/ADLS)
- âœ… Costo ridotto (paga solo compute quando serve)
- âœ… Durability cloud-native (11 nines su S3)

---

##### **1. CDP Public Cloud â˜ï¸**
**âœ… SÃŒ - Storage SEMPRE separato e SEMPRE in cloud**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CDP Public Cloud Architecture                          â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Compute Layer  â”‚   â†â†’    â”‚  Storage Layer       â”‚  â”‚
â”‚  â”‚  (Ephemeral)    â”‚         â”‚  (Persistent)        â”‚  â”‚
â”‚  â”‚                 â”‚         â”‚                      â”‚  â”‚
â”‚  â”‚ â€¢ CDE (Spark)   â”‚         â”‚ â€¢ S3 (AWS)           â”‚  â”‚
â”‚  â”‚ â€¢ CDW (Hive)    â”‚         â”‚ â€¢ ADLS (Azure)       â”‚  â”‚
â”‚  â”‚ â€¢ CML (ML)      â”‚         â”‚ â€¢ GCS (Google Cloud) â”‚  â”‚
â”‚  â”‚ â€¢ COD (HBase)   â”‚         â”‚                      â”‚  â”‚
â”‚  â”‚                 â”‚         â”‚ Object Storage       â”‚  â”‚
â”‚  â”‚ Auto-scaling    â”‚         â”‚ Durable, scalable    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Caratteristiche:**
- **Storage:** Object storage cloud (S3, ADLS Gen2, GCS)
- **Compute:** Cluster effimeri (EC2, Azure VMs, GCE instances)
- **Architettura:** Completamente disaccoppiata
- **Location:** Tutto in cloud (AWS/Azure/GCP)

**Vantaggi:**
- ðŸš€ **ElasticitÃ  totale:** scala compute senza toccare storage
- ðŸ’° **Costi ottimizzati:** paghi compute solo quando lo usi
- ðŸ”’ **DurabilitÃ :** dati persistono anche cancellando cluster
- â™»ï¸ **Multi-workload:** stessi dati accessibili da CDE, CDW, CML simultaneamente
- ðŸŒ **Global:** replica dati cross-region facilmente

**Esempio pratico:**
```
Data Lake su S3 (us-east-1)
    â†“
â”œâ”€ CDE Virtual Cluster #1 (Spark batch)
â”‚   â””â”€ Scala/scompare on-demand
â”‚
â”œâ”€ CDW Virtual Warehouse (Impala query)
â”‚   â””â”€ Auto-scale basato su query load
â”‚
â””â”€ CML Workspace (data scientists)
    â””â”€ Jupyter notebooks leggono/scrivono stesso Data Lake
```

---

##### **2. CDP Private Cloud Base ðŸ¢**
**âŒ NO - Storage e Compute ACCOPPIATI (architettura tradizionale Hadoop)**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CDP Private Cloud Base Architecture                    â”‚
â”‚                                                          â”‚
â”‚  Ogni nodo ha STORAGE + COMPUTE insieme                 â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Nodo 1: HDFS DataNode + YARN NodeManager        â”‚  â”‚
â”‚  â”‚         [Storage locale] + [Compute]             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Nodo 2: HDFS DataNode + YARN NodeManager        â”‚  â”‚
â”‚  â”‚         [Storage locale] + [Compute]             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Nodo 3: HDFS DataNode + YARN NodeManager        â”‚  â”‚
â”‚  â”‚         [Storage locale] + [Compute]             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                          â”‚
â”‚  On-premise, bare metal servers                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Caratteristiche:**
- **Storage:** HDFS locale sui nodi del cluster
- **Compute:** YARN NodeManager sugli stessi nodi
- **Architettura:** Tightly coupled (heritage da CDH/HDP)
- **Location:** On-premise (data center aziendale)

**PerchÃ© Ã¨ accoppiato:**
- ðŸ“ **Data locality:** compute preferisce elaborare dati locali (stessa macchina)
- ðŸ—ï¸ **Architettura legacy:** ereditÃ  da Hadoop originale (2006-2015)
- ðŸ”§ **Hardware fisico:** server bare metal permanenti

**Limitazioni:**
- âš ï¸ Non puoi scalare storage senza aggiungere nodi compute
- âš ï¸ Non puoi scalare compute senza aggiungere storage HDFS
- âš ï¸ Cluster sempre accesi (no elasticitÃ  on-demand)

---

##### **3. CDP Private Cloud Data Services ðŸ¢â˜ï¸**
**âœ… SÃŒ - Storage separato (on-premise ma cloud-like)**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CDP Private Cloud Data Services Architecture           â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Compute Layer  â”‚   â†â†’    â”‚  Storage Layer       â”‚  â”‚
â”‚  â”‚  (Kubernetes)   â”‚         â”‚  (Object Storage)    â”‚  â”‚
â”‚  â”‚                 â”‚         â”‚                      â”‚  â”‚
â”‚  â”‚ â€¢ CDE Pods      â”‚         â”‚ â€¢ Ozone              â”‚  â”‚
â”‚  â”‚ â€¢ CDW Pods      â”‚         â”‚ â€¢ MinIO              â”‚  â”‚
â”‚  â”‚ â€¢ CML Pods      â”‚         â”‚ â€¢ NetApp StorageGRID â”‚  â”‚
â”‚  â”‚                 â”‚         â”‚ â€¢ Dell ECS           â”‚  â”‚
â”‚  â”‚ OpenShift/ECS   â”‚         â”‚                      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                          â”‚
â”‚  On-premise, but cloud-native architecture              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Caratteristiche:**
- **Storage:** Object storage on-premise (Ozone, MinIO, NetApp, Dell ECS)
- **Compute:** Container orchestration (Kubernetes: OpenShift o ECS Anywhere)
- **Architettura:** Separata, cloud-native in data center
- **Location:** On-premise ma con modello cloud

**Vantaggi:**
- âœ… Separazione storage/compute come il cloud pubblico
- âœ… Auto-scaling dei Data Services
- âœ… Containerizzazione (portabilitÃ )
- âœ… Rimane on-premise (compliance/data sovereignty)

---

##### **Tabella Riepilogativa**

| **CDP Deployment**               | **Storage Separato?** | **In Cloud?** | **Storage Type**        | **Compute Type**          |
|----------------------------------|-----------------------|---------------|-------------------------|---------------------------|
| **CDP Public Cloud**             | âœ… SÃŒ                 | âœ… SÃŒ         | S3/ADLS/GCS (object)   | Cloud VMs (ephemeral)     |
| **CDP Private Cloud Base**       | âŒ NO                 | âŒ NO         | HDFS (local disks)     | Bare metal (permanent)    |
| **CDP Private Cloud Data Services** | âœ… SÃŒ              | âŒ NO         | Ozone/MinIO (object)   | Kubernetes pods (elastic) |

---

##### **In sintesi (rispondendo alla tua domanda):**

**"In CDP lo storage Ã¨ sempre separato dal compute ed in cloud?"**

**Risposta:**
- **CDP Public Cloud:** âœ… SÃŒ, sempre separato + sempre cloud (AWS/Azure/GCP)
- **CDP Private Cloud Base:** âŒ NO, accoppiato + on-premise (HDFS tradizionale)
- **CDP Private Cloud Data Services:** âœ… Separato ma âŒ on-premise (cloud-like architecture ma on prem)

**Quindi:**
- âœ… **Cloud = Sempre separato**
- âŒ **On-premise Base = Mai separato** (tightly coupled)
- âš¡ **On-premise Data Services = Separato ma non cloud** (hybrid model)

---

### 0.4.4 Da monolite a microservizi

**CDH/HDP (monolite):**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Cluster unico on-premise            â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ HDFS + YARN + Hive + Spark +    â”‚ â”‚
â”‚ â”‚ HBase + Kafka + tutto insieme   â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
- Un cluster fa tutto
- Upgrade = downtime di tutto
- Resource contention tra workload

**CDP (microservizi):**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CDE (Spark)    â”‚  â”‚ CDW (Hive)     â”‚  â”‚ CML (ML)       â”‚
â”‚ Auto-scaling   â”‚  â”‚ Auto-scaling   â”‚  â”‚ Isolated       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“                   â†“                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SDX (Shared Data Experience)                             â”‚
â”‚ Ranger + Atlas + Metastore                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Data Lake (S3/ADLS/GCS)                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
- Servizi indipendenti
- Upgrade indipendenti (zero downtime)
- Isolamento risorse
- Governance condivisa (SDX)

---

## 0.5 Timeline evolutiva

```
2008 â†’ Cloudera fondata
2009 â†’ CDH 1 (prima distribuzione Hadoop commerciale)
2011 â†’ Hortonworks fondata
2012 â†’ CDH 4 (Impala lanciato)
2013 â†’ HDP 2.0 (Ranger, Atlas)
2014 â†’ CDH 5 (Spark integrato)
2017 â†’ CDH 6 (ultima major release CDH)
2018 â†’ Merger Cloudera + Hortonworks annunciato
2019 â†’ Merger completato, CDP annunciato
2020 â†’ CDP Public Cloud GA (General Availability)
2021 â†’ CDP Private Cloud Data Services GA
2023 â†’ CDP evoluzione continua (nuovi Data Services)
```

---

## 0.6 PerchÃ© CDP Ã¨ importante per l'esame

**L'esame CDP-0011 testa:**
1. Conoscenza componenti (heritage da CDH/HDP)
2. Architettura moderna (cloud-native, SDX)
3. Differenze Public vs Private Cloud
4. Data Services (nuovo in CDP)

**Non chiede:**
- Dettagli su CDH/HDP legacy (obsoleti)
- Ambari (sostituito da Cloudera Manager)
- Sentry (sostituito da Ranger)

**Focus:** CDP come piattaforma unificata moderna.

---

## 0.7 Riepilogo: cosa devi sapere

âœ… **CDP unisce best-of-breed di CDH e HDP**
âœ… **SDX Ã¨ il cuore (Ranger + Atlas + Metastore unificati)**
âœ… **Hybrid cloud: Private Cloud Base + Public Cloud**
âœ… **Separation of storage and compute (cloud-native)**
âœ… **Data Services containerizzati e auto-scaling**
âœ… **Security/governance integrate by design**

âŒ **Non serve sapere:** dettagli CDH/HDP specifici, Ambari, Sentry

*SDX (Shared Data Experience) Ã¨ una componente della piattaforma Cloudera che gestisce in modo centralizzato:
- la sicurezza, 
- il catalogo dei dati, 
- la governance 
- e le policy di accesso ai dati nei cluster Big Data

In pratica, SDX permette di:

- Definire e applicare regole di sicurezza e privacy sui dati.
- Gestire i metadati (informazioni sui dati) in modo unificato.
- Tracciare e monitorare chi accede ai dati e come vengono usati.
- Garantire coerenza e controllo su dati distribuiti tra diversi servizi (come Hadoop, Hive, Impala, ecc.).
- SDX semplifica la gestione dei dati in ambienti complessi, assicurando che le policy siano rispettate ovunque i dati vengano usati.

---

# PARTE 1: COMPONENTI PRINCIPALI CDP (15 domande)

---

## 0. HDFS â€“ Hadoop Distributed File System

### 0.1 Cos'Ã¨ HDFS

**HDFS** Ã¨ un **file system distribuito Java-based** per memorizzare grandi volumi di dati.

**Caratteristiche principali:**
- Storage scalabile su cluster di commodity server
- Replica automatica dei dati (default 3 copie)
- Fault tolerance nativa
- Write-once, read-many (ottimizzato per streaming)

### 0.2 Architettura HDFS

```
NameNode (master)
- Gestisce namespace del file system* **
- Controlla metadata (nomi file, permessi, posizioni blocchi)
- Single point of failure (mitigato da HA)

DataNode (worker)
- Memorizza i blocchi di dati effettivi
- Invia heartbeat al NameNode
- Esegue letture/scritture su richiesta client
```

*â€œGestisce namespace del file systemâ€ significa che il sistema (ad esempio HDFS) si occupa di organizzare e tenere traccia della struttura delle cartelle e dei file, dei loro nomi, delle gerarchie e dei percorsi. In pratica, il namespace Ã¨ lâ€™insieme di tutti i nomi (file e directory) e la loro organizzazione allâ€™interno del file system, come una mappa che dice dove si trova ogni file o cartella.
**Il file system Ã¨ il componente di un sistema operativo (o di una piattaforma come HDFS) che organizza, gestisce e memorizza i file e le cartelle su un dispositivo di archiviazione (come disco, SSD, ecc.). Permette di salvare, leggere, modificare e cancellare file, mantenendo la struttura gerarchica (cartelle, sottocartelle, percorsi) e gestendo i nomi e i permessi di accesso. In sintesi, Ã¨ il â€œsistemaâ€ che tiene in ordine tutti i dati su un computer o cluster

### 0.3 Concetti chiave HDFS

| Concetto | Descrizione |
|----------|-------------|
| **Blocco** | UnitÃ  minima di storage (default 128MB/256MB) |
| **Replica** | Numero di copie di ogni blocco (default 3)   |
| **Rack Awareness** | Distribuisce repliche su rack diversi |
| **NameNode HA** | Secondary/Standby NameNode per failover  |

ðŸ‘‰ **Domanda tipica d'esame**
> HDFS Ã¨ ottimizzato per? â†’ **Grandi file, accesso sequenziale, throughput alto**
> Quante repliche default? â†’ **3**

---

## 0.5 Hue â€“ SQL Query Interface

### 0.5.1 Cos'Ã¨ Hue

**Hue** Ã¨ l'interfaccia web unificata interrogare dati con hive ed impala in CDP.

**Funzioni principali:**
- Editor SQL per Hive e Impala
- File browser HDFS
- Job browser (YARN, Oozie)
- Query history e saved queries

### 0.5.2 Hue e integrazione motori

Hue si connette a:
- **Hive** per query batch
- **Impala** per query interattive
- **YARN** per monitoring job
- **Oozie** per workflow

ðŸ‘‰ **Domanda tipica d'esame**
> Hue Ã¨ un motore SQL? â†’ **No, Ã¨ un'interfaccia web per Hive/Impala**

---

## 0.7 YARN â€“ Resource Manager

### 0.7.1 Cos'Ã¨ YARN

**Apache Hadoop YARN** Ã¨ il **resource manager** per applicazioni distribuite.

**Funzione principale:**
- Scheduling e allocazione risorse (CPU, RAM)
- Gestione container per applicazioni
- Monitoring e fault tolerance

### 0.7.2 Architettura YARN

```
ResourceManager (master)
- Scheduler globale
- Assegna risorse ai job

NodeManager (worker)
- Lancia container sui nodi
- Monitora utilizzo risorse

ApplicationMaster
- Negozia risorse per ogni applicazione
- Coordina esecuzione task
```

### 0.7.3 YARN e motori

YARN gestisce risorse per:
- MapReduce
- Spark
- Tez (Hive)

ðŸ‘‰ **Domanda tipica d'esame**
> YARN gestisce storage o compute? â†’ **Compute (CPU/RAM)**
> YARN Ã¨ necessario per Impala? â†’ **No, Impala Ã¨ long-running daemon**

---

## 0.9 Apache Spark

### 0.9.1 Cos'Ã¨ Spark

**Apache Spark** Ã¨ un **motore di elaborazione distribuita in-memory** per big data e analytics.

**Caratteristiche:**
- Elaborazione in-memory (10-100x piÃ¹ veloce di MapReduce)
- API unificata: batch*, streaming, ML, SQL, graph
- Supporta Scala, Java, Python, R

* Ã¨ unâ€™operazione che esegue una serie di comandi o elaborazioni automaticamente, senza intervento umano, spesso su grandi quantitÃ  di dati.

### 0.9.2 Componenti Spark

| Componente | Funzione |
|------------|----------|
| **Spark Core** | Engine di base, RDD, task scheduling |
| **Spark SQL** | Query SQL su dati strutturati |
| **Spark Streaming** | Stream processing (micro-batch) |
| **MLlib** | Machine learning library |
| **GraphX** | Graph processing |

### 0.9.3 Spark vs MapReduce

| Aspetto | MapReduce | Spark |
|---------|-----------|-------|
| Storage intermedio | Disco (spill) | Memoria (RAM) |
| Latenza | Minuti | Secondi |
| Fault tolerance | Retry task | RDD lineage |
| API | Java MapReduce | Scala/Python/Java/R |

ðŸ‘‰ **Domanda tipica d'esame**
> Spark Ã¨ batch o streaming? â†’ **Entrambi**
> PerchÃ© Spark Ã¨ piÃ¹ veloce? â†’ **Elaborazione in-memory**

---

## 0.11 Apache Oozie

### 0.11.1 Cos'Ã¨ Oozie

**Apache Oozie** Ã¨ un **workflow scheduler** per job Hadoop.

**Funzioni:**
- Orchestrazione job complessi (DAG - Directed Acyclic Graph)
- Scheduling basato su tempo o eventi
- Coordinamento dipendenze tra job

### 0.11.2 Tipi di job Oozie

| Tipo | Descrizione |
|------|-------------|
| **Workflow** | Sequenza di azioni (map, reduce, Spark, Hive, ecc.) |
| **Coordinator** | Workflow ricorrenti (schedule cron-like) |
| **Bundle** | Gruppi di coordinator |

### 0.11.3 Azioni supportate

Oozie supporta:
- MapReduce
- Spark
- Hive
- Sqoop
- Shell script
- Java

ðŸ‘‰ **Domanda tipica d'esame**
> Oozie Ã¨ un workflow scheduler? â†’ **SÃ¬**
> Combina job sequenzialmente? â†’ **SÃ¬**
> Supporta MiNiFi? â†’ **No**

---

## 0.13 Apache Kafka

### 0.13.1 Cos'Ã¨ Kafka

**Apache Kafka** Ã¨ una **piattaforma di streaming distribuita** ad alte prestazioni.

**Caratteristiche:**
- Publish-subscribe messaging*
- Storage persistente su disco
- Alta throughput (milioni msg/sec)
- Fault tolerance e replication

*Publish-subscribe messaging: Ã¨ un modello di comunicazione asincrona in cui i produttori (publisher) inviano messaggi a un canale o argomento (topic), senza conoscere i destinatari. I consumatori (subscriber) si iscrivono a uno o piÃ¹ topic e ricevono solo i messaggi di loro interesse. Questo modello permette un forte disaccoppiamento tra chi produce e chi consuma i dati, ed Ã¨ molto usato in sistemi distribuiti, streaming e big data (es. Apache Kafka, RabbitMQ, Google Pub/Sub).

### 0.13.2 Concetti chiave Kafka

| Concetto | Descrizione |
|----------|-------------|
| **Topic** | Categoria/feed di messaggi |
| **Producer** | Pubblica messaggi su topic |
| **Consumer** | Legge messaggi da topic |
| **Broker** | Nodo Kafka che memorizza dati |
| **Partition** | Shard di un topic per parallelismo |

### 0.13.3 Kafka use cases

- Real-time streaming analytics
- Log aggregation
- Event sourcing
- Messaging tra microservizi

ðŸ‘‰ **Domanda tipica d'esame**
> Kafka Ã¨ storage o processing? â†’ **Entrambi (memorizza + distribuisce)**
> Kafka Ã¨ persistente? â†’ **SÃ¬, retention configurabile**

---

## 0.15 Apache NiFi

### 0.15.1 Cos'Ã¨ NiFi

**Apache NiFi** Ã¨ un **sistema per automatizzare il flusso di dati** tra sistemi.

**Caratteristiche:**
- GUI web drag-and-drop (visual programming)
- Connessioni a 300+ sorgenti/destinazioni
- Data provenance (tracciabilitÃ  completa)
- Backpressure handling

### 0.15.2 NiFi use cases

- Ingestione dati da sorgenti multiple
- Routing e trasformazione dati
- Data enrichment
- Push/pull da/verso sistemi esterni

### 0.15.3 NiFi vs Kafka

| Aspetto | NiFi | Kafka |
|---------|------|-------|
| Focus | Data flow orchestration | Messaging/streaming |
| GUI | SÃ¬ (visual) | No |
| Trasformazioni | SÃ¬ (native) | No (serve Kafka Streams) |
| Throughput | Medio/alto | Altissimo |

ðŸ‘‰ **Domanda tipica d'esame**
> NiFi ha GUI? â†’ **SÃ¬, web-based drag-and-drop**
> NiFi Ã¨ no-code? â†’ **SÃ¬, visual programming**

---

## 0.17 Apache HBase e Phoenix

### 0.17.1 Cos'Ã¨ HBase

**Apache HBase** Ã¨ un **database NoSQL distribuito** per accesso real-time a big data.

**Caratteristiche:**
- Modello wide-column (colonne sparse)
- Accesso random read/write veloce
- ScalabilitÃ  orizzontale automatica
- Consistency strong (non eventual)

### 0.17.2 HBase use cases

- Time-series data
- Real-time analytics
- Messaggistica e social media feed
- IoT sensor data

### 0.17.3 Cos'Ã¨ Phoenix

**Apache Phoenix** Ã¨ un **layer SQL sopra HBase**.

**Funzioni:**
- Query SQL su dati HBase
- Indici secondari
- JDBC driver
- Performance ottimizzate

ðŸ‘‰ **Domanda tipica d'esame**
> HBase Ã¨ relazionale? â†’ **No, NoSQL wide-column**
> Phoenix cosa fa? â†’ **SQL interface per HBase**

---

## 0.19 Apache Kudu

### 0.19.1 Cos'Ã¨ Kudu

**Apache Kudu** Ã¨ un **columnar storage engine** per Hadoop.

Kudu in Cloudera serve per memorizzare e gestire dati che devono essere sia letti che scritti velocemente, anche in tempo reale. Ãˆ un database pensato per analisi veloci: permette di aggiungere, modificare e leggere dati subito, senza dover aspettare lunghi tempi di caricamento. Kudu Ã¨ ideale quando hai bisogno di aggiornare spesso i dati e fare analisi rapide, ad esempio per dashboard, report o applicazioni che lavorano con dati sempre aggiornati.

**Caratteristiche:**
- Storage colonnare (come Parquet, ma mutabile)
- Fast analytics (scan) + fast updates/inserts
- Integrazione nativa con Impala e Spark
- ACID compliant

### 0.19.2 Kudu vs HBase vs HDFS

| Aspetto | HDFS | HBase | Kudu |
|---------|------|-------|------|
| Workload | Batch analytics | Random access | Hybrid (analytics + updates) |
| Updates | Immutabile | Veloce | Veloce |
| Scans | Veloce | Lento | Veloce |
| Formato | File-based | Row-based | Column-based |

ðŸ‘‰ **Domanda tipica d'esame**
> Kudu Ã¨ colonnare? â†’ **SÃ¬**
> Kudu supporta update? â†’ **SÃ¬, ACID**
> Kudu sostituisce HDFS? â†’ **No, Ã¨ complementare**

---

## 1. Ruolo di Hive e Impala nella Cloudera Data Platform

In **In cloudera**, **Hive** e **Impala** non sono alternative, ma **complementari**.

| Motore | Tipo di accesso | Caso dâ€™uso principale |
|------|----------------|----------------------|
| Hive | SQL batch | ETL, reporting massivo |
| Impala | SQL interattivo | Analisi a bassa latenza |

ðŸ‘‰ **Domanda tipica dâ€™esame**  
> Quale scegliere per query interattive? â†’ **Impala**  
> Quale per ETL batch? â†’ **Hive**

---

## 2. Apache Hive â€“ Approfondimento completo

## 2.1 Cosâ€™Ã¨ Apache Hive

**Apache Hive** Ã¨ un **data warehouse distribuito** che fornisce:
- un livello SQL sopra Hadoop (Consente di scrivere query SQL-like per analizzare i dati in HDFS)
- Ã¨ uno strato sopra HDFS (Hive organizza i dati in tabelle e schemi, fornendo una struttura logica ai file grezzi in HDFS)
- uno schema-on-read (Lo schema viene applicato ai dati solo quando vengono letti (non al momento della scrittura).

Hive **non Ã¨ un database** e **non Ã¨ OLTP**.

---

## 2.2 Hive come strato semantico del Data Lake

Senza Hive, il Data Lake Ã¨ solo un insieme di file.  
Hive introduce:

- tabelle
- colonne
- tipi di dato
- partizioni

âž¡ï¸ **Hive dÃ  significato al dato**

Questo Ã¨ fondamentale anche lato governance (Atlas, Ranger, auditing).

---

## 2.3 Hive Metastore (concetto CHIAVE per lâ€™esame)

Il **Metastore** Ã¨ il componente piÃ¹ importante di Hive.

### **Cosa memorizza il Metastore?**
1. **Definizione delle tabelle:**
   - Nomi delle tabelle e dei database.
2. **Schema delle tabelle:**
   - Colonne, tipi di dati, vincoli.
3. **Partizioni:**
   - Informazioni sulle partizioni delle tabelle (es. `year=2025`, `region=EU`).
4. **Formati dei file:**
   - Specifica il formato di archiviazione (es. Parquet, ORC, TextFile).
5. **Location su HDFS / Object Storage:**
   - Percorso fisico dei dati (es. `hdfs://data/employees`).
6. **Metadati aggiuntivi:**
   - Statistiche (es. numero di righe, dimensione dei dati).

### **PerchÃ© Ã¨ importante per lâ€™esame?**
- **Concetto chiave:** Il Metastore Ã¨ il cuore di Hive, senza di esso non Ã¨ possibile interrogare i dati.
- **Domande tipiche:**
  - Cosa memorizza il Metastore?
  - Dove sono archiviati i metadati di Hive?

### **Esempio pratico:**
Per una tabella Hive:
```sql
CREATE TABLE employees (
    id INT,
    name STRING,
    salary DECIMAL
)
PARTITIONED BY (department STRING)
STORED AS PARQUET
LOCATION 'hdfs://data/employees';
```
Il Metastore memorizza:
- **Schema delle colonne:** `id INT`, `name STRING`, `salary DECIMAL`.
- **Partizioni:** `department STRING`.
- **Formato file:** `PARQUET`.
- **Percorso:** `hdfs://data/employees`.

---

## 2.4 Schema-on-read (concetto fondamentale)

Hive applica lo schema **in lettura**, non in scrittura.

Vantaggi:
- ingestione rapida
- flessibilitÃ 
- adattabilitÃ  a sorgenti diverse

Svantaggi:
- errori di schema emergono a query time
- maggiore responsabilitÃ  sullo strato analitico

ðŸ‘‰ **Domanda tipica dâ€™esame**  
> Hive usa schema-on-read o schema-on-write? â†’ **schema-on-read**

---

## 2.5 Tipi di tabelle Hive

### Managed Tables
- Hive gestisce dati e metadati
- `DROP TABLE` elimina anche i file
- piÃ¹ rischiose in ambienti enterprise

### External Tables
- Hive gestisce solo i metadati
- i dati restano esterni
- preferite nei Data Lake

ðŸ‘‰ **Domanda tipica d'esame**  
> Quali tabelle sono consigliate per Data Lake? â†’ **External**

---

## 2.6 Hive e performance

-â€¯Batch-oriented: Hive Ã¨ progettato per elaborare grandi quantitÃ  di dati in blocco (batch), non per rispondere a singole query in tempo reale. Ãˆ ideale per analisi massive, come report o aggregazioni su tabelle molto grandi.

-â€¯Adatto a scansioni complete: Hive lavora bene quando deve leggere e analizzare intere tabelle o grandi porzioni di dati, ad esempio per calcolare totali, medie o altre statistiche su dataset estesi.

-â€¯Meno performante su query rapide: Se hai bisogno di risposte immediate su pochi record (come una ricerca puntuale), Hive non Ã¨ la scelta migliore, perchÃ© il suo motore (basato su MapReduce o Tez) ha una latenza di avvio elevata.

Ottimizzazioni comuni:
-â€¯Partizionamento: suddivide le tabelle in â€œpartiâ€ (es. per data, paese, ecc.), cosÃ¬ le query leggono solo i dati necessari, riducendo i tempi di scansione.
-â€¯Formati colonnari (ORC, Parquet): questi formati memorizzano i dati per colonne invece che per righe, migliorando la compressione e la velocitÃ  di lettura per le query analitiche.
-â€¯Predicate pushdown: permette di applicare i filtri (WHERE) direttamente durante la lettura dei dati, evitando di caricare dati inutili e velocizzando le query.


---

## 2.7 Quando usare Hive (riassunto da esame)

Usa Hive quando:
- i dati sono molto grandi
- la latenza non Ã¨ critica
- stai facendo ETL o reporting batch
- la prioritÃ  Ã¨ la scalabilitÃ 

---

## 3. Apache Impala â€“ Approfondimento completo

## 3.1 Cosâ€™Ã¨ Apache Impala

**:contentReference[oaicite:2]{index=2}** Ã¨ un **motore SQL MPP (Massively Parallel Processing)** progettato per:
- query interattive
- bassa latenza
- analisi esplorativa

Impala **non usa MapReduce**.

---

## 3.2 Architettura di Impala

Impala utilizza:
- daemon su ogni nodo
- esecuzione in parallelo
- elaborazione in memoria

Caratteristiche:
- niente job batch
- niente scritture temporanee su HDFS
- risposta immediata

ðŸ‘‰ **Domanda tipica dâ€™esame**  
> Impala Ã¨ batch o interattivo? â†’ **interattivo**

---

## 3.3 Impala e Metastore condiviso

Impala:
- usa lo stesso Metastore di Hive
- vede le stesse tabelle
- usa gli stessi file su HDFS

âš ï¸ **Punto dâ€™esame importante**
> Non esiste duplicazione dei dati tra Hive e Impala

---

## 3.4 Impala e performance

Impala Ã¨ molto veloce perchÃ©:
- legge direttamente i file
- usa memoria
- sfrutta MPP

Ma:
- consuma molte risorse
- Ã¨ sensibile a query inefficienti
- va governato (YARN, admission control)

---

## 3.5 Impala e sicurezza

In Cloudera, Impala:
- usa Kerberos
- applica policy Ranger
- Ã¨ soggetto ad auditing

âš ï¸ Impala **espone dati velocemente** â†’ rischio maggiore se mal configurato.

---

## 3.6 Quando usare Impala (riassunto da esame)

Usa Impala quando:
- serve risposta rapida
- analisi interattiva
- dashboard
- esplorazione dati

---

## 4. Confronto Hive vs Impala (TABELLA DA MEMORIZZARE)

| Caratteristica | Hive | Impala |
|--------------|------|--------|
| Tipo | Data Warehouse | SQL Engine |
| Latenza | Alta | Bassa |
| Uso | Batch / ETL | Interattivo |
| Motore | Job batch | MPP |
| Metastore | SÃ¬ | SÃ¬ (condiviso) |
| Schema | Schema-on-read | Schema-on-read |
| Query rapide | âŒ | âœ… |

ðŸ‘‰ **Questa tabella copre il 90% delle domande Hive/Impala allâ€™esame**

---

## 5. Scenario tipico dâ€™esame (ragionamento)

**Domanda**  
Un analista deve eseguire query SQL rapide su grandi volumi di dati giÃ  strutturati. Quale strumento scegliere?

**Risposta corretta**
â†’ **Impala**

**PerchÃ©**
- bassa latenza
- SQL interattivo
- dati giÃ  nel Data Lake

---

## 6. Errori comuni da evitare allâ€™esame

âŒ Dire che Hive Ã¨ interattivo  
âŒ Dire che Impala Ã¨ un data warehouse  
âŒ Pensare che Hive e Impala abbiano storage separato  
âŒ Confondere Metastore con HDFS  

---

## 7. Sintesi finale (da memorizzare)

- Hive = significato + batch
- Impala = velocitÃ  + interattivitÃ 
- Metastore = cuore semantico
- HDFS = storage comune
- CDP = governance unica

---

## 8. Frase chiave da esame (memorizzala)

> **Hive e Impala sono due motori SQL diversi che condividono gli stessi dati e lo stesso Metastore, ma servono casi dâ€™uso differenti.**
---
# PARTE 2: SICUREZZA CDP (12 domande)

## 9. Shared Data Experience (SDX)

### 9.1 Cos'Ã¨ SDX

**SDX** Ã¨ l'architettura di sicurezza e governance integrata di CDP.

**Componenti SDX:**
- **Apache Ranger** - Authorization & access control
- **Apache Atlas** - Metadata management & data lineage
- **Apache Knox** - Perimeter security (gateway)
- **Hive Metastore** - Schema centrale
- **Data Catalog** - Discovery & search
- **Replication Manager** - Backup & DR
- **Workload Manager** - Monitoring & optimization

### 9.2 PerchÃ© SDX Ã¨ importante

âœ… **Sicurezza integrata by design**
âœ… **Governance centralizzata**
âœ… **Policy consistenti su tutti i servizi**
âœ… **Audit trail completo**

ðŸ‘‰ **Domanda tipica d'esame**
> SDX include Ranger e Atlas? â†’ **SÃ¬**
> SDX Ã¨ solo per security? â†’ **No, anche governance e metadata**

---

## 10. Apache Ranger â€“ Authorization

### 10.1 Cos'Ã¨ Ranger

**Apache Ranger** fornisce **autorizzazione centralizzata** per l'ecosistema Hadoop.

**Funzioni:**
- Policy-based access control (PBAC)
- Role-based access control (RBAC)
- Fine-grained authorization (riga/colonna)
- Data masking (offuscamento dati sensibili)
- Row-level filtering
- Audit centralizzato

### 10.2 Servizi supportati da Ranger

Ranger gestisce accessi per:
- HDFS
- Hive
- Impala
- HBase
- Kafka
- Solr
- YARN
- Atlas

### 10.3 Ranger policies

**Tipi di policy:**
- **Access policies** - chi puÃ² fare cosa (SELECT, INSERT, UPDATE, DELETE)
- **Masking policies** - offusca dati sensibili (es. GDPR)
- **Row filter policies** - limita righe visibili per utente/gruppo

ðŸ‘‰ **Domanda tipica d'esame**
> Ranger fa authentication o authorization? â†’ **Authorization**
> Ranger supporta masking? â†’ **SÃ¬**

---

## 11. Apache Atlas â€“ Metadata & Governance

### 11.1 Cos'Ã¨ Atlas

**Apache Atlas** Ã¨ la piattaforma di **metadata management e data governance**.

**Funzioni:**
- Metadata repository (catalogo dati)
- Data lineage (da dove viene il dato)
- Data classification (PII, sensibile, pubblico)
- Business glossary
- Search & discovery

### 11.2 Atlas e lineage

**Data Lineage** traccia:
- Origine dati (source)
- Trasformazioni (ETL)
- Destinazione (target)
- Dipendenze tra entitÃ 

Esempio: `Salesforce â†’ Sqoop â†’ HDFS â†’ Hive â†’ Impala â†’ BI Report`

### 11.3 Atlas integration

Atlas traccia automaticamente:
- Hive queries (CREATE TABLE, INSERT)
- Spark jobs
- Sqoop imports
- NiFi flows

ðŸ‘‰ **Domanda tipica d'esame**
> Atlas fa security o governance? â†’ **Governance (metadata)**
> Atlas traccia lineage? â†’ **SÃ¬**

---

## 12. Apache Knox â€“ Perimeter Security

### 12.1 Cos'Ã¨ Knox

**Apache Knox** Ã¨ un **gateway di sicurezza perimetrale** per cluster Hadoop.

**Funzioni:**
- Single point of access (reverse proxy)
- Authentication (LDAP, SSO, Kerberos)
- SSL/TLS termination
- Token-based authentication (JWT)
- Topology-based routing

### 12.2 Knox use cases

- Esporre servizi Hadoop (Hive, HBase) all'esterno del cluster
- Integrazione con enterprise SSO
- Protezione endpoint REST API
- Load balancing

ðŸ‘‰ **Domanda tipica d'esame**
> Knox Ã¨ un gateway? â†’ **SÃ¬**
> Knox fa authentication? â†’ **SÃ¬**

---

## 13. CDP Public Cloud â€“ Integration SSO

### 13.1 Identity Federation

CDP Public Cloud supporta **identity federation** con SAML-based IdP.

**IdP supportati:**
- Okta
- Azure AD
- Google Workspace
- Ping Identity
- ADFS (Active Directory Federation Services)

### 13.2 Vantaggi SSO

âœ… Single sign-on (un login per tutti i servizi)
âœ… No account Cloudera necessario
âœ… Gestione utenti centralizzata
âœ… MFA (Multi-Factor Authentication) support

ðŸ‘‰ **Domanda tipica d'esame**
> CDP Public supporta SAML SSO? â†’ **SÃ¬**
> Serve account Cloudera con SSO? â†’ **No**

---

## 14. CDP Private Cloud â€“ LDAP e Kerberos

### 14.1 Authentication in Private Cloud

CDP Private Cloud integra:
- **LDAP** (Lightweight Directory Access Protocol) per identity
- **Kerberos** per authentication
- **Active Directory** (LDAP + Kerberos combinati)

### 14.2 LDAP

**Funzioni:**
- User/group management
- Directory services
- Integrazione con AD aziendale

### 14.3 Kerberos

**Funzioni:**
- Strong authentication (ticket-based)
- Mutual authentication (client â†” server)
- Protection contro replay attacks
- Single sign-on (SSO)

ðŸ‘‰ **Domanda tipica d'esame**
> Private Cloud usa Kerberos? â†’ **SÃ¬**
> LDAP Ã¨ per identity o authentication? â†’ **Identity (Kerberos per auth)**

---

## 15. Encryption â€“ Data at Rest

### 15.1 HDFS Transparent Encryption

**HDFS TDE** (Transparent Data Encryption):
- Cifratura automatica dei dati su HDFS
- Trasparente per applicazioni (no code change)
- Key management via KMS (Key Management Service)
- Per-zone encryption (encryption zones)

### 15.2 Cloudera Navigator Encrypt

**Navigator Encrypt**:
- Full-disk encryption per nodi del cluster
- Cifratura a livello OS (sotto HDFS)
- Protection anche se disco rubato
- Transparent per applicazioni

### 15.3 Cloud Storage Encryption

**Cloud providers:**
- **AWS S3** - SSE (Server-Side Encryption), KMS
- **Azure ADLS** - Storage Service Encryption
- **GCP GCS** - Default encryption at rest

ðŸ‘‰ **Domanda tipica d'esame**
> HDFS supporta encryption at rest? â†’ **SÃ¬ (TDE)**
> Cloud storage Ã¨ cifrato? â†’ **SÃ¬ (di default nei cloud provider)**

---

## 16. Encryption â€“ Data in Transit

### 16.1 TLS/SSL

**Transport Layer Security** (TLS 1.2+):
- Cifratura traffico di rete
- Certificati X.509
- Protection contro man-in-the-middle

**Servizi con TLS:**
- HDFS (NameNode â†” DataNode)
- Hive/Impala (client â†” server)
- HTTP/REST API
- JDBC/ODBC connections

ðŸ‘‰ **Domanda tipica d'esame**
> TLS cifra data in transit? â†’ **SÃ¬**
> CDP supporta TLS? â†’ **SÃ¬ (1.2+)**

---

# PARTE 3: DATA SERVICES (9 domande)

## 17. Cloudera Data Engineering (CDE)

### 17.1 Cos'Ã¨ CDE

**Cloudera Data Engineering** Ã¨ un servizio per **gestire e schedulare job Apache Spark**.

**Caratteristiche:**
- Auto-scaling cluster Spark
- No overhead di gestione cluster manuale
- Supporto batch e streaming
- Integrato con SDX (security/governance)

### 17.2 CDE Public vs Private Cloud

| Aspetto | Public Cloud | Private Cloud |
|---------|--------------|---------------|
| Infrastructure | Cloud provider managed | On-premise Kubernetes |
| Scaling | Elastico (cloud-native) | Limitato da hardware |
| Deployment | Managed service | Self-service virtual cluster |

ðŸ‘‰ **Domanda tipica d'esame**
> CDE Ã¨ per Spark? â†’ **SÃ¬**
> CDE fa auto-scaling? â†’ **SÃ¬**

---

## 18. Cloudera Data Warehouse (CDW)

### 18.1 Cos'Ã¨ CDW

**Cloudera Data Warehouse** Ã¨ un servizio per creare **data warehouse indipendenti e auto-scaling**.

**Caratteristiche:**
- Containerizzato (Kubernetes)
- Hive e Impala virtual warehouses
- Auto-scaling dinamico
- Indipendenti e isolati (multi-tenancy)
- Upgrade indipendenti

### 18.2 CDW Virtual Warehouses

**Tipi:**
- **Hive Virtual Warehouse** - batch ETL
- **Impala Virtual Warehouse** - query interattive

Ogni VW puÃ² scalare indipendentemente.

### 18.3 CDW Public vs Private Cloud

| Aspetto | Public Cloud | Private Cloud |
|---------|--------------|---------------|
| Infrastructure | AWS/Azure/GCP | OpenShift/ECS/Kubernetes |
| Scaling | Elastic cloud-native | Limitato da capacity |
| Storage | S3/ADLS/GCS | HDFS/Ozone |

ðŸ‘‰ **Domanda tipica d'esame**
> CDW Ã¨ containerizzato? â†’ **SÃ¬ (Kubernetes)**
> CDW supporta Hive e Impala? â†’ **SÃ¬ (virtual warehouses)**

---

## 19. Cloudera Operational Database (COD)

### 19.1 Cos'Ã¨ COD

**Cloudera Operational Database** Ã¨ un servizio per **database operazionali real-time, scalabili e always-available**.

**Tecnologie:**
- Powered by **Apache HBase** (storage)
- **Apache Phoenix** (SQL interface)

### 19.2 COD use cases

- Low-latency random access
- Store/retrieve authentication details
- Time-series data (IoT, logs)
- Real-time analytics
- Session management

### 19.3 COD caratteristiche

âœ… Auto-scaling
âœ… Always-on (HA nativa)
âœ… SQL via Phoenix
âœ… NoSQL via HBase API

ðŸ‘‰ **Domanda tipica d'esame**
> COD Ã¨ per low-latency? â†’ **SÃ¬**
> COD usa HBase? â†’ **SÃ¬**
> COD Ã¨ per authentication data? â†’ **SÃ¬ (domanda campione esame)**

---

## 20. Cloudera Machine Learning (CML)

### 20.1 Cos'Ã¨ CML

**Cloudera Machine Learning** unifica **data science e data engineering** in un servizio integrato.

**Funzioni:**
- Workspace collaborativo per data scientist
- Supporto Python, R, Scala
- Model training e deployment
- Jupyter, RStudio, VS Code integration
- MLOps (CI/CD per modelli)

### 20.2 CML caratteristiche

- **Workspace isolati** per progetti
- **Experiments tracking** (modelli, hyperparameter)
- **Model deployment** (REST API)
- **Model monitoring** (drift detection)

### 20.3 CML Public vs Private Cloud

| Aspetto | Public Cloud | Private Cloud |
|---------|--------------|---------------|
| Infrastructure | Cloud managed | OpenShift/Kubernetes |
| GPU support | SÃ¬ | SÃ¬ (se disponibile) |
| Scaling | Elastico | Limitato da cluster |

ðŸ‘‰ **Domanda tipica d'esame**
> CML Ã¨ per ML? â†’ **SÃ¬**
> CML supporta Python/R? â†’ **SÃ¬**

---

## 21. Cloudera DataFlow (CDF)

### 21.1 Cos'Ã¨ CDF

**Cloudera DataFlow** Ã¨ un servizio **cloud-native per distribuzione universale di dati**.

**Tecnologia:**
- Powered by **Apache NiFi**

**Caratteristiche:**
- Connect to any data source
- Process and deliver to any destination
- GUI drag-and-drop
- Auto-scaling flow deployments

### 21.2 CDF use cases

- Real-time data ingestion
- Data routing e enrichment
- Edge-to-cloud data movement
- IoT data collection

ðŸ‘‰ **Domanda tipica d'esame**
> CDF usa NiFi? â†’ **SÃ¬**
> CDF Ã¨ cloud-native? â†’ **SÃ¬ (Public Cloud)**

---

# PARTE 4: DEPLOY CDP PUBLIC CLOUD (9 domande)

## 22. CDP Public Cloud â€“ Concetti Core

### 22.1 Cos'Ã¨ un Environment

**Environment** Ã¨ un **subset logico del cloud provider account** che include:
- Virtual network (VPC/VNet)
- Security groups
- Storage locations (S3/ADLS/GCS)
- SDX (Data Lake)

âœ… Puoi registrare **quanti environment vuoi**
âœ… Ogni environment Ã¨ isolato

ðŸ‘‰ **Domanda tipica d'esame** (domanda campione esame)
> Environment Ã¨ un subset del cloud account? â†’ **SÃ¬**
> Quanti environment posso creare? â†’ **Quanti voglio**

---

## 22.2 Credential

**Credential** permette a CDP di **autenticarsi con il cloud provider**.

**Prerequisiti:**
- AWS: IAM role, cross-account access
- Azure: Service Principal, Managed Identity
- GCP: Service Account

---

## 22.3 Data Lake

**Data Lake** in CDP Public Cloud:
- Storage centralizzato (S3/ADLS/GCS)
- SDX (Ranger + Atlas)
- Hive Metastore
- Shared tra tutti i Data Hub dello stesso environment

---

## 23. CDP Public Cloud â€“ Cloud Providers

### 23.1 AWS Requirements

**Prerequisites:**
- AWS account con privilegi sufficienti
- VPC con subnet (pubbliche/private)
- S3 bucket per storage
- IAM roles/policies
- Cross-account trust

**Services usati:**
- EC2 (compute)
- S3 (storage)
- RDS (Metastore/Ranger DB)
- EKS (Kubernetes per Data Services)

---

### 23.2 Azure Requirements

**Prerequisites:**
- Azure subscription
- Resource group
- VNet con subnet
- ADLS Gen2 storage account
- Service Principal o Managed Identity

**Services usati:**
- VMs (compute)
- ADLS Gen2 (storage)
- Azure Database (Postgres/MySQL)
- AKS (Kubernetes per Data Services)

---

### 23.3 GCP Requirements

**Prerequisites:**
- GCP project
- VPC network
- GCS bucket per storage
- Service Account

**Services usati:**
- Compute Engine (VMs)
- GCS (storage)
- Cloud SQL (databases)
- GKE (Kubernetes per Data Services)

---

ðŸ‘‰ **Domanda tipica d'esame**
> CDP Public supporta AWS/Azure/GCP? â†’ **SÃ¬, tutti e tre**
> Serve VPC/VNet? â†’ **SÃ¬**

---

# PARTE 5: DEPLOY CDP PRIVATE CLOUD BASE (6 domande)

## 24. CDP Private Cloud Base â€“ System Requirements

### 24.1 Hardware Requirements

**Per production cluster:**
- Minimum 3 nodi (5+ raccomandati)
- CPU: 4+ core per nodo (8+ raccomandati)
- RAM: 16GB+ per nodo (32GB+ raccomandati)
- Disk: 
  - OS: 100GB+
  - Data: dipende da workload (TB+)
- Network: 10 Gigabit Ethernet (raccomandato)

---

### 24.2 OS supportati

**Operating Systems:**
- Red Hat Enterprise Linux (RHEL) 7.x, 8.x
- CentOS 7.x, 8.x
- Ubuntu 18.04, 20.04
- SUSE Linux Enterprise Server (SLES) 12, 15

---

### 24.3 Java supportati

**Java Providers:** (domanda campione esame)
- âœ… **Oracle JDK** 8, 11
- âœ… **OpenJDK** 8, 11
- âœ… **Azul Zulu JDK** 8, 11
- âŒ Closed JDK (non esiste)

ðŸ‘‰ **Domanda tipica d'esame** (domanda campione esame)
> Oracle JDK supportato? â†’ **SÃ¬**
> OpenJDK supportato? â†’ **SÃ¬**
> Azul/Zulu supportato? â†’ **SÃ¬**

---

### 24.4 Database supportati

**Databases per Metastore/Ranger:** (domanda campione esame)
- âœ… **PostgreSQL** 10, 11, 12
- âœ… **MySQL** 5.7, 8.0
- âœ… **MariaDB** 10.x
- âœ… **Oracle Database** 12c, 19c

ðŸ‘‰ **Domanda tipica d'esame** (domanda campione esame)
> PostgreSQL supportato? â†’ **SÃ¬**
> MS SQL Server supportato? â†’ **SÃ¬**
> Oracle DB supportato? â†’ **SÃ¬**
> MySQL supportato? â†’ **SÃ¬**

---

### 24.5 Networking

**Requirements:**
- Forward and reverse DNS
- NTP (Network Time Protocol) sincronizzato
- Firewall rules per comunicazione inter-nodi
- No conflitti di porte

---

# PARTE 6: CLOUDERA MANAGER (3 domande)

## 25. Cloudera Manager

### 25.1 Cos'Ã¨ Cloudera Manager

**Cloudera Manager** Ã¨ l'applicazione per **gestire, configurare e monitorare cluster CDP Private Cloud Base**.

**Architettura:**
```

Cloudera Manager Server
- Gira su un host dedicato
- Web UI + API REST
- Gestisce uno o piÃ¹ cluster

Cloudera Manager Agent
- Gira su ogni nodo del cluster
- Esegue comandi dal Server
- Invia metriche e heartbeat
```

---

### 25.2 Funzioni principali

**Configurazione:**
- Install/upgrade servizi (Hive, HDFS, YARN, ecc.)
- Configurazione centralizzata
- Rolling restart

**Monitoring:**
- Metriche real-time (CPU, disk, network)
- Health checks automatici
- Alerts e notifications

**Troubleshooting:**
- Log aggregation
- Diagnostics
- Performance tuning

---

### 25.3 Cloudera Manager e database

Cloudera Manager richiede un database esterno per:
- Configuration metadata
- Monitoring data
- User/role management

**Databases supportati:** (giÃ  visto sopra)
- PostgreSQL
- MySQL / MariaDB
- Oracle DB
- MS SQL Server

ðŸ‘‰ **Domanda tipica d'esame**
> Cloudera Manager gestisce cluster? â†’ **SÃ¬**
> Serve database? â†’ **SÃ¬**
> Dove gira? â†’ **Su host dedicato**

---

# PARTE 7: WORKLOAD XM (3 domande)

## 26. Workload XM

### 26.1 Cos'Ã¨ Workload XM

**Workload XM** Ã¨ uno strumento per **monitorare, analizzare e ottimizzare workload** su cluster CDP.

**Funzioni:**
- Understand workloads (Hive, Impala, Spark)
- Troubleshoot failed jobs
- Optimize slow queries
- Capacity planning
- Cost optimization

---

### 26.2 Workload XM caratteristiche

**Analisi:**
- Query performance analysis
- Resource utilization (CPU, memory, I/O)
- Baseline comparison
- Anomaly detection

**Recommendations:**
- Query optimization suggestions
- Configuration tuning
- Resource allocation

---

### 26.3 Telemetry Publisher e redaction

**Telemetry Publisher** raccoglie dati diagnostici e li invia a Workload XM.

**Dati sensibili - redaction supportata:** (domanda campione esame)
- âœ… **Log and query** text
- âœ… **MapReduce job properties**
- âœ… **Spark event and executor log**
- âŒ HBase users (non redactable in questo contesto)
- âŒ Kafka topics (non redactable in questo contesto)

ðŸ‘‰ **Domanda tipica d'esame** (domanda campione esame)
> Workload XM ottimizza query? â†’ **SÃ¬**
> Telemetry Publisher supporta redaction? â†’ **SÃ¬**
> Log and query possono essere redatti? â†’ **SÃ¬**

---

# PARTE 8: REPLICATION MANAGER (3 domande)

## 27. Replication Manager

### 27.1 Cos'Ã¨ Replication Manager

**Replication Manager** Ã¨ uno strumento per **replicare e migrare dati tra ambienti CDP**.

**Funzioni:**
- Copy HDFS data
- Replicate Hive external tables
- Backup HBase tables
- Disaster Recovery (DR)
- Cloud migration

---

### 27.2 Replication Manager â€“ Private Cloud

**Private Cloud:**
- Replica HDFS tra cluster CDP Private Cloud Base 7.1.8+
- Replica Hive external tables
- Replica Ozone data

---

### 27.3 Replication Manager â€“ Public Cloud

**Public Cloud:**
- Replica da CDH â†’ CDP Public Cloud
- Replica da CDP Private Cloud Base â†’ CDP Public Cloud
- Supporta HDFS, Hive, HBase
- Cloud storage (S3/ADLS/GCS) come destination

---

### 27.4 HDFS Replication Policies

**Requirements per replicare HDFS su cloud storage:** (domanda campione esame)
- âœ… **Register cloud credentials** in Replication Manager
- âœ… **Verify cluster access** e configure minimum ports
- âŒ Non serve configurare Hive (HDFS Ã¨ indipendente)
- âŒ Non Ã¨ vero che "works without configuration"

ðŸ‘‰ **Domanda tipica d'esame** (domanda campione esame)
> Cosa serve per HDFS replication su cloud? â†’ **Cloud credentials + cluster access**
> Serve configurare Hive? â†’ **No (HDFS â‰  Hive)**

---

# RIEPILOGO FINALE

## Distribuzione domande per topic

| Topic | Domande | Focus |
|-------|---------|-------|
| **Componenti CDP** | 15 | HDFS, Hive, Impala, YARN, Spark, Oozie, Kafka, NiFi, HBase, Kudu |
| **Sicurezza** | 12 | SDX, Ranger, Atlas, Knox, encryption, SSO, Kerberos |
| **Data Services** | 9 | CDE, CDW, COD, CML, CDF |
| **Deploy Public Cloud** | 9 | AWS, Azure, GCP, environment, credential |
| **Deploy Private Cloud** | 6 | System requirements, Java, DB, OS |
| **Cloudera Manager** | 3 | Gestione cluster, configurazione |
| **Workload XM** | 3 | Monitoring, optimization, telemetry |
| **Replication Manager** | 3 | Backup, DR, migration |

**Totale:** 60 domande  
**Pass Score:** 60% (36 domande corrette su 60)

---

## Strategie per l'esame

### âœ… Cosa memorizzare

1. **Tabelle comparative** (Hive vs Impala, MapReduce vs Spark, ecc.)
2. **Use cases specifici** (quando usare quale strumento)
3. **Domande campione** (Oozie supporta MiNiFi? â†’ No)
4. **Liste supportate** (Java providers, databases, cloud providers)
5. **Acronimi** (SDX, CDE, CDW, COD, CML, CDF, TDE, RBAC)

### âŒ Errori comuni da evitare

- Confondere Hive (batch) con Impala (interattivo)
- Pensare che Ranger faccia authentication (fa authorization)
- Credere che Atlas faccia security (fa governance/metadata)
- Confondere NiFi (data flow) con Kafka (messaging)
- Dimenticare che Hive e Impala condividono Metastore
- Non conoscere i database supportati da Cloudera Manager

### ðŸ“š Risorse da studiare

1. **Questo documento** (coverage completa 60 domande)
2. **CDP documentation** ufficiale (link per approfondimenti)
3. **Cloudera Essentials for CDP** (corso video)
4. **Hands-on experience** (importante per domande pratiche)

---

## Frasi chiave da memorizzare

> **Hive e Impala** condividono dati e Metastore, ma servono casi d'uso differenti.

> **SDX** Ã¨ l'architettura di sicurezza e governance integrata (Ranger + Atlas + Knox + Metastore).

> **COD** Ã¨ ideal per low-latency, highly scalable storage/retrieval (authentication, IoT).

> **Environment** Ã¨ un logical subset del cloud account con virtual network.

> **Oozie** Ã¨ un workflow scheduler che combina job sequenzialmente.

> **Workload XM** ottimizza workload e troubleshoota failed jobs.

> **Replication Manager** replica dati tra ambienti CDP (serve cloud credentials + cluster access).

---

### **Cos'Ã¨ lo Schema?**

Lo **schema** Ã¨ una definizione strutturale che descrive l'organizzazione e il formato dei dati in un sistema di gestione dei dati. Esso specifica come i dati sono strutturati, quali campi o colonne esistono, e quali tipi di dati sono associati a ciascun campo.

#### **Caratteristiche principali dello Schema:**
1. **Definizione della struttura:**
   - Specifica i campi (colonne) e i loro tipi di dati (es. stringa, intero, data).
   - Definisce le relazioni tra i dati (es. chiavi primarie, univocitÃ , ecc.) nei database relazionali.

2. **Tipi di Schema:**
   - **Schema-on-write:**
     - Lo schema Ã¨ definito prima che i dati vengano scritti nel sistema.
     - Richiede che i dati rispettino la struttura predefinita.
     - Utilizzato nei database relazionali (es. MySQL, PostgreSQL).
   - **Schema-on-read:**
     - Lo schema viene applicato solo al momento della lettura o dell'analisi dei dati.
     - Permette di gestire dati non strutturati o semi-strutturati.
     - Utilizzato in strumenti di big data come Hadoop e Hive.

3. **FlessibilitÃ :**
   - Nei sistemi relazionali, lo schema Ã¨ rigido e deve essere rispettato.
   - Nei sistemi non relazionali, lo schema puÃ² essere flessibile o assente.

4. **Esempi di Schema:**
   - **Database relazionale:**
     ```sql
     CREATE TABLE Clienti (
       ID INT PRIMARY KEY,
       Nome VARCHAR(50),
       Cognome VARCHAR(50),
       Email VARCHAR(100)
     );
     ```
     Questo schema definisce una tabella con colonne e tipi di dati specifici.
   - **Big Data (Hive):**
     ```sql
     CREATE EXTERNAL TABLE LogDati (
       Timestamp STRING,
       Messaggio STRING
     )
     STORED AS TEXTFILE;
     ```
     Questo schema viene applicato ai dati giÃ  esistenti in HDFS.

### **Esempio di Schema**

Uno schema definisce la struttura di una tabella, specificando i nomi delle colonne e i tipi di dati associati. Ecco un esempio:

```sql
CREATE TABLE employees (
    id INT,          -- Identificativo univoco
    name STRING,     -- Nome del dipendente
    salary DECIMAL   -- Stipendio
);
```

#### **Dettagli dello schema:**
- **`id INT`**: Colonna `id` con tipo di dato intero (integer).
- **`name STRING`**: Colonna `name` con tipo di dato stringa (testo).
- **`salary DECIMAL`**: Colonna `salary` con tipo di dato decimale (numerico con precisione).

#### **Cosa rappresenta uno schema?**
- Lo schema Ã¨ la **struttura logica** di una tabella.
- Specifica:
  1. **Nomi delle colonne** (es. `id`, `name`, `salary`).
  2. **Tipi di dati** (es. `INT`, `STRING`, `DECIMAL`).
  3. (Opzionale) **Vincoli** come chiavi primarie, univocitÃ , ecc.

#### **Nota per l'esame CDP:**
- Ogni tabella in Hive o SQL richiede uno schema.
- Lo schema Ã¨ obbligatorio per definire come i dati vengono archiviati e interrogati.

#### **PerchÃ© lo Schema Ã¨ Importante?**
- **Organizzazione:** Permette di dare struttura ai dati, rendendoli piÃ¹ facili da interrogare e analizzare.
- **Validazione:** Garantisce che i dati rispettino determinati vincoli (es. tipi di dati corretti).
- **Governance:** Aiuta a mantenere coerenza e integritÃ  nei sistemi di gestione dei dati.

---

In sintesi, lo schema Ã¨ il "progetto" che descrive come i dati sono organizzati e strutturati in un sistema, influenzando il modo in cui vengono archiviati, letti e analizzati.

---

# Chiave primaria e chiave esterna

## Introduzione

In un database, lâ€™organizzazione, lâ€™identificazione e la coerenza dei dati dipendono sia dal **modello di database adottato** sia dallâ€™uso corretto di **chiavi** e **metadati**.

In questo documento vengono spiegati:

* chiave primaria e chiave esterna nei database relazionali
* come vengono identificate tabelle e record
* le differenze tra **database relazionali (RDBMS)** e **non relazionali (NoSQL)**
* il collegamento con i sistemi **Big Data** come Hive

---

## Differenza tra database relazionali e non relazionali

### Database relazionali (RDBMS)

I database relazionali (**Relational Database Management System**) organizzano i dati in **tabelle** composte da **righe (record)** e **colonne (attributi)**, seguendo uno **schema fisso** definito a priori.

Ogni tabella:

* rappresenta unâ€™**entitÃ ** del dominio applicativo
* Ã¨ identificata dal **nome della tabella allâ€™interno di uno schema**
* utilizza una **chiave primaria** per identificare univocamente i record
* puÃ² essere collegata ad altre tabelle tramite **chiavi esterne**

Le relazioni tra tabelle sono **esplicite** e il database garantisce la coerenza dei dati tramite le proprietÃ  **ACID**:

* **AtomicitÃ **
* **Consistenza**
* **Isolamento**
* **DurabilitÃ **

ðŸ“Œ Esempi di RDBMS:

* MySQL
* PostgreSQL
* Oracle

Si chiamano database relazionali perchÃ© organizzano i dati in tabelle che possono essere messe in relazione tra loro tramite chiavi (primarie e esterne). Il termine â€œrelazionaleâ€ deriva dal concetto matematico di â€œrelazioneâ€, che in questo contesto indica una tabella composta da righe e colonne. Le relazioni tra le tabelle permettono di collegare e integrare dati diversi in modo strutturato e coerente.

---

### Database non relazionali (NoSQL)

I database non relazionali (**NoSQL**) non si basano sul modello tabellare classico e **non richiedono uno schema rigido**. Sono progettati per gestire **grandi volumi di dati**, **alta scalabilitÃ  orizzontale** e dati **semi-strutturati o non strutturati**.

Non utilizzano chiavi esterne formali e le relazioni tra dati sono spesso:

* incorporate nei dati stessi
* oppure gestite a livello applicativo

I principali modelli NoSQL sono:

* **Documentali** (es. MongoDB)
  I dati sono memorizzati come documenti JSON/BSON. Ogni documento ha un identificatore univoco (es. `_id`), simile a una chiave primaria, ma senza vincoli relazionali.

* **Key-Value** (es. Redis)
  I dati sono coppie chiaveâ€“valore. Il modello Ã¨ estremamente veloce, ma non supporta relazioni strutturate.

* **A colonne** (es. Cassandra, HBase)
  I dati sono organizzati per colonne e partizioni. Ãˆ adatto a grandi volumi e carichi distribuiti.

* **A grafo** (es. Neo4j)
  I dati sono nodi e relazioni esplicite, ideali per rappresentare reti complesse (social network, recommendation system).

---

### Confronto sintetico RDBMS vs NoSQL

| Aspetto           | Database relazionali            | Database NoSQL                           |
| ----------------- | ------------------------------- | ---------------------------------------- |
| Modello dati      | Tabelle (righe/colonne)         | Documenti, key-value, colonne, grafi     |
| Schema            | Rigido                          | Flessibile o assente                     |
| Chiave primaria   | SÃ¬ (vincolo reale)              | Identificatore univoco                   |
| Chiave esterna    | SÃ¬                              | No                                       |
| Coerenza          | Forte (ACID)                    | Eventuale (BASE)                         |
| ScalabilitÃ        | Verticale                       | Orizzontale                              |
| Caso dâ€™uso tipico | Transazioni, sistemi gestionali | Big Data, analytics, sistemi distribuiti |

---

## Cosâ€™Ã¨ una tabella

Una **tabella** rappresenta unâ€™**entitÃ ** del mondo reale (ad esempio: Studente, Cliente, Ordine).
Ãˆ composta da:

* **righe (record)** â†’ singole istanze dellâ€™entitÃ 
* **colonne (attributi)** â†’ caratteristiche dellâ€™entitÃ 

### Identificazione di una tabella

Una tabella **non Ã¨ identificata dalla chiave primaria**.

ðŸ‘‰ **La tabella Ã¨ identificata dal suo nome allâ€™interno di uno schema (o database).**

Formalmente, lâ€™identificatore univoco di una tabella Ã¨:

```
(schema, nome_tabella)
```

Questo significa che due tabelle possono avere lo stesso nome se appartengono a schemi diversi.

### Esempio

```
public.studente
didattica.studente
```

Queste due tabelle:

* hanno lo stesso nome (`studente`)
* appartengono a schemi diversi
* sono **tabelle distinte**

---

## Chiave primaria (Primary Key)

### Definizione

La **chiave primaria** Ã¨ un attributo (o un insieme di attributi) che **identifica univocamente ogni record di una tabella**.

ðŸ‘‰ **La chiave primaria identifica un record, non la tabella.**

### ProprietÃ  fondamentali

Una chiave primaria deve essere:

* **Univoca** (nessun duplicato)
* **Non nulla** (NOT NULL)
* **Stabile** (non dovrebbe cambiare nel tempo)

PuÃ² essere:

* **Semplice** â†’ una sola colonna
* **Composta** â†’ piÃ¹ colonne insieme

---

## Esempio pratico: chiave primaria

### Tabella STUDENTE

| matricola (PK) | nome  | cognome |
| -------------- | ----- | ------- |
| 12345          | Mario | Rossi   |
| 12346          | Luca  | Bianchi |

* `matricola = 12345` identifica **Mario Rossi**
* `matricola = 12346` identifica **Luca Bianchi**

---

## Chiave esterna (Foreign Key)

### Definizione

La **chiave esterna** Ã¨ un attributo di una tabella che fa riferimento alla **chiave primaria di unâ€™altra tabella**.

Serve a:

* collegare dati tra tabelle diverse
* garantire lâ€™**integritÃ  referenziale**

ðŸ‘‰ Un valore di chiave esterna **deve corrispondere a una chiave primaria esistente**.

---

## Esempio pratico: chiave primaria e chiave esterna

### Tabella CLIENTE

| id_cliente (PK) | nome  |
| --------------- | ----- |
| 10              | Anna  |
| 11              | Paolo |

### Tabella ORDINE

| id_ordine (PK) | data       | id_cliente (FK) |
| -------------- | ---------- | --------------- |
| 501            | 2026-01-10 | 10              |
| 502            | 2026-01-12 | 10              |
| 503            | 2026-01-13 | 11              |

* `id_cliente` Ã¨ **PK** in CLIENTE
* `id_cliente` Ã¨ **FK** in ORDINE
* ogni ordine Ã¨ associato a un cliente esistente

---

## Rappresentazione grafica concettuale

```
CLIENTE (1) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€< ORDINE (N)
```

* una riga di CLIENTE puÃ² essere collegata a molte righe di ORDINE
* la relazione Ã¨ realizzata tramite la chiave esterna

---

## Chiave primaria composta

In alcuni casi, una singola colonna non Ã¨ sufficiente a identificare un record.

### Esempio: ISCRIZIONE_ESAME

| matricola | id_esame |
| --------- | -------- |
| 12345     | 1        |
| 12345     | 2        |
| 12346     | 1        |

Qui la chiave primaria Ã¨ **composta**:

```
PK = (matricola, id_esame)
```

Questa coppia identifica univocamente una singola iscrizione.

---

## Confronto con database non relazionali (NoSQL)

Nei database NoSQL:

* esiste solitamente un **identificatore univoco** del dato (es. `_id` in MongoDB)
* **non esistono chiavi esterne formali**
* le relazioni sono gestite dallâ€™applicazione o tramite strutture annidate

### Esempio MongoDB

```
{
  _id: "u1",
  nome: "Anna",
  ordini: [501, 502]
}
```

* `_id` svolge un ruolo simile alla chiave primaria
* le relazioni non sono vincolate dal database

---

## Schema gerarchico di identificazione

```
Database
 â””â”€â”€ Schema
      â””â”€â”€ Tabella
           â””â”€â”€ Record (riga)
```

* **Database** â†’ identificato dal suo nome
* **Schema** â†’ identificato dal suo nome allâ€™interno del database
* **Tabella** â†’ identificata dalla coppia *(schema, nome_tabella)*
* **Record** â†’ identificato dalla **chiave primaria**

---

## Confronto: chiave primaria vs nome della tabella

| Aspetto                | Chiave primaria (PK)                    | Nome della tabella                     |
| ---------------------- | --------------------------------------- | -------------------------------------- |
| Cosa identifica        | Un **record (riga)**                    | Una **tabella**                        |
| Ambito                 | Interno alla tabella                    | Allâ€™interno di uno **schema/database** |
| UnicitÃ                 | Deve essere **univoca** per ogni record | Deve essere univoco nello schema       |
| PuÃ² cambiare?          | No (o fortemente sconsigliato)          | SÃ¬ (rinomina tabella)                  |
| Serve per le relazioni | SÃ¬ (referenziata dalle FK)              | No                                     |
| Esempio                | `id_cliente = 10`                       | `public.cliente`                       |

ðŸ‘‰ **Errore comune da evitare**: pensare che la chiave primaria identifichi la tabella.

---

## Collegamento a Hive Metastore e Big Data

Nei sistemi Big Data basati su **Hive** (e piÃ¹ in generale su Hadoop/Cloudera), i concetti di database e tabella esistono ancora, ma il ruolo delle chiavi cambia.

### Hive Metastore

Il **Hive Metastore** Ã¨ il servizio che mantiene i **metadati** delle tabelle, tra cui:

* database
* nome della tabella
* colonne e tipi di dato
* partizioni
* percorso fisico dei dati su HDFS o Object Storage

ðŸ“Œ In Hive:

* una tabella Ã¨ identificata da **(database, nome_tabella)**
* esattamente come negli RDBMS con *(schema, nome_tabella)*

### Gerarchia in Hive

```
Hive Metastore
 â””â”€â”€ Database
      â””â”€â”€ Table
           â””â”€â”€ Partition (opzionale)
                â””â”€â”€ File / Record
```

### Chiavi primarie in Hive

* Hive **supporta sintatticamente** PRIMARY KEY e FOREIGN KEY
* **non sono vincoli applicati** (non viene garantita lâ€™unicitÃ )
* servono principalmente per:

  * documentazione del modello dati
  * ottimizzazioni del query planner
  * integrazione con strumenti di BI

ðŸ‘‰ In Hive:

> **la chiave primaria non garantisce lâ€™unicitÃ  dei record**, ma descrive lâ€™intenzione logica del modello.

### Confronto RDBMS vs Hive

| Aspetto                | RDBMS                  | Hive / Big Data            |
| ---------------------- | ---------------------- | -------------------------- |
| IdentitÃ  tabella       | (schema, nome)         | (database, nome)           |
| PK applicata           | SÃ¬ (vincolo reale)     | No (solo metadato)         |
| FK applicata           | SÃ¬                     | No                         |
| IntegritÃ  referenziale | Garantita              | Demandata allâ€™applicazione |
| Focus                  | Coerenza transazionale | Analisi su grandi volumi   |

### Collegamento concettuale chiave

* **RDBMS** â†’ PK/FK = vincoli forti
* **Hive/Big Data** â†’ PK/FK = informazione logica
* **Metastore** â†’ â€œcatalogoâ€ delle tabelle, non dei record

-------|----------------------|-------------------|
| Cosa identifica | Un **record (riga)** | Una **tabella** |
| Ambito | Interno alla tabella | Allâ€™interno di uno **schema/database** |
| UnicitÃ  | Deve essere **univoca** per ogni record | Deve essere univoco nello schema |
| PuÃ² cambiare? | No (o fortemente sconsigliato) | SÃ¬ (rinomina tabella) |
| Serve per le relazioni | SÃ¬ (referenziata dalle FK) | No |
| Esempio | `id_cliente = 10` | `public.cliente` |

ðŸ‘‰ **Errore comune da evitare**: pensare che la chiave primaria identifichi la tabella.

---

## Quando scegliere RDBMS, NoSQL o Hive

La scelta tra **database relazionali**, **NoSQL** e **Hive/Big Data** dipende principalmente dal **tipo di dati**, dal **carico di lavoro** e dai **requisiti di coerenza e scalabilitÃ **.

---

### Quando scegliere un database relazionale (RDBMS)

Scegli un **RDBMS** quando:

* i dati sono **altamente strutturati**
* lo schema Ã¨ **stabile nel tempo**
* sono richieste **transazioni affidabili**
* lâ€™integritÃ  dei dati Ã¨ **critica**

ðŸ“Œ Casi dâ€™uso tipici:

* sistemi gestionali (ERP, CRM)
* contabilitÃ  e fatturazione
* sistemi bancari e finanziari
* applicazioni OLTP

ðŸ‘‰ PerchÃ©: PK e FK garantiscono **coerenza forte** e **integritÃ  referenziale**.

---

### Quando scegliere un database NoSQL

Scegli un **NoSQL** quando:

* i dati sono **eterogenei o semi-strutturati**
* lo schema cambia frequentemente
* Ã¨ richiesta **alta scalabilitÃ  orizzontale**
* le prestazioni sono piÃ¹ importanti della coerenza immediata

ðŸ“Œ Casi dâ€™uso tipici:

* applicazioni web ad alto traffico
* caching e session management (Redis)
* IoT e time series
* sistemi distribuiti globali

ðŸ‘‰ PerchÃ©: maggiore **flessibilitÃ ** e **scalabilitÃ **, accettando coerenza eventuale.

---

### Quando scegliere Hive / Big Data

Scegli **Hive** (o sistemi Big Data simili) quando:

* i dati sono **molto voluminosi** (Big Data)
* il carico Ã¨ principalmente **analitico** (OLAP)
* non servono transazioni riga-per-riga
* lâ€™obiettivo Ã¨ lâ€™analisi storica e batch

ðŸ“Œ Casi dâ€™uso tipici:

* data warehouse
* data lake
* reportistica e BI
* analisi su grandi dataset storici

ðŸ‘‰ PerchÃ©: Hive separa **storage e compute** e scala su grandi volumi, ma non applica vincoli PK/FK.

---

### Confronto decisionale rapido

| Esigenza                | Tecnologia consigliata |
| ----------------------- | ---------------------- |
| Transazioni critiche    | RDBMS                  |
| Schema flessibile       | NoSQL                  |
| Altissimo volume dati   | Hive / Big Data        |
| IntegritÃ  referenziale  | RDBMS                  |
| ScalabilitÃ  orizzontale | NoSQL / Hive           |
| Analytics e BI          | Hive                   |

---

## Riassunto finale

* **La tabella rappresenta unâ€™entitÃ **
* **La chiave primaria identifica un record della tabella**
* **La chiave esterna collega record di tabelle diverse**
* Nei database relazionali, PK e FK garantiscono coerenza e integritÃ  dei dati

ðŸ‘‰ Frase chiave da ricordare:

> *La chiave primaria identifica univocamente una riga di una tabella; la chiave esterna realizza le relazioni tra tabelle.*

---

## Chiave primaria nei database non relazionali

Nei database non relazionali, il concetto di chiave primaria esiste ma puÃ² essere diverso rispetto ai database relazionali:
- Nei database documentali (es. MongoDB), ogni documento ha un identificatore unico (di solito il campo _id), che svolge il ruolo di chiave primaria.
- Nei database key-value, la â€œchiaveâ€ Ã¨ sempre unica e identifica il valore associato.
- Nei database a colonne (es. Cassandra), si usano chiavi primarie composte per identificare in modo univoco le righe.
- Nei database a grafo, i nodi e le relazioni hanno identificatori unici.

Quindi, anche nei database non relazionali esiste un meccanismo per identificare univocamente i dati, ma la gestione e la struttura possono variare a seconda del modello.
