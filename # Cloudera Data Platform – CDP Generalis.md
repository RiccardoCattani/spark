# INTRODUZIONE: STORIA DI CLOUDERA E EVOLUZIONE VERSO CDP

## Pre-Cloudera: Il contesto tecnologico (2003-2008)

### Tecnologie pre-big data

Prima dell'avvento di Hadoop e Cloudera, il panorama del data management era dominato da soluzioni tradizionali.

**Data Warehouse tradizionali (anni '90-2000):**
- **Oracle Database** - leader enterprise RDBMS
- **IBM DB2** - mainframe e enterprise
- **Teradata** - appliance per analytics
- **Microsoft SQL Server** - piattaforma Windows

**Limitazioni critiche:**
- ‚ùå **Scalabilit√† verticale** - solo scale-up, hardware costoso
- ‚ùå **Gestione dati non strutturati** - difficile gestire log, testo come documenti articoli e commenti sui social media
- ‚ùå **Costi proibitivi** - milioni di dollari per petabyte
- ‚ùå **Schema rigido** - schema-on-write, no flessibilit√†
- ‚ùå **Vendor lock-in** - dipendenza da fornitori proprietari

## Differenza tra dati relazionali e non relazionali

### **Dati Relazionali**
I dati relazionali sono organizzati in un formato strutturato, seguendo uno schema rigido.

#### **Caratteristiche principali:**
1. **Struttura**:
   - Organizzati in tabelle con righe e colonne.
   - Ogni tabella ha uno schema predefinito (schema-on-write).
   - Le relazioni tra i dati sono definite tramite chiavi primarie e chiavi esterne.

2. **Esempi di dati**:
   - Informazioni su clienti (nome, cognome, email, telefono).
   - Transazioni finanziarie (ID transazione, importo, data).
   - Inventari di prodotti (ID prodotto, quantit√†, prezzo).

3. **Database relazionali (RDBMS)**:
   - MySQL, PostgreSQL, Oracle Database, Microsoft SQL Server.

4. **Vantaggi**:
   - **Integrit√† dei dati**: Garantita da vincoli (es. chiavi primarie, univocit√†).
   - **Query potenti**: Linguaggio SQL per interrogare i dati.
   - **Adatto a dati strutturati**: Ideale per applicazioni aziendali tradizionali.

5. **Svantaggi**:
   - **Scalabilit√† verticale**: Difficile scalare orizzontalmente (richiede hardware pi√π potente).
   - **Schema rigido**: Cambiare lo schema pu√≤ essere complesso.
   - **Non adatto a dati non strutturati**: Come immagini, video, log.

---

### **Dati Non Relazionali**
I dati non relazionali sono pi√π flessibili e non seguono uno schema rigido.

#### **Caratteristiche principali:**
1. **Struttura**:
   - Non organizzati in tabelle (IMP).
   - Possono essere archiviati in formati come documenti, grafi, colonne o chiavi-valori.
   - Schema dinamico o assente (schema-on-read).

2. **Esempi di dati**:
   - Log di sistema (timestamp, messaggio di errore).
   - Post sui social media (testo, immagini, video).
   - Dati IoT (sensori, eventi in tempo reale).

3. **Database non relazionali (NoSQL)**:
   - MongoDB (documenti), Cassandra (colonne), Redis (chiavi-valori), Neo4j (grafi).

4. **Vantaggi**:
   - **Scalabilit√† orizzontale**: Aggiungere nodi per gestire pi√π dati.
   - **Flessibilit√†**: Adatto a dati non strutturati o semi-strutturati.
   - **Performance**: Ottimizzato per specifici casi d'uso (es. letture/scritture rapide).

5. **Svantaggi**:
   - **Meno consistenza**: Non sempre garantisce transazioni ACID.
   - **Query limitate**: Non sempre supporta SQL.
   - **Meno adatto a dati strutturati**: Non ideale per applicazioni tradizionali.

---

HDFS (Hadoop Distributed File System) non √® un database relazionale. √à un file system distribuito progettato per archiviare grandi quantit√† di dati su cluster di computer. HDFS gestisce file e directory, non tabelle relazionali, e non impone uno schema rigido ai dati. Quindi, HDFS √® considerato un sistema di archiviazione non relazionale.
Hive e Impala non sono database relazionali in senso stretto, ma sono motori di query che permettono di eseguire interrogazioni SQL su dati archiviati in HDFS (o altri file system distribuiti). Tuttavia, forniscono un‚Äôinterfaccia relazionale: i dati sono organizzati in tabelle e si usa SQL per interrogarli, quindi si comportano come sistemi relazionali dal punto di vista dell‚Äôutente, pur non essendo veri e propri RDBMS tradizionali.

La differenza principale tra database e filesystem √® la seguente:

Un filesystem gestisce l‚Äôarchiviazione e l‚Äôorganizzazione di file e cartelle su un disco. Permette di salvare, leggere, modificare e cancellare file, ma non offre funzionalit√† avanzate per la gestione strutturata dei dati.
Un database, invece, √® progettato per archiviare, organizzare e gestire dati strutturati (ad esempio, in tabelle) e offre funzionalit√† come query, transazioni, integrit√† dei dati e sicurezza. Permette di cercare e manipolare i dati in modo efficiente tramite linguaggi come SQL.
In sintesi: il filesystem gestisce file, il database gestisce dati strutturati.


### **Confronto Tabellare**

| **Caratteristica**       | **Relazionale**                     | **Non Relazionale**               |
|---------------------------|-------------------------------------|----------------------------------|
| **Struttura**             | Tabelle (righe e colonne)          | Documenti, grafi, colonne, chiavi-valori |
| **Schema**                | Rigido (schema-on-write)*           | Flessibile (schema-on-read)       |
| **Scalabilit√†**           | Verticale                          | Orizzontale                       |
| **Adatto per**            | Dati strutturati                   | Dati non strutturati/semi-strutturati |
| **Esempi di database**    | MySQL, PostgreSQL, Oracle          | MongoDB, Cassandra, Neo4j         |
| **Query**                 | SQL                                | API specifiche o linguaggi NoSQL  |

* "Schema rigido on write" significa che, quando si scrivono dati in un database, questi devono rispettare una struttura (schema) predefinita e obbligatoria. Ogni record deve avere i campi, i tipi di dati e le regole stabilite dallo schema, altrimenti la scrittura viene rifiutata

In pratica:
- Prima di inserire dati, lo schema (ad esempio tabelle e colonne in SQL) deve essere gi√† definito.
- Non puoi aggiungere dati con campi diversi o mancanti rispetto allo schema.
- Questo garantisce coerenza e integrit√† dei dati, ma riduce la flessibilit√† rispetto a sistemi con schema dinamico (come MongoDB).

---

In sintesi, i dati relazionali sono ideali per applicazioni aziendali tradizionali con dati strutturati, mentre i dati non relazionali sono pi√π adatti per scenari moderni che richiedono flessibilit√† e scalabilit√†.

---

### **Concetto fondamentale: Database vs Schema**

#### **Spesso confusi, ma sono diversi:**

**Database (DB):**
- √à l'**intero contenitore** di dati e metadati
- √à il **livello pi√π alto di organizzazione**
- Raggruppa pi√π tabelle correlate (namespace Hive)
- Esempio: `hive_warehouse`, `analytics_db`

**Schema:**
- √à la **struttura** di una singola tabella
- Definisce colonne, tipi di dati, vincoli
- √à l'**intestazione** di una tabella
- Esempio: `(id INT, name STRING, salary DECIMAL)`

#### **Analogia visiva:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Database: hive_warehouse               ‚îÇ  ‚Üê Intero cassetto
‚îÇ                                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Table: employees                  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Schema: id INT, name STRING,      ‚îÇ ‚îÇ  ‚Üê Struttura colonne
‚îÇ  ‚îÇ         salary DECIMAL            ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Data (rows):                      ‚îÇ ‚îÇ  ‚Üê Dati effettivi
‚îÇ  ‚îÇ 1, John, 50000                    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ 2, Jane, 60000                    ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Table: departments                ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Schema: dept_id INT,              ‚îÇ ‚îÇ
‚îÇ  ‚îÇ         dept_name STRING          ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### **In SQL/Hive:**

```sql
-- Creare un DATABASE (contenitore)
CREATE DATABASE hive_warehouse;

-- Creare una TABELLA con SCHEMA definito (struttura)
CREATE TABLE hive_warehouse.employees (
    id INT,                    -- ‚Üì Questo √® lo SCHEMA
    name STRING,               -- Definisce la struttura
    salary DECIMAL             -- della tabella
);

-- Inserire DATA (dati effettivi)
INSERT INTO employees VALUES (1, 'John', 50000);
```

#### **Differenze chiave:**

| **Aspetto**        | **Database**                      | **Schema**                          |
|-------------------|-----------------------------------|-------------------------------------|
| **Cos'√®?**        | Contenitore/namespace            | Struttura di una singola tabella    |
| **Livello**       | Alto (raggruppa tabelle)         | Basso (singola tabella)             |
| **Comando SQL**   | `CREATE DATABASE mydb;`          | `CREATE TABLE mydb.mytable (...)`  |
| **Contiene**      | Molteplici tabelle               | Definizione colonne + tipi + vincoli |
| **Esempio**       | `analytics_db`, `sales_db`       | `(id INT, name STRING, date DATE)` |
| **Modifica**      | Raro (cambio struttura db)       | Pi√π frequente (ALTER TABLE)        |

#### **Nel contesto Cloudera/Hive:**

- **Hive Database** = Namespace che raggruppa tabelle correlate
  ```sql
  CREATE DATABASE sales;  -- database per dati vendite
  CREATE TABLE sales.transactions (...);
  CREATE TABLE sales.customers (...);
  ```

- **Hive Schema** = Definizione della tabella (colonne + tipi)
  ```sql
  CREATE TABLE sales.transactions (
      transaction_id INT,
      customer_id INT,
      amount DECIMAL(10,2),
      transaction_date DATE
  );
  -- ‚Üë Questa √® la struttura (schema) della tabella
  ```

#### **Per l'esame CDP:**

‚ö†Ô∏è Assicurati di capire:
- **Database**: namespace logico che organizza tabelle correlate
- **Schema**: la struttura fisica di una tabella (colonne + tipi)
- **Metastore Hive**: dove vengono archiviati i metadati (info su database e schema)
- **Atlas**: catalogo che documenta database, schema, lineage, ownership

---

### Google: La rivoluzione (2003-2004)

#### **Timeline chiara: Da Google a Hadoop**

**2003‚Äì2004: Google pubblica i paper rivoluzionari**

**Google File System (GFS) - 2003**
Google pubblic√≤ un paper rivoluzionario sul **Google File System**.

**‚ö†Ô∏è Importante:** Nel 2003 **Hadoop non esisteva ancora**. Non si "parlava di Hadoop" mentre Google creava GFS.

**Problemi che GFS risolveva:**
- Storage distribuito su migliaia di server commodity
- Fault tolerance automatica
- Alta throughput per grandi file
- Gestione petabyte di dati web

**Paper:** "The Google File System" - Ghemawat, Gobioff, Leung (SOSP 2003)


**MapReduce (Google, 2004)**
- Google pubblica il paper "MapReduce: Simplified Data Processing on Large Clusters" (Dean, Ghemawat).
- Concetti chiave:
   - Map: elaborazione parallela dei dati
   - Reduce: aggregazione dei risultati
   - Scalabilit√† lineare: pi√π nodi = pi√π performance
   - Fault tolerance: retry automatico dei task falliti
- Google non rilascia codice open source, solo paper.

**2005‚Äì2006: Nasce Hadoop**
- Doug Cutting (su Apache Nutch) crea l‚Äôimplementazione open source ispirata ai paper di Google:
   - HDFS (da GFS)
   - MapReduce (da Google MapReduce)
- Nel 2003 non esisteva Hadoop, ma si discutevano gi√† i problemi di Big Data e scalabilit√†.
- GFS (Google File System) viene prima (2003), Hadoop nasce dopo (2006) come reimplementazione open source.

**Apache Hadoop: La nascita 2006**
- Doug Cutting e Mike Cafarella (ex Yahoo!) implementano Hadoop per creare un motore di ricerca web scalabile.
- Nome "Hadoop": elefante di peluche del figlio di Doug Cutting.
- Componenti iniziali: HDFS e MapReduce.
- 2006: Hadoop come sottoprogetto di Apache Nutch.
- 2008: Hadoop diventa progetto Apache top-level.

Def. attuale di Hadoop:  √® un framework open source per l‚Äôarchiviazione e l‚Äôelaborazione distribuita di grandi quantit√† di dati (Big Data) su cluster di computer. √à composto principalmente da:

HDFS (Hadoop Distributed File System): file system distribuito che memorizza i dati su pi√π nodi.
MapReduce: modello di programmazione per elaborare dati in parallelo.
Altri componenti: YARN (gestione delle risorse), Hive, Pig, ecc.
---

### Yahoo!: Il primo grande utilizzatore (2006-2008)

**Yahoo! assunse Doug Cutting nel 2006** per sviluppare Hadoop internamente.

**Motivi:**
- Indicizzare miliardi di pagine web
- Competere con Google nella ricerca web
- Ridurre costi infrastrutturali

**Investimenti Yahoo! in Hadoop:**
- Team dedicato di sviluppo
- Cluster da migliaia di nodi
- Contributi open source massicci
- Test in produzione su scala web

**Risultato:** Yahoo! dimostr√≤ che Hadoop poteva scalare a livelli enterprise.

---

### Facebook: Big data sociale (2007-2008)

**Facebook** inizi√≤ ad usare Hadoop per analytics sui dati utenti.

**Contributi di Facebook:**
- **Apache Hive** (2008) - SQL su Hadoop
- Processing di log massivi
- Analytics comportamentali utenti
- Data warehouse distribuito

**Jeff Hammerbacher** (co-fondatore di Cloudera) era il data team lead di Facebook.

---

### Il problema che Hadoop risolse

**Prima di Hadoop (2003-2006):**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Aziende con big data (Google, Yahoo!)   ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ Opzioni:                                ‚îÇ
‚îÇ 1. Build custom distributed systems     ‚îÇ
‚îÇ    ‚Üí Costi: milioni $, anni sviluppo    ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ 2. Buy expensive appliance              ‚îÇ
‚îÇ    ‚Üí Costi: $$$, no flessibilit√†        ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ 3. Non fare analytics                   ‚îÇ
‚îÇ    ‚Üí Perdere insights business          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Dopo Hadoop (2006-2008):**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Hadoop open source                      ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ ‚úÖ Commodity hardware (economico)       ‚îÇ
‚îÇ ‚úÖ Scalabilit√† orizzontale infinita     ‚îÇ
‚îÇ ‚úÖ Fault tolerance nativa               ‚îÇ
‚îÇ ‚úÖ Open source (no vendor lock-in)      ‚îÇ
‚îÇ ‚úÖ Dati non strutturati (log, testo)    ‚îÇ
‚îÇ ‚úÖ Schema-on-read (flessibilit√†)        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

### La sfida: Hadoop era difficile (2006-2008)

**Problemi di Hadoop "raw":**
- ‚ùå No gestione centralizzata (manuale)
- ‚ùå Installazione complessa
- ‚ùå Security minima (no autenticazione/autorizzazione)
- ‚ùå No monitoring/alerting
- ‚ùå No supporto enterprise
- ‚ùå Solo per esperti Linux/Java
- ‚ùå No governance/auditing

**Opportunit√† per Cloudera:**
Rendere Hadoop **enterprise-ready** con:
- Manager centralizzato
- Distribuzione pacchettizzata
- Security integrata
- monitoring/alerting
- Supporto professionale
- Governance e compliance

---

## 0.0 Come √® nata Cloudera

### 0.0.1 Le origini (2008)

**Cloudera** √® stata fondata nel 2008 da:
- Doug Cutting (creatore di Hadoop)
- Christophe Bisciglia (ex-Google)
- Amr Awadallah (ex-Yahoo!)
- Jeff Hammerbacher (ex-Facebook)

**Missione originale:** commercializzare Apache Hadoop e renderlo enterprise-ready.

---

## 0.1 Prima di CDP: CDH e HDP

### 0.1.1 Cloudera Distribution for Hadoop (CDH)

**CDH** (2009-2020) era la distribuzione Hadoop di Cloudera.

**Caratteristiche:**
- Componenti: Hadoop, HDFS, MapReduce, YARN, Hive, Impala, HBase, Spark
- Versioni: CDH 4, CDH 5, CDH 6
- Manager: Cloudera Manager (GUI per gestione cluster)
- Security: Cloudera Navigator (audit/lineage), Sentry (authorization)
- Deployment: on-premise (bare metal)

**Limitazioni:**
- Solo on-premise
- Architettura monolitica
- Scaling verticale/orizzontale limitato
- Sicurezza frammentata (tool separati)

---

### 0.1.2 Hortonworks Data Platform (HDP)

**Hortonworks** (fondata 2011) era il competitor principale di Cloudera.

**HDP** caratteristiche:
- 100% open source (no codice proprietario)
- Componenti: Hadoop, YARN, Hive, HBase, Kafka, Storm, Ranger, Atlas
- Manager: Ambari (GUI cluster management)
- Security: Ranger (authorization), Knox (gateway), Atlas (metadata)
- Philosophy: "enterprise Hadoop without vendor lock-in"

**Differenze CDH vs HDP:**

| Aspetto | CDH (Cloudera) | --------------------------| HDP (Hortonworks) |
|---------|----------------|-------------------------- |-------------------|
| Filosofia | Enterprise + alcune feature proprietarie | 100% open source |
| SQL Engine | Impala (proprietario, veloce)           | Hive + Tez |
| Manager | Cloudera Manager                           | Ambari |
| Security | Sentry + Navigator                        | Ranger + Knox + Atlas |
| Target | Enterprise con budget                       | Open source enthusiast |
| Support | Subscription commerciale                   | Subscription + community |

---

## 0.2 La fusione Cloudera (CDH) + Hortonworks (HDP) (2019)

### 0.2.1 Merger announcement (Ottobre 2018)

**Motivo della fusione:**
- Competizione cloud (AWS, Azure, GCP stavano dominando)
- Necessit√† di unire forze contro cloud provider
- Combinare best-of-breed di entrambe le piattaforme

**Nuovo nome:** Cloudera (mantiene il brand)

**Valore:** ~$5.2 miliardi USD

---

### 0.2.2 Cosa √® cambiato dopo la fusione

‚úÖ **Combinazione tecnologie:**
- Impala (da CDH) + Ranger/Atlas (da HDP)
- Cloudera Manager + features di Ambari
- Best security/governance di entrambe

‚úÖ **Nuova vision:**
- Hybrid/multi-cloud (non solo on-premise)
- Enterprise Data Cloud
- Data lifecycle completo (ingest ‚Üí process ‚Üí serve ‚Üí protect)

---

## 0.3 Nascita di CDP (Cloudera Data Platform)

### 0.3.1 Lancio CDP (2019-2020)

**CDP** √® la piattaforma unificata che sostituisce CDH e HDP (Che prima erano unite).

**Novit√† rispetto a CDH/HDP:**
- ‚úÖ **Hybrid cloud** (on-premise + AWS + Azure + GCP)
- ‚úÖ **SDX integrato** (Shared Data Experience: security + governance unificate)
- ‚úÖ **Containerizzazione** (Kubernetes per Data Services)
- ‚úÖ **Separation of storage and compute** (invece di tight coupling)
- ‚úÖ **Cloud-native architecture** (auto-scaling, serverless)
- ‚úÖ **Data Services modulari** (CDE, CDW, COD, CML, CDF)

---

### 0.3.2 Versioni CDP

**CDP Private Cloud Base** (ex-CDH/HDP on-premise)
- Deployment: on-premise, bare metal
- Componenti: Cloudera Runtime (Hadoop, Spark, Hive, Impala, ecc.)
- Manager: Cloudera Manager
- Security: SDX (Ranger + Atlas integrati)
- Target: aziende con data center esistenti, compliance strict

**CDP Private Cloud Data Services** (nuovo, containerizzato, microservizi)
- Deployment: on-premise Kubernetes (OpenShift, ECS)
- Architettura: containerized, microservices
- Data Services: CDE, CDW, CML
- Target: aziende on-premise che vogliono cloud-like experience

**CDP Public Cloud** (cloud-native)
- Deployment: AWS, Azure, GCP
- Managed service (Cloudera gestisce control plane)
- Auto-scaling, elastic, pay-as-you-go
- Data Services: CDE, CDW, COD, CML, CDF
- Target: aziende cloud-first, workload variabili

---

## 0.4 Differenze architetturali: CDH/HDP ‚Üí CDP

### 0.4.1 Differenze fisiche (infrastruttura)

| Aspetto | CDH/HDP (legacy) | CDP |
|---------|------------------|-----|
| **Deployment** | Bare metal on-premise | Hybrid: on-premise + cloud |
| **Architettura** | Monolitica (tutto su un cluster) | Modulare (Data Services separati) |
| **Storage/Compute** | Tightly coupled (HDFS locale) | Separated (S3/ADLS + compute elastico) |
| **Scaling** | Verticale/orizzontale hardware | Elastic cloud-native (auto-scaling) |
| **Containers** | No (bare metal JVMs) | S√¨ (Kubernetes) |
| **Hardware** | Commodity servers permanenti | Cloud VMs ephemeral |
| **Network** | Intra-cluster (rack-local) | Cloud VPC + cross-region |

---

### 0.4.2 Differenze logiche (software/architettura)

**Sicurezza e governance:**

| Aspetto | CDH | HDP | CDP |
|---------|-----|-----|-----|
| **Authorization** | Sentry | Ranger | Ranger (unified) |
| **Metadata/Lineage** | Navigator | Atlas | Atlas (unified) |
| **Gateway** | Knox (add-on) | Knox | Knox (integrated) |
| **Encryption** | Navigator Encrypt + HDFS TDE | HDFS TDE | HDFS TDE + cloud KMS |
| **Integrazione** | Tool separati | Tool separati | **SDX (tutto integrato)** |

**Management:**

| Aspetto | CDH | HDP | CDP |
|---------|-----|-----|-----|
| **Cluster manager** | Cloudera Manager | Ambari | Cloudera Manager (enhanced) |
| **Monitoring** | Cloudera Manager | Ambari + external | Cloudera Manager + Workload XM |
| **Replication** | Cloudera Manager | Ambari + Falcon | Replication Manager (unified) |

**Data Services (nuovo in CDP):**

CDH/HDP non avevano servizi modulari cloud-native.

CDP introduce:
- **CDE** (Cloudera Data Engineering) - Spark as a Service
- **CDW** (Cloudera Data Warehouse) - Hive/Impala virtual warehouses
- **COD** (Cloudera Operational DB) - HBase as a Service
- **CML** (Cloudera Machine Learning) - ML workspace unificato
- **CDF** (Cloudera DataFlow) - NiFi as a Service

Questi sono **containerizzati**, **auto-scaling**, **indipendenti**.

---

### 0.4.3 Storage: da HDFS locale a object storage

**CDH/HDP:**
```
Cluster on-premise
‚îÇ
‚îú‚îÄ‚îÄ Nodo 1: HDFS DataNode + YARN NodeManager + Compute
‚îú‚îÄ‚îÄ Nodo 2: HDFS DataNode + YARN NodeManager + Compute
‚îî‚îÄ‚îÄ Nodo 3: HDFS DataNode + YARN NodeManager + Compute

Storage e compute sono ACCOPPIATI (tightly coupled)
```

**CDP Public Cloud:**
```
Cloud Storage (S3/ADLS/GCS) ‚Üí Storage separato, persistente
          ‚Üì
Ephemeral Compute Cluster (auto-scaling)
- Spark executors
- Hive/Impala workers
- Containers Kubernetes

Storage e compute sono SEPARATI (decoupled)
```

**Vantaggi separation of storage/compute:**
- ‚úÖ Scale storage e compute indipendentemente
- ‚úÖ Compute ephemeral (crea/distruggi cluster on-demand)
- ‚úÖ Storage persistente (dati rimangono su S3/ADLS)
- ‚úÖ Costo ridotto (paga solo compute quando serve)
- ‚úÖ Durability cloud-native (11 nines su S3)

---

##### **1. CDP Public Cloud ‚òÅÔ∏è**
**‚úÖ S√å - Storage SEMPRE separato e SEMPRE in cloud**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  CDP Public Cloud Architecture                          ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Compute Layer  ‚îÇ   ‚Üê‚Üí    ‚îÇ  Storage Layer       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  (Ephemeral)    ‚îÇ         ‚îÇ  (Persistent)        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ         ‚îÇ                      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ CDE (Spark)   ‚îÇ         ‚îÇ ‚Ä¢ S3 (AWS)           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ CDW (Hive)    ‚îÇ         ‚îÇ ‚Ä¢ ADLS (Azure)       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ CML (ML)      ‚îÇ         ‚îÇ ‚Ä¢ GCS (Google Cloud) ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ COD (HBase)   ‚îÇ         ‚îÇ                      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ         ‚îÇ Object Storage       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ Auto-scaling    ‚îÇ         ‚îÇ Durable, scalable    ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Caratteristiche:**
- **Storage:** Object storage cloud (S3, ADLS Gen2, GCS)
- **Compute:** Cluster effimeri (EC2, Azure VMs, GCE instances)
- **Architettura:** Completamente disaccoppiata
- **Location:** Tutto in cloud (AWS/Azure/GCP)

**Vantaggi:**
- üöÄ **Elasticit√† totale:** scala compute senza toccare storage
- üí∞ **Costi ottimizzati:** paghi compute solo quando lo usi
- üîí **Durabilit√†:** dati persistono anche cancellando cluster
- ‚ôªÔ∏è **Multi-workload:** stessi dati accessibili da CDE, CDW, CML simultaneamente
- üåç **Global:** replica dati cross-region facilmente

**Esempio pratico:**
```
Data Lake su S3 (us-east-1)
    ‚Üì
‚îú‚îÄ CDE Virtual Cluster #1 (Spark batch)
‚îÇ   ‚îî‚îÄ Scala/scompare on-demand
‚îÇ
‚îú‚îÄ CDW Virtual Warehouse (Impala query)
‚îÇ   ‚îî‚îÄ Auto-scale basato su query load
‚îÇ
‚îî‚îÄ CML Workspace (data scientists)
    ‚îî‚îÄ Jupyter notebooks leggono/scrivono stesso Data Lake
```

---

##### **2. CDP Private Cloud Base üè¢**
**‚ùå NO - Storage e Compute ACCOPPIATI (architettura tradizionale Hadoop)**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  CDP Private Cloud Base Architecture                    ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  Ogni nodo ha STORAGE + COMPUTE insieme                 ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ Nodo 1: HDFS DataNode + YARN NodeManager        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         [Storage locale] + [Compute]             ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ Nodo 2: HDFS DataNode + YARN NodeManager        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         [Storage locale] + [Compute]             ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ Nodo 3: HDFS DataNode + YARN NodeManager        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         [Storage locale] + [Compute]             ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  On-premise, bare metal servers                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Caratteristiche:**
- **Storage:** HDFS locale sui nodi del cluster
- **Compute:** YARN NodeManager sugli stessi nodi
- **Architettura:** Tightly coupled (heritage da CDH/HDP)
- **Location:** On-premise (data center aziendale)

**Perch√© √® accoppiato:**
- üìç **Data locality:** compute preferisce elaborare dati locali (stessa macchina)
- üèóÔ∏è **Architettura legacy:** eredit√† da Hadoop originale (2006-2015)
- üîß **Hardware fisico:** server bare metal permanenti

**Limitazioni:**
- ‚ö†Ô∏è Non puoi scalare storage senza aggiungere nodi compute
- ‚ö†Ô∏è Non puoi scalare compute senza aggiungere storage HDFS
- ‚ö†Ô∏è Cluster sempre accesi (no elasticit√† on-demand)

---

##### **3. CDP Private Cloud Data Services üè¢‚òÅÔ∏è**
**‚úÖ S√å - Storage separato (on-premise ma cloud-like)**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  CDP Private Cloud Data Services Architecture           ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Compute Layer  ‚îÇ   ‚Üê‚Üí    ‚îÇ  Storage Layer       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  (Kubernetes)   ‚îÇ         ‚îÇ  (Object Storage)    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ         ‚îÇ                      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ CDE Pods      ‚îÇ         ‚îÇ ‚Ä¢ Ozone              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ CDW Pods      ‚îÇ         ‚îÇ ‚Ä¢ MinIO              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ CML Pods      ‚îÇ         ‚îÇ ‚Ä¢ NetApp StorageGRID ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ         ‚îÇ ‚Ä¢ Dell ECS           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ OpenShift/ECS   ‚îÇ         ‚îÇ                      ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  On-premise, but cloud-native architecture              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Caratteristiche:**
- **Storage:** Object storage on-premise (Ozone, MinIO, NetApp, Dell ECS)
- **Compute:** Container orchestration (Kubernetes: OpenShift o ECS Anywhere)
- **Architettura:** Separata, cloud-native in data center
- **Location:** On-premise ma con modello cloud

**Vantaggi:**
- ‚úÖ Separazione storage/compute come il cloud pubblico
- ‚úÖ Auto-scaling dei Data Services
- ‚úÖ Containerizzazione (portabilit√†)
- ‚úÖ Rimane on-premise (compliance/data sovereignty)

---

##### **Tabella Riepilogativa**

| **CDP Deployment**               | **Storage Separato?** | **In Cloud?** | **Storage Type**        | **Compute Type**          |
|----------------------------------|-----------------------|---------------|-------------------------|---------------------------|
| **CDP Public Cloud**             | ‚úÖ S√å                 | ‚úÖ S√å         | S3/ADLS/GCS (object)   | Cloud VMs (ephemeral)     |
| **CDP Private Cloud Base**       | ‚ùå NO                 | ‚ùå NO         | HDFS (local disks)     | Bare metal (permanent)    |
| **CDP Private Cloud Data Services** | ‚úÖ S√å              | ‚ùå NO         | Ozone/MinIO (object)   | Kubernetes pods (elastic) |

---

##### **In sintesi (rispondendo alla tua domanda):**

**"In CDP lo storage √® sempre separato dal compute ed in cloud?"**

**Risposta:**
- **CDP Public Cloud:** ‚úÖ S√å, sempre separato + sempre cloud (AWS/Azure/GCP)
- **CDP Private Cloud Base:** ‚ùå NO, accoppiato + on-premise (HDFS tradizionale)
- **CDP Private Cloud Data Services:** ‚úÖ Separato ma ‚ùå on-premise (cloud-like architecture ma on prem)

**Quindi:**
- ‚úÖ **Cloud = Sempre separato**
- ‚ùå **On-premise Base = Mai separato** (tightly coupled)
- ‚ö° **On-premise Data Services = Separato ma non cloud** (hybrid model)

---

### 0.4.4 Da monolite a microservizi

**CDH/HDP (monolite):**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Cluster unico on-premise            ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ ‚îÇ HDFS + YARN + Hive + Spark +    ‚îÇ ‚îÇ
‚îÇ ‚îÇ HBase + Kafka + tutto insieme   ‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```
- Un cluster fa tutto
- Upgrade = downtime di tutto
- Resource contention tra workload

**CDP (microservizi):**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ CDE (Spark)    ‚îÇ  ‚îÇ CDW (Hive)     ‚îÇ  ‚îÇ CML (ML)       ‚îÇ
‚îÇ Auto-scaling   ‚îÇ  ‚îÇ Auto-scaling   ‚îÇ  ‚îÇ Isolated       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚Üì                   ‚Üì                   ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ SDX (Shared Data Experience)                             ‚îÇ
‚îÇ Ranger + Atlas + Metastore                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Data Lake (S3/ADLS/GCS)                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```
- Servizi indipendenti
- Upgrade indipendenti (zero downtime)
- Isolamento risorse
- Governance condivisa (SDX)

---

## 0.5 Timeline evolutiva

```
2008 ‚Üí Cloudera fondata
2009 ‚Üí CDH 1 (prima distribuzione Hadoop commerciale)
2011 ‚Üí Hortonworks fondata
2012 ‚Üí CDH 4 (Impala lanciato)
2013 ‚Üí HDP 2.0 (Ranger, Atlas)
2014 ‚Üí CDH 5 (Spark integrato)
2017 ‚Üí CDH 6 (ultima major release CDH)
2018 ‚Üí Merger Cloudera + Hortonworks annunciato
2019 ‚Üí Merger completato, CDP annunciato
2020 ‚Üí CDP Public Cloud GA (General Availability)
2021 ‚Üí CDP Private Cloud Data Services GA
2023 ‚Üí CDP evoluzione continua (nuovi Data Services)
```

---

## 0.6 Perch√© CDP √® importante per l'esame

**L'esame CDP-0011 testa:**
1. Conoscenza componenti (heritage da CDH/HDP)
2. Architettura moderna (cloud-native, SDX)
3. Differenze Public vs Private Cloud
4. Data Services (nuovo in CDP)

**Non chiede:**
- Dettagli su CDH/HDP legacy (obsoleti)
- Ambari (sostituito da Cloudera Manager)
- Sentry (sostituito da Ranger)

**Focus:** CDP come piattaforma unificata moderna.

---

## 0.7 Riepilogo: cosa devi sapere

‚úÖ **CDP unisce best-of-breed di CDH e HDP**
‚úÖ **SDX √® il cuore (Ranger + Atlas + Metastore unificati)**
‚úÖ **Hybrid cloud: Private Cloud Base + Public Cloud**
‚úÖ **Separation of storage and compute (cloud-native)**
‚úÖ **Data Services containerizzati e auto-scaling**
‚úÖ **Security/governance integrate by design**

‚ùå **Non serve sapere:** dettagli CDH/HDP specifici, Ambari, Sentry

*SDX (Shared Data Experience) √® una componente della piattaforma Cloudera che gestisce in modo centralizzato la sicurezza, il catalogo dei dati, la governance e le policy di accesso ai dati nei cluster Big Data.

In pratica, SDX permette di:

- Definire e applicare regole di sicurezza e privacy sui dati.
- Gestire i metadati (informazioni sui dati) in modo unificato.
- Tracciare e monitorare chi accede ai dati e come vengono usati.
- Garantire coerenza e controllo su dati distribuiti tra diversi servizi (come Hadoop, Hive, Impala, ecc.).
- SDX semplifica la gestione dei dati in ambienti complessi, assicurando che le policy siano rispettate ovunque i dati vengano usati.

---

# PARTE 1: COMPONENTI PRINCIPALI CDP (15 domande)

---

## 0. HDFS ‚Äì Hadoop Distributed File System

### 0.1 Cos'√® HDFS

**HDFS** √® un **file system distribuito Java-based** per memorizzare grandi volumi di dati.

**Caratteristiche principali:**
- Storage scalabile su cluster di commodity server
- Replica automatica dei dati (default 3 copie)
- Fault tolerance nativa
- Write-once, read-many (ottimizzato per streaming)

### 0.2 Architettura HDFS

```
NameNode (master)
- Gestisce namespace del file system*
- Controlla metadata (nomi file, permessi, posizioni blocchi)
- Single point of failure (mitigato da HA)

DataNode (worker)
- Memorizza i blocchi di dati effettivi
- Invia heartbeat al NameNode
- Esegue letture/scritture su richiesta client
```

*‚ÄúGestisce namespace del file system‚Äù significa che il sistema (ad esempio HDFS) si occupa di organizzare e tenere traccia della struttura delle cartelle e dei file, dei loro nomi, delle gerarchie e dei percorsi. In pratica, il namespace √® l‚Äôinsieme di tutti i nomi (file e directory) e la loro organizzazione all‚Äôinterno del file system, come una mappa che dice dove si trova ogni file o cartella.

### 0.3 Concetti chiave HDFS

| Concetto | Descrizione |
|----------|-------------|
| **Blocco** | Unit√† minima di storage (default 128MB/256MB) |
| **Replica** | Numero di copie di ogni blocco (default 3) |
| **Rack Awareness** | Distribuisce repliche su rack diversi |
| **NameNode HA** | Secondary/Standby NameNode per failover |

üëâ **Domanda tipica d'esame**
> HDFS √® ottimizzato per? ‚Üí **Grandi file, accesso sequenziale, throughput alto**
> Quante repliche default? ‚Üí **3**

---

## 0.5 Hue ‚Äì SQL Query Interface

### 0.5.1 Cos'√® Hue

**Hue** √® l'interfaccia web unificata per interrogare dati in CDP.

**Funzioni principali:**
- Editor SQL per Hive e Impala
- File browser HDFS
- Job browser (YARN, Oozie)
- Query history e saved queries

### 0.5.2 Hue e integrazione motori

Hue si connette a:
- **Hive** per query batch
- **Impala** per query interattive
- **YARN** per monitoring job
- **Oozie** per workflow

üëâ **Domanda tipica d'esame**
> Hue √® un motore SQL? ‚Üí **No, √® un'interfaccia web per Hive/Impala**

---

## 0.7 YARN ‚Äì Resource Manager

### 0.7.1 Cos'√® YARN

**Apache Hadoop YARN** √® il **resource manager** per applicazioni distribuite.

**Funzione principale:**
- Scheduling e allocazione risorse (CPU, RAM)
- Gestione container per applicazioni
- Monitoring e fault tolerance

### 0.7.2 Architettura YARN

```
ResourceManager (master)
- Scheduler globale
- Assegna risorse ai job

NodeManager (worker)
- Lancia container sui nodi
- Monitora utilizzo risorse

ApplicationMaster
- Negozia risorse per ogni applicazione
- Coordina esecuzione task
```

### 0.7.3 YARN e motori

YARN gestisce risorse per:
- MapReduce
- Spark
- Tez (Hive)

üëâ **Domanda tipica d'esame**
> YARN gestisce storage o compute? ‚Üí **Compute (CPU/RAM)**
> YARN √® necessario per Impala? ‚Üí **No, Impala √® long-running daemon**

---

## 0.9 Apache Spark

### 0.9.1 Cos'√® Spark

**Apache Spark** √® un **motore di elaborazione distribuita in-memory** per big data e analytics.

**Caratteristiche:**
- Elaborazione in-memory (10-100x pi√π veloce di MapReduce)
- API unificata: batch, streaming, ML, SQL, graph
- Supporta Scala, Java, Python, R

### 0.9.2 Componenti Spark

| Componente | Funzione |
|------------|----------|
| **Spark Core** | Engine di base, RDD, task scheduling |
| **Spark SQL** | Query SQL su dati strutturati |
| **Spark Streaming** | Stream processing (micro-batch) |
| **MLlib** | Machine learning library |
| **GraphX** | Graph processing |

### 0.9.3 Spark vs MapReduce

| Aspetto | MapReduce | Spark |
|---------|-----------|-------|
| Storage intermedio | Disco (spill) | Memoria (RAM) |
| Latenza | Minuti | Secondi |
| Fault tolerance | Retry task | RDD lineage |
| API | Java MapReduce | Scala/Python/Java/R |

üëâ **Domanda tipica d'esame**
> Spark √® batch o streaming? ‚Üí **Entrambi**
> Perch√© Spark √® pi√π veloce? ‚Üí **Elaborazione in-memory**

---



## 0.11 Apache Oozie

### 0.11.1 Cos'√® Oozie

**Apache Oozie** √® un **workflow scheduler** per job Hadoop.

**Funzioni:**
- Orchestrazione job complessi (DAG - Directed Acyclic Graph)
- Scheduling basato su tempo o eventi
- Coordinamento dipendenze tra job

### 0.11.2 Tipi di job Oozie

| Tipo | Descrizione |
|------|-------------|
| **Workflow** | Sequenza di azioni (map, reduce, Spark, Hive, ecc.) |
| **Coordinator** | Workflow ricorrenti (schedule cron-like) |
| **Bundle** | Gruppi di coordinator |

### 0.11.3 Azioni supportate

Oozie supporta:
- MapReduce
- Spark
- Hive
- Sqoop
- Shell script
- Java

üëâ **Domanda tipica d'esame**
> Oozie √® un workflow scheduler? ‚Üí **S√¨**
> Combina job sequenzialmente? ‚Üí **S√¨**
> Supporta MiNiFi? ‚Üí **No**

---

## 0.13 Apache Kafka

### 0.13.1 Cos'√® Kafka

**Apache Kafka** √® una **piattaforma di streaming distribuita** ad alte prestazioni.

**Caratteristiche:**
- Publish-subscribe messaging*
- Storage persistente su disco
- Alta throughput (milioni msg/sec)
- Fault tolerance e replication

*Publish-subscribe messaging: √® un modello di comunicazione asincrona in cui i produttori (publisher) inviano messaggi a un canale o argomento (topic), senza conoscere i destinatari. I consumatori (subscriber) si iscrivono a uno o pi√π topic e ricevono solo i messaggi di loro interesse. Questo modello permette un forte disaccoppiamento tra chi produce e chi consuma i dati, ed √® molto usato in sistemi distribuiti, streaming e big data (es. Apache Kafka, RabbitMQ, Google Pub/Sub).

### 0.13.2 Concetti chiave Kafka

| Concetto | Descrizione |
|----------|-------------|
| **Topic** | Categoria/feed di messaggi |
| **Producer** | Pubblica messaggi su topic |
| **Consumer** | Legge messaggi da topic |
| **Broker** | Nodo Kafka che memorizza dati |
| **Partition** | Shard di un topic per parallelismo |

### 0.13.3 Kafka use cases

- Real-time streaming analytics
- Log aggregation
- Event sourcing
- Messaging tra microservizi

üëâ **Domanda tipica d'esame**
> Kafka √® storage o processing? ‚Üí **Entrambi (memorizza + distribuisce)**
> Kafka √® persistente? ‚Üí **S√¨, retention configurabile**

---

## 0.15 Apache NiFi

### 0.15.1 Cos'√® NiFi

**Apache NiFi** √® un **sistema per automatizzare il flusso di dati** tra sistemi.

**Caratteristiche:**
- GUI web drag-and-drop (visual programming)
- Connessioni a 300+ sorgenti/destinazioni
- Data provenance (tracciabilit√† completa)
- Backpressure handling

### 0.15.2 NiFi use cases

- Ingestione dati da sorgenti multiple
- Routing e trasformazione dati
- Data enrichment
- Push/pull da/verso sistemi esterni

### 0.15.3 NiFi vs Kafka

| Aspetto | NiFi | Kafka |
|---------|------|-------|
| Focus | Data flow orchestration | Messaging/streaming |
| GUI | S√¨ (visual) | No |
| Trasformazioni | S√¨ (native) | No (serve Kafka Streams) |
| Throughput | Medio/alto | Altissimo |

üëâ **Domanda tipica d'esame**
> NiFi ha GUI? ‚Üí **S√¨, web-based drag-and-drop**
> NiFi √® no-code? ‚Üí **S√¨, visual programming**

---

## 0.17 Apache HBase e Phoenix

### 0.17.1 Cos'√® HBase

**Apache HBase** √® un **database NoSQL distribuito** per accesso real-time a big data.

**Caratteristiche:**
- Modello wide-column (colonne sparse)
- Accesso random read/write veloce
- Scalabilit√† orizzontale automatica
- Consistency strong (non eventual)

### 0.17.2 HBase use cases

- Time-series data
- Real-time analytics
- Messaggistica e social media feed
- IoT sensor data

### 0.17.3 Cos'√® Phoenix

**Apache Phoenix** √® un **layer SQL sopra HBase**.

**Funzioni:**
- Query SQL su dati HBase
- Indici secondari
- JDBC driver
- Performance ottimizzate

üëâ **Domanda tipica d'esame**
> HBase √® relazionale? ‚Üí **No, NoSQL wide-column**
> Phoenix cosa fa? ‚Üí **SQL interface per HBase**

---

## 0.19 Apache Kudu

### 0.19.1 Cos'√® Kudu

**Apache Kudu** √® un **columnar storage engine** per Hadoop.

**Caratteristiche:**
- Storage colonnare (come Parquet, ma mutabile)
- Fast analytics (scan) + fast updates/inserts
- Integrazione nativa con Impala e Spark
- ACID compliant

### 0.19.2 Kudu vs HBase vs HDFS

| Aspetto | HDFS | HBase | Kudu |
|---------|------|-------|------|
| Workload | Batch analytics | Random access | Hybrid (analytics + updates) |
| Updates | Immutabile | Veloce | Veloce |
| Scans | Veloce | Lento | Veloce |
| Formato | File-based | Row-based | Column-based |

üëâ **Domanda tipica d'esame**
> Kudu √® colonnare? ‚Üí **S√¨**
> Kudu supporta update? ‚Üí **S√¨, ACID**
> Kudu sostituisce HDFS? ‚Üí **No, √® complementare**

---

## 1. Ruolo di Hive e Impala nella Cloudera Data Platform

In **:contentReference[oaicite:0]{index=0}**, **Hive** e **Impala** non sono alternative, ma **complementari**.

| Motore | Tipo di accesso | Caso d‚Äôuso principale |
|------|----------------|----------------------|
| Hive | SQL batch | ETL, reporting massivo |
| Impala | SQL interattivo | Analisi a bassa latenza |

üëâ **Domanda tipica d‚Äôesame**  
> Quale scegliere per query interattive? ‚Üí **Impala**  
> Quale per ETL batch? ‚Üí **Hive**

---

## 2. Apache Hive ‚Äì Approfondimento completo

## 2.1 Cos‚Äô√® Apache Hive

**:contentReference[oaicite:1]{index=1}** √® un **data warehouse distribuito** che fornisce:
- un livello SQL sopra Hadoop (Consente di scrivere query SQL-like per analizzare i dati in HDFS)
- uno strato semantico sopra HDFS (Hive organizza i dati in tabelle e schemi, fornendo una struttura logica ai file grezzi in HDFS)
- uno schema-on-read (Lo schema viene applicato ai dati solo quando vengono letti (non al momento della scrittura).

Hive **non √® un database** e **non √® OLTP**.

---

## 2.2 Hive come strato semantico del Data Lake

Senza Hive, il Data Lake √® solo un insieme di file.  
Hive introduce:

- tabelle
- colonne
- tipi di dato
- partizioni

‚û°Ô∏è **Hive d√† significato al dato**

Questo √® fondamentale anche lato governance (Atlas, Ranger, auditing).

---

## 2.3 Hive Metastore (concetto CHIAVE per l‚Äôesame)

Il **Metastore** √® il componente pi√π importante di Hive.

### **Cosa memorizza il Metastore?**
1. **Definizione delle tabelle:**
   - Nomi delle tabelle e dei database.
2. **Schema delle tabelle:**
   - Colonne, tipi di dati, vincoli.
3. **Partizioni:**
   - Informazioni sulle partizioni delle tabelle (es. `year=2025`, `region=EU`).
4. **Formati dei file:**
   - Specifica il formato di archiviazione (es. Parquet, ORC, TextFile).
5. **Location su HDFS / Object Storage:**
   - Percorso fisico dei dati (es. `hdfs://data/employees`).
6. **Metadati aggiuntivi:**
   - Statistiche (es. numero di righe, dimensione dei dati).

### **Perch√© √® importante per l‚Äôesame?**
- **Concetto chiave:** Il Metastore √® il cuore di Hive, senza di esso non √® possibile interrogare i dati.
- **Domande tipiche:**
  - Cosa memorizza il Metastore?
  - Dove sono archiviati i metadati di Hive?

### **Esempio pratico:**
Per una tabella Hive:
```sql
CREATE TABLE employees (
    id INT,
    name STRING,
    salary DECIMAL
)
PARTITIONED BY (department STRING)
STORED AS PARQUET
LOCATION 'hdfs://data/employees';
```
Il Metastore memorizza:
- **Schema delle colonne:** `id INT`, `name STRING`, `salary DECIMAL`.
- **Partizioni:** `department STRING`.
- **Formato file:** `PARQUET`.
- **Percorso:** `hdfs://data/employees`.

---

## 2.4 Schema-on-read (concetto fondamentale)

Hive applica lo schema **in lettura**, non in scrittura.

Vantaggi:
- ingestione rapida
- flessibilit√†
- adattabilit√† a sorgenti diverse

Svantaggi:
- errori di schema emergono a query time
- maggiore responsabilit√† sullo strato analitico

üëâ **Domanda tipica d‚Äôesame**  
> Hive usa schema-on-read o schema-on-write? ‚Üí **schema-on-read**

---

## 2.5 Tipi di tabelle Hive

### Managed Tables
- Hive gestisce dati e metadati
- `DROP TABLE` elimina anche i file
- pi√π rischiose in ambienti enterprise

### External Tables
- Hive gestisce solo i metadati
- i dati restano esterni
- preferite nei Data Lake

üëâ **Domanda tipica d'esame**  
> Quali tabelle sono consigliate per Data Lake? ‚Üí **External**

---

## 2.6 Hive e performance

Hive √®:
- **batch-oriented**
- adatto a scansioni complete
- meno performante su query rapide

Ottimizzazioni comuni:
- partizionamento
- formati colonnari (ORC, Parquet)
- predicate pushdown

---

## 2.7 Quando usare Hive (riassunto da esame)

Usa Hive quando:
- i dati sono molto grandi
- la latenza non √® critica
- stai facendo ETL o reporting batch
- la priorit√† √® la scalabilit√†

---

## 3. Apache Impala ‚Äì Approfondimento completo

## 3.1 Cos‚Äô√® Apache Impala

**:contentReference[oaicite:2]{index=2}** √® un **motore SQL MPP (Massively Parallel Processing)** progettato per:
- query interattive
- bassa latenza
- analisi esplorativa

Impala **non usa MapReduce**.

---

## 3.2 Architettura di Impala

Impala utilizza:
- daemon su ogni nodo
- esecuzione in parallelo
- elaborazione in memoria

Caratteristiche:
- niente job batch
- niente scritture temporanee su HDFS
- risposta immediata

üëâ **Domanda tipica d‚Äôesame**  
> Impala √® batch o interattivo? ‚Üí **interattivo**

---

## 3.3 Impala e Metastore condiviso

Impala:
- usa lo stesso Metastore di Hive
- vede le stesse tabelle
- usa gli stessi file su HDFS

‚ö†Ô∏è **Punto d‚Äôesame importante**
> Non esiste duplicazione dei dati tra Hive e Impala

---

## 3.4 Impala e performance

Impala √® molto veloce perch√©:
- legge direttamente i file
- usa memoria
- sfrutta MPP

Ma:
- consuma molte risorse
- √® sensibile a query inefficienti
- va governato (YARN, admission control)

---

## 3.5 Impala e sicurezza

In Cloudera, Impala:
- usa Kerberos
- applica policy Ranger
- √® soggetto ad auditing

‚ö†Ô∏è Impala **espone dati velocemente** ‚Üí rischio maggiore se mal configurato.

---

## 3.6 Quando usare Impala (riassunto da esame)

Usa Impala quando:
- serve risposta rapida
- analisi interattiva
- dashboard
- esplorazione dati

---

## 4. Confronto Hive vs Impala (TABELLA DA MEMORIZZARE)

| Caratteristica | Hive | Impala |
|--------------|------|--------|
| Tipo | Data Warehouse | SQL Engine |
| Latenza | Alta | Bassa |
| Uso | Batch / ETL | Interattivo |
| Motore | Job batch | MPP |
| Metastore | S√¨ | S√¨ (condiviso) |
| Schema | Schema-on-read | Schema-on-read |
| Query rapide | ‚ùå | ‚úÖ |

üëâ **Questa tabella copre il 90% delle domande Hive/Impala all‚Äôesame**

---

## 5. Scenario tipico d‚Äôesame (ragionamento)

**Domanda**  
Un analista deve eseguire query SQL rapide su grandi volumi di dati gi√† strutturati. Quale strumento scegliere?

**Risposta corretta**
‚Üí **Impala**

**Perch√©**
- bassa latenza
- SQL interattivo
- dati gi√† nel Data Lake

---

## 6. Errori comuni da evitare all‚Äôesame

‚ùå Dire che Hive √® interattivo  
‚ùå Dire che Impala √® un data warehouse  
‚ùå Pensare che Hive e Impala abbiano storage separato  
‚ùå Confondere Metastore con HDFS  

---

## 7. Sintesi finale (da memorizzare)

- Hive = significato + batch
- Impala = velocit√† + interattivit√†
- Metastore = cuore semantico
- HDFS = storage comune
- CDP = governance unica

---

## 8. Frase chiave da esame (memorizzala)

> **Hive e Impala sono due motori SQL diversi che condividono gli stessi dati e lo stesso Metastore, ma servono casi d‚Äôuso differenti.**
---
# PARTE 2: SICUREZZA CDP (12 domande)

## 9. Shared Data Experience (SDX)

### 9.1 Cos'√® SDX

**SDX** √® l'architettura di sicurezza e governance integrata di CDP.

**Componenti SDX:**
- **Apache Ranger** - Authorization & access control
- **Apache Atlas** - Metadata management & data lineage
- **Apache Knox** - Perimeter security (gateway)
- **Hive Metastore** - Schema centrale
- **Data Catalog** - Discovery & search
- **Replication Manager** - Backup & DR
- **Workload Manager** - Monitoring & optimization

### 9.2 Perch√© SDX √® importante

‚úÖ **Sicurezza integrata by design**
‚úÖ **Governance centralizzata**
‚úÖ **Policy consistenti su tutti i servizi**
‚úÖ **Audit trail completo**

üëâ **Domanda tipica d'esame**
> SDX include Ranger e Atlas? ‚Üí **S√¨**
> SDX √® solo per security? ‚Üí **No, anche governance e metadata**

---

## 10. Apache Ranger ‚Äì Authorization

### 10.1 Cos'√® Ranger

**Apache Ranger** fornisce **autorizzazione centralizzata** per l'ecosistema Hadoop.

**Funzioni:**
- Policy-based access control (PBAC)
- Role-based access control (RBAC)
- Fine-grained authorization (riga/colonna)
- Data masking (offuscamento dati sensibili)
- Row-level filtering
- Audit centralizzato

### 10.2 Servizi supportati da Ranger

Ranger gestisce accessi per:
- HDFS
- Hive
- Impala
- HBase
- Kafka
- Solr
- YARN
- Atlas

### 10.3 Ranger policies

**Tipi di policy:**
- **Access policies** - chi pu√≤ fare cosa (SELECT, INSERT, UPDATE, DELETE)
- **Masking policies** - offusca dati sensibili (es. GDPR)
- **Row filter policies** - limita righe visibili per utente/gruppo

üëâ **Domanda tipica d'esame**
> Ranger fa authentication o authorization? ‚Üí **Authorization**
> Ranger supporta masking? ‚Üí **S√¨**

---

## 11. Apache Atlas ‚Äì Metadata & Governance

### 11.1 Cos'√® Atlas

**Apache Atlas** √® la piattaforma di **metadata management e data governance**.

**Funzioni:**
- Metadata repository (catalogo dati)
- Data lineage (da dove viene il dato)
- Data classification (PII, sensibile, pubblico)
- Business glossary
- Search & discovery

### 11.2 Atlas e lineage

**Data Lineage** traccia:
- Origine dati (source)
- Trasformazioni (ETL)
- Destinazione (target)
- Dipendenze tra entit√†

Esempio: `Salesforce ‚Üí Sqoop ‚Üí HDFS ‚Üí Hive ‚Üí Impala ‚Üí BI Report`

### 11.3 Atlas integration

Atlas traccia automaticamente:
- Hive queries (CREATE TABLE, INSERT)
- Spark jobs
- Sqoop imports
- NiFi flows

üëâ **Domanda tipica d'esame**
> Atlas fa security o governance? ‚Üí **Governance (metadata)**
> Atlas traccia lineage? ‚Üí **S√¨**

---

## 12. Apache Knox ‚Äì Perimeter Security

### 12.1 Cos'√® Knox

**Apache Knox** √® un **gateway di sicurezza perimetrale** per cluster Hadoop.

**Funzioni:**
- Single point of access (reverse proxy)
- Authentication (LDAP, SSO, Kerberos)
- SSL/TLS termination
- Token-based authentication (JWT)
- Topology-based routing

### 12.2 Knox use cases

- Esporre servizi Hadoop (Hive, HBase) all'esterno del cluster
- Integrazione con enterprise SSO
- Protezione endpoint REST API
- Load balancing

üëâ **Domanda tipica d'esame**
> Knox √® un gateway? ‚Üí **S√¨**
> Knox fa authentication? ‚Üí **S√¨**

---

## 13. CDP Public Cloud ‚Äì Integration SSO

### 13.1 Identity Federation

CDP Public Cloud supporta **identity federation** con SAML-based IdP.

**IdP supportati:**
- Okta
- Azure AD
- Google Workspace
- Ping Identity
- ADFS (Active Directory Federation Services)

### 13.2 Vantaggi SSO

‚úÖ Single sign-on (un login per tutti i servizi)
‚úÖ No account Cloudera necessario
‚úÖ Gestione utenti centralizzata
‚úÖ MFA (Multi-Factor Authentication) support

üëâ **Domanda tipica d'esame**
> CDP Public supporta SAML SSO? ‚Üí **S√¨**
> Serve account Cloudera con SSO? ‚Üí **No**

---

## 14. CDP Private Cloud ‚Äì LDAP e Kerberos

### 14.1 Authentication in Private Cloud

CDP Private Cloud integra:
- **LDAP** (Lightweight Directory Access Protocol) per identity
- **Kerberos** per authentication
- **Active Directory** (LDAP + Kerberos combinati)

### 14.2 LDAP

**Funzioni:**
- User/group management
- Directory services
- Integrazione con AD aziendale

### 14.3 Kerberos

**Funzioni:**
- Strong authentication (ticket-based)
- Mutual authentication (client ‚Üî server)
- Protection contro replay attacks
- Single sign-on (SSO)

üëâ **Domanda tipica d'esame**
> Private Cloud usa Kerberos? ‚Üí **S√¨**
> LDAP √® per identity o authentication? ‚Üí **Identity (Kerberos per auth)**

---

## 15. Encryption ‚Äì Data at Rest

### 15.1 HDFS Transparent Encryption

**HDFS TDE** (Transparent Data Encryption):
- Cifratura automatica dei dati su HDFS
- Trasparente per applicazioni (no code change)
- Key management via KMS (Key Management Service)
- Per-zone encryption (encryption zones)

### 15.2 Cloudera Navigator Encrypt

**Navigator Encrypt**:
- Full-disk encryption per nodi del cluster
- Cifratura a livello OS (sotto HDFS)
- Protection anche se disco rubato
- Transparent per applicazioni

### 15.3 Cloud Storage Encryption

**Cloud providers:**
- **AWS S3** - SSE (Server-Side Encryption), KMS
- **Azure ADLS** - Storage Service Encryption
- **GCP GCS** - Default encryption at rest

üëâ **Domanda tipica d'esame**
> HDFS supporta encryption at rest? ‚Üí **S√¨ (TDE)**
> Cloud storage √® cifrato? ‚Üí **S√¨ (di default nei cloud provider)**

---

## 16. Encryption ‚Äì Data in Transit

### 16.1 TLS/SSL

**Transport Layer Security** (TLS 1.2+):
- Cifratura traffico di rete
- Certificati X.509
- Protection contro man-in-the-middle

**Servizi con TLS:**
- HDFS (NameNode ‚Üî DataNode)
- Hive/Impala (client ‚Üî server)
- HTTP/REST API
- JDBC/ODBC connections

üëâ **Domanda tipica d'esame**
> TLS cifra data in transit? ‚Üí **S√¨**
> CDP supporta TLS? ‚Üí **S√¨ (1.2+)**

---

# PARTE 3: DATA SERVICES (9 domande)

## 17. Cloudera Data Engineering (CDE)

### 17.1 Cos'√® CDE

**Cloudera Data Engineering** √® un servizio per **gestire e schedulare job Apache Spark**.

**Caratteristiche:**
- Auto-scaling cluster Spark
- No overhead di gestione cluster manuale
- Supporto batch e streaming
- Integrato con SDX (security/governance)

### 17.2 CDE Public vs Private Cloud

| Aspetto | Public Cloud | Private Cloud |
|---------|--------------|---------------|
| Infrastructure | Cloud provider managed | On-premise Kubernetes |
| Scaling | Elastico (cloud-native) | Limitato da hardware |
| Deployment | Managed service | Self-service virtual cluster |

üëâ **Domanda tipica d'esame**
> CDE √® per Spark? ‚Üí **S√¨**
> CDE fa auto-scaling? ‚Üí **S√¨**

---

## 18. Cloudera Data Warehouse (CDW)

### 18.1 Cos'√® CDW

**Cloudera Data Warehouse** √® un servizio per creare **data warehouse indipendenti e auto-scaling**.

**Caratteristiche:**
- Containerizzato (Kubernetes)
- Hive e Impala virtual warehouses
- Auto-scaling dinamico
- Indipendenti e isolati (multi-tenancy)
- Upgrade indipendenti

### 18.2 CDW Virtual Warehouses

**Tipi:**
- **Hive Virtual Warehouse** - batch ETL
- **Impala Virtual Warehouse** - query interattive

Ogni VW pu√≤ scalare indipendentemente.

### 18.3 CDW Public vs Private Cloud

| Aspetto | Public Cloud | Private Cloud |
|---------|--------------|---------------|
| Infrastructure | AWS/Azure/GCP | OpenShift/ECS/Kubernetes |
| Scaling | Elastic cloud-native | Limitato da capacity |
| Storage | S3/ADLS/GCS | HDFS/Ozone |

üëâ **Domanda tipica d'esame**
> CDW √® containerizzato? ‚Üí **S√¨ (Kubernetes)**
> CDW supporta Hive e Impala? ‚Üí **S√¨ (virtual warehouses)**

---

## 19. Cloudera Operational Database (COD)

### 19.1 Cos'√® COD

**Cloudera Operational Database** √® un servizio per **database operazionali real-time, scalabili e always-available**.

**Tecnologie:**
- Powered by **Apache HBase** (storage)
- **Apache Phoenix** (SQL interface)

### 19.2 COD use cases

- Low-latency random access
- Store/retrieve authentication details
- Time-series data (IoT, logs)
- Real-time analytics
- Session management

### 19.3 COD caratteristiche

‚úÖ Auto-scaling
‚úÖ Always-on (HA nativa)
‚úÖ SQL via Phoenix
‚úÖ NoSQL via HBase API

üëâ **Domanda tipica d'esame**
> COD √® per low-latency? ‚Üí **S√¨**
> COD usa HBase? ‚Üí **S√¨**
> COD √® per authentication data? ‚Üí **S√¨ (domanda campione esame)**

---

## 20. Cloudera Machine Learning (CML)

### 20.1 Cos'√® CML

**Cloudera Machine Learning** unifica **data science e data engineering** in un servizio integrato.

**Funzioni:**
- Workspace collaborativo per data scientist
- Supporto Python, R, Scala
- Model training e deployment
- Jupyter, RStudio, VS Code integration
- MLOps (CI/CD per modelli)

### 20.2 CML caratteristiche

- **Workspace isolati** per progetti
- **Experiments tracking** (modelli, hyperparameter)
- **Model deployment** (REST API)
- **Model monitoring** (drift detection)

### 20.3 CML Public vs Private Cloud

| Aspetto | Public Cloud | Private Cloud |
|---------|--------------|---------------|
| Infrastructure | Cloud managed | OpenShift/Kubernetes |
| GPU support | S√¨ | S√¨ (se disponibile) |
| Scaling | Elastico | Limitato da cluster |

üëâ **Domanda tipica d'esame**
> CML √® per ML? ‚Üí **S√¨**
> CML supporta Python/R? ‚Üí **S√¨**

---

## 21. Cloudera DataFlow (CDF)

### 21.1 Cos'√® CDF

**Cloudera DataFlow** √® un servizio **cloud-native per distribuzione universale di dati**.

**Tecnologia:**
- Powered by **Apache NiFi**

**Caratteristiche:**
- Connect to any data source
- Process and deliver to any destination
- GUI drag-and-drop
- Auto-scaling flow deployments

### 21.2 CDF use cases

- Real-time data ingestion
- Data routing e enrichment
- Edge-to-cloud data movement
- IoT data collection

üëâ **Domanda tipica d'esame**
> CDF usa NiFi? ‚Üí **S√¨**
> CDF √® cloud-native? ‚Üí **S√¨ (Public Cloud)**

---

# PARTE 4: DEPLOY CDP PUBLIC CLOUD (9 domande)

## 22. CDP Public Cloud ‚Äì Concetti Core

### 22.1 Cos'√® un Environment

**Environment** √® un **subset logico del cloud provider account** che include:
- Virtual network (VPC/VNet)
- Security groups
- Storage locations (S3/ADLS/GCS)
- SDX (Data Lake)

‚úÖ Puoi registrare **quanti environment vuoi**
‚úÖ Ogni environment √® isolato

üëâ **Domanda tipica d'esame** (domanda campione esame)
> Environment √® un subset del cloud account? ‚Üí **S√¨**
> Quanti environment posso creare? ‚Üí **Quanti voglio**

---

## 22.2 Credential

**Credential** permette a CDP di **autenticarsi con il cloud provider**.

**Prerequisiti:**
- AWS: IAM role, cross-account access
- Azure: Service Principal, Managed Identity
- GCP: Service Account

---

## 22.3 Data Lake

**Data Lake** in CDP Public Cloud:
- Storage centralizzato (S3/ADLS/GCS)
- SDX (Ranger + Atlas)
- Hive Metastore
- Shared tra tutti i Data Hub dello stesso environment

---

## 23. CDP Public Cloud ‚Äì Cloud Providers

### 23.1 AWS Requirements

**Prerequisites:**
- AWS account con privilegi sufficienti
- VPC con subnet (pubbliche/private)
- S3 bucket per storage
- IAM roles/policies
- Cross-account trust

**Services usati:**
- EC2 (compute)
- S3 (storage)
- RDS (Metastore/Ranger DB)
- EKS (Kubernetes per Data Services)

---

### 23.2 Azure Requirements

**Prerequisites:**
- Azure subscription
- Resource group
- VNet con subnet
- ADLS Gen2 storage account
- Service Principal o Managed Identity

**Services usati:**
- VMs (compute)
- ADLS Gen2 (storage)
- Azure Database (Postgres/MySQL)
- AKS (Kubernetes per Data Services)

---

### 23.3 GCP Requirements

**Prerequisites:**
- GCP project
- VPC network
- GCS bucket per storage
- Service Account

**Services usati:**
- Compute Engine (VMs)
- GCS (storage)
- Cloud SQL (databases)
- GKE (Kubernetes per Data Services)

---

üëâ **Domanda tipica d'esame**
> CDP Public supporta AWS/Azure/GCP? ‚Üí **S√¨, tutti e tre**
> Serve VPC/VNet? ‚Üí **S√¨**

---

# PARTE 5: DEPLOY CDP PRIVATE CLOUD BASE (6 domande)

## 24. CDP Private Cloud Base ‚Äì System Requirements

### 24.1 Hardware Requirements

**Per production cluster:**
- Minimum 3 nodi (5+ raccomandati)
- CPU: 4+ core per nodo (8+ raccomandati)
- RAM: 16GB+ per nodo (32GB+ raccomandati)
- Disk: 
  - OS: 100GB+
  - Data: dipende da workload (TB+)
- Network: 10 Gigabit Ethernet (raccomandato)

---

### 24.2 OS supportati

**Operating Systems:**
- Red Hat Enterprise Linux (RHEL) 7.x, 8.x
- CentOS 7.x, 8.x
- Ubuntu 18.04, 20.04
- SUSE Linux Enterprise Server (SLES) 12, 15

---

### 24.3 Java supportati

**Java Providers:** (domanda campione esame)
- ‚úÖ **Oracle JDK** 8, 11
- ‚úÖ **OpenJDK** 8, 11
- ‚úÖ **Azul Zulu JDK** 8, 11
- ‚ùå Closed JDK (non esiste)

üëâ **Domanda tipica d'esame** (domanda campione esame)
> Oracle JDK supportato? ‚Üí **S√¨**
> OpenJDK supportato? ‚Üí **S√¨**
> Azul/Zulu supportato? ‚Üí **S√¨**

---

### 24.4 Database supportati

**Databases per Metastore/Ranger:** (domanda campione esame)
- ‚úÖ **PostgreSQL** 10, 11, 12
- ‚úÖ **MySQL** 5.7, 8.0
- ‚úÖ **MariaDB** 10.x
- ‚úÖ **Oracle Database** 12c, 19c

üëâ **Domanda tipica d'esame** (domanda campione esame)
> PostgreSQL supportato? ‚Üí **S√¨**
> MS SQL Server supportato? ‚Üí **S√¨**
> Oracle DB supportato? ‚Üí **S√¨**
> MySQL supportato? ‚Üí **S√¨**

---

### 24.5 Networking

**Requirements:**
- Forward and reverse DNS
- NTP (Network Time Protocol) sincronizzato
- Firewall rules per comunicazione inter-nodi
- No conflitti di porte

---

# PARTE 6: CLOUDERA MANAGER (3 domande)

## 25. Cloudera Manager

### 25.1 Cos'√® Cloudera Manager

**Cloudera Manager** √® l'applicazione per **gestire, configurare e monitorare cluster CDP Private Cloud Base**.

**Architettura:**
```

Cloudera Manager Server
- Gira su un host dedicato
- Web UI + API REST
- Gestisce uno o pi√π cluster

Cloudera Manager Agent
- Gira su ogni nodo del cluster
- Esegue comandi dal Server
- Invia metriche e heartbeat
```

---

### 25.2 Funzioni principali

**Configurazione:**
- Install/upgrade servizi (Hive, HDFS, YARN, ecc.)
- Configurazione centralizzata
- Rolling restart

**Monitoring:**
- Metriche real-time (CPU, disk, network)
- Health checks automatici
- Alerts e notifications

**Troubleshooting:**
- Log aggregation
- Diagnostics
- Performance tuning

---

### 25.3 Cloudera Manager e database

Cloudera Manager richiede un database esterno per:
- Configuration metadata
- Monitoring data
- User/role management

**Databases supportati:** (gi√† visto sopra)
- PostgreSQL
- MySQL / MariaDB
- Oracle DB
- MS SQL Server

üëâ **Domanda tipica d'esame**
> Cloudera Manager gestisce cluster? ‚Üí **S√¨**
> Serve database? ‚Üí **S√¨**
> Dove gira? ‚Üí **Su host dedicato**

---

# PARTE 7: WORKLOAD XM (3 domande)

## 26. Workload XM

### 26.1 Cos'√® Workload XM

**Workload XM** √® uno strumento per **monitorare, analizzare e ottimizzare workload** su cluster CDP.

**Funzioni:**
- Understand workloads (Hive, Impala, Spark)
- Troubleshoot failed jobs
- Optimize slow queries
- Capacity planning
- Cost optimization

---

### 26.2 Workload XM caratteristiche

**Analisi:**
- Query performance analysis
- Resource utilization (CPU, memory, I/O)
- Baseline comparison
- Anomaly detection

**Recommendations:**
- Query optimization suggestions
- Configuration tuning
- Resource allocation

---

### 26.3 Telemetry Publisher e redaction

**Telemetry Publisher** raccoglie dati diagnostici e li invia a Workload XM.

**Dati sensibili - redaction supportata:** (domanda campione esame)
- ‚úÖ **Log and query** text
- ‚úÖ **MapReduce job properties**
- ‚úÖ **Spark event and executor log**
- ‚ùå HBase users (non redactable in questo contesto)
- ‚ùå Kafka topics (non redactable in questo contesto)

üëâ **Domanda tipica d'esame** (domanda campione esame)
> Workload XM ottimizza query? ‚Üí **S√¨**
> Telemetry Publisher supporta redaction? ‚Üí **S√¨**
> Log and query possono essere redatti? ‚Üí **S√¨**

---

# PARTE 8: REPLICATION MANAGER (3 domande)

## 27. Replication Manager

### 27.1 Cos'√® Replication Manager

**Replication Manager** √® uno strumento per **replicare e migrare dati tra ambienti CDP**.

**Funzioni:**
- Copy HDFS data
- Replicate Hive external tables
- Backup HBase tables
- Disaster Recovery (DR)
- Cloud migration

---

### 27.2 Replication Manager ‚Äì Private Cloud

**Private Cloud:**
- Replica HDFS tra cluster CDP Private Cloud Base 7.1.8+
- Replica Hive external tables
- Replica Ozone data

---

### 27.3 Replication Manager ‚Äì Public Cloud

**Public Cloud:**
- Replica da CDH ‚Üí CDP Public Cloud
- Replica da CDP Private Cloud Base ‚Üí CDP Public Cloud
- Supporta HDFS, Hive, HBase
- Cloud storage (S3/ADLS/GCS) come destination

---

### 27.4 HDFS Replication Policies

**Requirements per replicare HDFS su cloud storage:** (domanda campione esame)
- ‚úÖ **Register cloud credentials** in Replication Manager
- ‚úÖ **Verify cluster access** e configure minimum ports
- ‚ùå Non serve configurare Hive (HDFS √® indipendente)
- ‚ùå Non √® vero che "works without configuration"

üëâ **Domanda tipica d'esame** (domanda campione esame)
> Cosa serve per HDFS replication su cloud? ‚Üí **Cloud credentials + cluster access**
> Serve configurare Hive? ‚Üí **No (HDFS ‚â† Hive)**

---

# RIEPILOGO FINALE

## Distribuzione domande per topic

| Topic | Domande | Focus |
|-------|---------|-------|
| **Componenti CDP** | 15 | HDFS, Hive, Impala, YARN, Spark, Oozie, Kafka, NiFi, HBase, Kudu |
| **Sicurezza** | 12 | SDX, Ranger, Atlas, Knox, encryption, SSO, Kerberos |
| **Data Services** | 9 | CDE, CDW, COD, CML, CDF |
| **Deploy Public Cloud** | 9 | AWS, Azure, GCP, environment, credential |
| **Deploy Private Cloud** | 6 | System requirements, Java, DB, OS |
| **Cloudera Manager** | 3 | Gestione cluster, configurazione |
| **Workload XM** | 3 | Monitoring, optimization, telemetry |
| **Replication Manager** | 3 | Backup, DR, migration |

**Totale:** 60 domande  
**Pass Score:** 60% (36 domande corrette su 60)

---

## Strategie per l'esame

### ‚úÖ Cosa memorizzare

1. **Tabelle comparative** (Hive vs Impala, MapReduce vs Spark, ecc.)
2. **Use cases specifici** (quando usare quale strumento)
3. **Domande campione** (Oozie supporta MiNiFi? ‚Üí No)
4. **Liste supportate** (Java providers, databases, cloud providers)
5. **Acronimi** (SDX, CDE, CDW, COD, CML, CDF, TDE, RBAC)

### ‚ùå Errori comuni da evitare

- Confondere Hive (batch) con Impala (interattivo)
- Pensare che Ranger faccia authentication (fa authorization)
- Credere che Atlas faccia security (fa governance/metadata)
- Confondere NiFi (data flow) con Kafka (messaging)
- Dimenticare che Hive e Impala condividono Metastore
- Non conoscere i database supportati da Cloudera Manager

### üìö Risorse da studiare

1. **Questo documento** (coverage completa 60 domande)
2. **CDP documentation** ufficiale (link per approfondimenti)
3. **Cloudera Essentials for CDP** (corso video)
4. **Hands-on experience** (importante per domande pratiche)

---

## Frasi chiave da memorizzare

> **Hive e Impala** condividono dati e Metastore, ma servono casi d'uso differenti.

> **SDX** √® l'architettura di sicurezza e governance integrata (Ranger + Atlas + Knox + Metastore).

> **COD** √® ideal per low-latency, highly scalable storage/retrieval (authentication, IoT).

> **Environment** √® un logical subset del cloud account con virtual network.

> **Oozie** √® un workflow scheduler che combina job sequenzialmente.

> **Workload XM** ottimizza workload e troubleshoota failed jobs.

> **Replication Manager** replica dati tra ambienti CDP (serve cloud credentials + cluster access).

---

### **Cos'√® lo Schema?**

Lo **schema** √® una definizione strutturale che descrive l'organizzazione e il formato dei dati in un sistema di gestione dei dati. Esso specifica come i dati sono strutturati, quali campi o colonne esistono, e quali tipi di dati sono associati a ciascun campo.

#### **Caratteristiche principali dello Schema:**
1. **Definizione della struttura:**
   - Specifica i campi (colonne) e i loro tipi di dati (es. stringa, intero, data).
   - Definisce le relazioni tra i dati (es. chiavi primarie, univocit√†, ecc.) nei database relazionali.

2. **Tipi di Schema:**
   - **Schema-on-write:**
     - Lo schema √® definito prima che i dati vengano scritti nel sistema.
     - Richiede che i dati rispettino la struttura predefinita.
     - Utilizzato nei database relazionali (es. MySQL, PostgreSQL).
   - **Schema-on-read:**
     - Lo schema viene applicato solo al momento della lettura o dell'analisi dei dati.
     - Permette di gestire dati non strutturati o semi-strutturati.
     - Utilizzato in strumenti di big data come Hadoop e Hive.

3. **Flessibilit√†:**
   - Nei sistemi relazionali, lo schema √® rigido e deve essere rispettato.
   - Nei sistemi non relazionali, lo schema pu√≤ essere flessibile o assente.

4. **Esempi di Schema:**
   - **Database relazionale:**
     ```sql
     CREATE TABLE Clienti (
       ID INT PRIMARY KEY,
       Nome VARCHAR(50),
       Cognome VARCHAR(50),
       Email VARCHAR(100)
     );
     ```
     Questo schema definisce una tabella con colonne e tipi di dati specifici.
   - **Big Data (Hive):**
     ```sql
     CREATE EXTERNAL TABLE LogDati (
       Timestamp STRING,
       Messaggio STRING
     )
     STORED AS TEXTFILE;
     ```
     Questo schema viene applicato ai dati gi√† esistenti in HDFS.

### **Esempio di Schema**

Uno schema definisce la struttura di una tabella, specificando i nomi delle colonne e i tipi di dati associati. Ecco un esempio:

```sql
CREATE TABLE employees (
    id INT,          -- Identificativo univoco
    name STRING,     -- Nome del dipendente
    salary DECIMAL   -- Stipendio
);
```

#### **Dettagli dello schema:**
- **`id INT`**: Colonna `id` con tipo di dato intero (integer).
- **`name STRING`**: Colonna `name` con tipo di dato stringa (testo).
- **`salary DECIMAL`**: Colonna `salary` con tipo di dato decimale (numerico con precisione).

#### **Cosa rappresenta uno schema?**
- Lo schema √® la **struttura logica** di una tabella.
- Specifica:
  1. **Nomi delle colonne** (es. `id`, `name`, `salary`).
  2. **Tipi di dati** (es. `INT`, `STRING`, `DECIMAL`).
  3. (Opzionale) **Vincoli** come chiavi primarie, univocit√†, ecc.

#### **Nota per l'esame CDP:**
- Ogni tabella in Hive o SQL richiede uno schema.
- Lo schema √® obbligatorio per definire come i dati vengono archiviati e interrogati.

#### **Perch√© lo Schema √® Importante?**
- **Organizzazione:** Permette di dare struttura ai dati, rendendoli pi√π facili da interrogare e analizzare.
- **Validazione:** Garantisce che i dati rispettino determinati vincoli (es. tipi di dati corretti).
- **Governance:** Aiuta a mantenere coerenza e integrit√† nei sistemi di gestione dei dati.

---

In sintesi, lo schema √® il "progetto" che descrive come i dati sono organizzati e strutturati in un sistema, influenzando il modo in cui vengono archiviati, letti e analizzati.

---

# Chiave primaria e chiave esterna

## Introduzione

In un database, l‚Äôorganizzazione, l‚Äôidentificazione e la coerenza dei dati dipendono sia dal **modello di database adottato** sia dall‚Äôuso corretto di **chiavi** e **metadati**.

In questo documento vengono spiegati:

* chiave primaria e chiave esterna nei database relazionali
* come vengono identificate tabelle e record
* le differenze tra **database relazionali (RDBMS)** e **non relazionali (NoSQL)**
* il collegamento con i sistemi **Big Data** come Hive

---

## Differenza tra database relazionali e non relazionali

### Database relazionali (RDBMS)

I database relazionali (**Relational Database Management System**) organizzano i dati in **tabelle** composte da **righe (record)** e **colonne (attributi)**, seguendo uno **schema fisso** definito a priori.

Ogni tabella:

* rappresenta un‚Äô**entit√†** del dominio applicativo
* √® identificata dal **nome della tabella all‚Äôinterno di uno schema**
* utilizza una **chiave primaria** per identificare univocamente i record
* pu√≤ essere collegata ad altre tabelle tramite **chiavi esterne**

Le relazioni tra tabelle sono **esplicite** e il database garantisce la coerenza dei dati tramite le propriet√† **ACID**:

* **Atomicit√†**
* **Consistenza**
* **Isolamento**
* **Durabilit√†**

üìå Esempi di RDBMS:

* MySQL
* PostgreSQL
* Oracle

Si chiamano database relazionali perch√© organizzano i dati in tabelle che possono essere messe in relazione tra loro tramite chiavi (primarie e esterne). Il termine ‚Äúrelazionale‚Äù deriva dal concetto matematico di ‚Äúrelazione‚Äù, che in questo contesto indica una tabella composta da righe e colonne. Le relazioni tra le tabelle permettono di collegare e integrare dati diversi in modo strutturato e coerente.

---

### Database non relazionali (NoSQL)

I database non relazionali (**NoSQL**) non si basano sul modello tabellare classico e **non richiedono uno schema rigido**. Sono progettati per gestire **grandi volumi di dati**, **alta scalabilit√† orizzontale** e dati **semi-strutturati o non strutturati**.

Non utilizzano chiavi esterne formali e le relazioni tra dati sono spesso:

* incorporate nei dati stessi
* oppure gestite a livello applicativo

I principali modelli NoSQL sono:

* **Documentali** (es. MongoDB)
  I dati sono memorizzati come documenti JSON/BSON. Ogni documento ha un identificatore univoco (es. `_id`), simile a una chiave primaria, ma senza vincoli relazionali.

* **Key-Value** (es. Redis)
  I dati sono coppie chiave‚Äìvalore. Il modello √® estremamente veloce, ma non supporta relazioni strutturate.

* **A colonne** (es. Cassandra, HBase)
  I dati sono organizzati per colonne e partizioni. √à adatto a grandi volumi e carichi distribuiti.

* **A grafo** (es. Neo4j)
  I dati sono nodi e relazioni esplicite, ideali per rappresentare reti complesse (social network, recommendation system).

---

### Confronto sintetico RDBMS vs NoSQL

| Aspetto           | Database relazionali            | Database NoSQL                           |
| ----------------- | ------------------------------- | ---------------------------------------- |
| Modello dati      | Tabelle (righe/colonne)         | Documenti, key-value, colonne, grafi     |
| Schema            | Rigido                          | Flessibile o assente                     |
| Chiave primaria   | S√¨ (vincolo reale)              | Identificatore univoco                   |
| Chiave esterna    | S√¨                              | No                                       |
| Coerenza          | Forte (ACID)                    | Eventuale (BASE)                         |
| Scalabilit√†       | Verticale                       | Orizzontale                              |
| Caso d‚Äôuso tipico | Transazioni, sistemi gestionali | Big Data, analytics, sistemi distribuiti |

---

## Cos‚Äô√® una tabella

Una **tabella** rappresenta un‚Äô**entit√†** del mondo reale (ad esempio: Studente, Cliente, Ordine).
√à composta da:

* **righe (record)** ‚Üí singole istanze dell‚Äôentit√†
* **colonne (attributi)** ‚Üí caratteristiche dell‚Äôentit√†

### Identificazione di una tabella

Una tabella **non √® identificata dalla chiave primaria**.

üëâ **La tabella √® identificata dal suo nome all‚Äôinterno di uno schema (o database).**

Formalmente, l‚Äôidentificatore univoco di una tabella √®:

```
(schema, nome_tabella)
```

Questo significa che due tabelle possono avere lo stesso nome se appartengono a schemi diversi.

### Esempio

```
public.studente
didattica.studente
```

Queste due tabelle:

* hanno lo stesso nome (`studente`)
* appartengono a schemi diversi
* sono **tabelle distinte**

---

## Chiave primaria (Primary Key)

### Definizione

La **chiave primaria** √® un attributo (o un insieme di attributi) che **identifica univocamente ogni record di una tabella**.

üëâ **La chiave primaria identifica un record, non la tabella.**

### Propriet√† fondamentali

Una chiave primaria deve essere:

* **Univoca** (nessun duplicato)
* **Non nulla** (NOT NULL)
* **Stabile** (non dovrebbe cambiare nel tempo)

Pu√≤ essere:

* **Semplice** ‚Üí una sola colonna
* **Composta** ‚Üí pi√π colonne insieme

---

## Esempio pratico: chiave primaria

### Tabella STUDENTE

| matricola (PK) | nome  | cognome |
| -------------- | ----- | ------- |
| 12345          | Mario | Rossi   |
| 12346          | Luca  | Bianchi |

* `matricola = 12345` identifica **Mario Rossi**
* `matricola = 12346` identifica **Luca Bianchi**

---

## Chiave esterna (Foreign Key)

### Definizione

La **chiave esterna** √® un attributo di una tabella che fa riferimento alla **chiave primaria di un‚Äôaltra tabella**.

Serve a:

* collegare dati tra tabelle diverse
* garantire l‚Äô**integrit√† referenziale**

üëâ Un valore di chiave esterna **deve corrispondere a una chiave primaria esistente**.

---

## Esempio pratico: chiave primaria e chiave esterna

### Tabella CLIENTE

| id_cliente (PK) | nome  |
| --------------- | ----- |
| 10              | Anna  |
| 11              | Paolo |

### Tabella ORDINE

| id_ordine (PK) | data       | id_cliente (FK) |
| -------------- | ---------- | --------------- |
| 501            | 2026-01-10 | 10              |
| 502            | 2026-01-12 | 10              |
| 503            | 2026-01-13 | 11              |

* `id_cliente` √® **PK** in CLIENTE
* `id_cliente` √® **FK** in ORDINE
* ogni ordine √® associato a un cliente esistente

---

## Rappresentazione grafica concettuale

```
CLIENTE (1) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ< ORDINE (N)
```

* una riga di CLIENTE pu√≤ essere collegata a molte righe di ORDINE
* la relazione √® realizzata tramite la chiave esterna

---

## Chiave primaria composta

In alcuni casi, una singola colonna non √® sufficiente a identificare un record.

### Esempio: ISCRIZIONE_ESAME

| matricola | id_esame |
| --------- | -------- |
| 12345     | 1        |
| 12345     | 2        |
| 12346     | 1        |

Qui la chiave primaria √® **composta**:

```
PK = (matricola, id_esame)
```

Questa coppia identifica univocamente una singola iscrizione.

---

## Confronto con database non relazionali (NoSQL)

Nei database NoSQL:

* esiste solitamente un **identificatore univoco** del dato (es. `_id` in MongoDB)
* **non esistono chiavi esterne formali**
* le relazioni sono gestite dall‚Äôapplicazione o tramite strutture annidate

### Esempio MongoDB

```
{
  _id: "u1",
  nome: "Anna",
  ordini: [501, 502]
}
```

* `_id` svolge un ruolo simile alla chiave primaria
* le relazioni non sono vincolate dal database

---

## Schema gerarchico di identificazione

```
Database
 ‚îî‚îÄ‚îÄ Schema
      ‚îî‚îÄ‚îÄ Tabella
           ‚îî‚îÄ‚îÄ Record (riga)
```

* **Database** ‚Üí identificato dal suo nome
* **Schema** ‚Üí identificato dal suo nome all‚Äôinterno del database
* **Tabella** ‚Üí identificata dalla coppia *(schema, nome_tabella)*
* **Record** ‚Üí identificato dalla **chiave primaria**

---

## Confronto: chiave primaria vs nome della tabella

| Aspetto                | Chiave primaria (PK)                    | Nome della tabella                     |
| ---------------------- | --------------------------------------- | -------------------------------------- |
| Cosa identifica        | Un **record (riga)**                    | Una **tabella**                        |
| Ambito                 | Interno alla tabella                    | All‚Äôinterno di uno **schema/database** |
| Unicit√†                | Deve essere **univoca** per ogni record | Deve essere univoco nello schema       |
| Pu√≤ cambiare?          | No (o fortemente sconsigliato)          | S√¨ (rinomina tabella)                  |
| Serve per le relazioni | S√¨ (referenziata dalle FK)              | No                                     |
| Esempio                | `id_cliente = 10`                       | `public.cliente`                       |

üëâ **Errore comune da evitare**: pensare che la chiave primaria identifichi la tabella.

---

## Collegamento a Hive Metastore e Big Data

Nei sistemi Big Data basati su **Hive** (e pi√π in generale su Hadoop/Cloudera), i concetti di database e tabella esistono ancora, ma il ruolo delle chiavi cambia.

### Hive Metastore

Il **Hive Metastore** √® il servizio che mantiene i **metadati** delle tabelle, tra cui:

* database
* nome della tabella
* colonne e tipi di dato
* partizioni
* percorso fisico dei dati su HDFS o Object Storage

üìå In Hive:

* una tabella √® identificata da **(database, nome_tabella)**
* esattamente come negli RDBMS con *(schema, nome_tabella)*

### Gerarchia in Hive

```
Hive Metastore
 ‚îî‚îÄ‚îÄ Database
      ‚îî‚îÄ‚îÄ Table
           ‚îî‚îÄ‚îÄ Partition (opzionale)
                ‚îî‚îÄ‚îÄ File / Record
```

### Chiavi primarie in Hive

* Hive **supporta sintatticamente** PRIMARY KEY e FOREIGN KEY
* **non sono vincoli applicati** (non viene garantita l‚Äôunicit√†)
* servono principalmente per:

  * documentazione del modello dati
  * ottimizzazioni del query planner
  * integrazione con strumenti di BI

üëâ In Hive:

> **la chiave primaria non garantisce l‚Äôunicit√† dei record**, ma descrive l‚Äôintenzione logica del modello.

### Confronto RDBMS vs Hive

| Aspetto                | RDBMS                  | Hive / Big Data            |
| ---------------------- | ---------------------- | -------------------------- |
| Identit√† tabella       | (schema, nome)         | (database, nome)           |
| PK applicata           | S√¨ (vincolo reale)     | No (solo metadato)         |
| FK applicata           | S√¨                     | No                         |
| Integrit√† referenziale | Garantita              | Demandata all‚Äôapplicazione |
| Focus                  | Coerenza transazionale | Analisi su grandi volumi   |

### Collegamento concettuale chiave

* **RDBMS** ‚Üí PK/FK = vincoli forti
* **Hive/Big Data** ‚Üí PK/FK = informazione logica
* **Metastore** ‚Üí ‚Äúcatalogo‚Äù delle tabelle, non dei record

-------|----------------------|-------------------|
| Cosa identifica | Un **record (riga)** | Una **tabella** |
| Ambito | Interno alla tabella | All‚Äôinterno di uno **schema/database** |
| Unicit√† | Deve essere **univoca** per ogni record | Deve essere univoco nello schema |
| Pu√≤ cambiare? | No (o fortemente sconsigliato) | S√¨ (rinomina tabella) |
| Serve per le relazioni | S√¨ (referenziata dalle FK) | No |
| Esempio | `id_cliente = 10` | `public.cliente` |

üëâ **Errore comune da evitare**: pensare che la chiave primaria identifichi la tabella.

---

## Quando scegliere RDBMS, NoSQL o Hive

La scelta tra **database relazionali**, **NoSQL** e **Hive/Big Data** dipende principalmente dal **tipo di dati**, dal **carico di lavoro** e dai **requisiti di coerenza e scalabilit√†**.

---

### Quando scegliere un database relazionale (RDBMS)

Scegli un **RDBMS** quando:

* i dati sono **altamente strutturati**
* lo schema √® **stabile nel tempo**
* sono richieste **transazioni affidabili**
* l‚Äôintegrit√† dei dati √® **critica**

üìå Casi d‚Äôuso tipici:

* sistemi gestionali (ERP, CRM)
* contabilit√† e fatturazione
* sistemi bancari e finanziari
* applicazioni OLTP

üëâ Perch√©: PK e FK garantiscono **coerenza forte** e **integrit√† referenziale**.

---

### Quando scegliere un database NoSQL

Scegli un **NoSQL** quando:

* i dati sono **eterogenei o semi-strutturati**
* lo schema cambia frequentemente
* √® richiesta **alta scalabilit√† orizzontale**
* le prestazioni sono pi√π importanti della coerenza immediata

üìå Casi d‚Äôuso tipici:

* applicazioni web ad alto traffico
* caching e session management (Redis)
* IoT e time series
* sistemi distribuiti globali

üëâ Perch√©: maggiore **flessibilit√†** e **scalabilit√†**, accettando coerenza eventuale.

---

### Quando scegliere Hive / Big Data

Scegli **Hive** (o sistemi Big Data simili) quando:

* i dati sono **molto voluminosi** (Big Data)
* il carico √® principalmente **analitico** (OLAP)
* non servono transazioni riga-per-riga
* l‚Äôobiettivo √® l‚Äôanalisi storica e batch

üìå Casi d‚Äôuso tipici:

* data warehouse
* data lake
* reportistica e BI
* analisi su grandi dataset storici

üëâ Perch√©: Hive separa **storage e compute** e scala su grandi volumi, ma non applica vincoli PK/FK.

---

### Confronto decisionale rapido

| Esigenza                | Tecnologia consigliata |
| ----------------------- | ---------------------- |
| Transazioni critiche    | RDBMS                  |
| Schema flessibile       | NoSQL                  |
| Altissimo volume dati   | Hive / Big Data        |
| Integrit√† referenziale  | RDBMS                  |
| Scalabilit√† orizzontale | NoSQL / Hive           |
| Analytics e BI          | Hive                   |

---

## Riassunto finale

* **La tabella rappresenta un‚Äôentit√†**
* **La chiave primaria identifica un record della tabella**
* **La chiave esterna collega record di tabelle diverse**
* Nei database relazionali, PK e FK garantiscono coerenza e integrit√† dei dati

üëâ Frase chiave da ricordare:

> *La chiave primaria identifica univocamente una riga di una tabella; la chiave esterna realizza le relazioni tra tabelle.*

---

## Chiave primaria nei database non relazionali

Nei database non relazionali, il concetto di chiave primaria esiste ma pu√≤ essere diverso rispetto ai database relazionali:
- Nei database documentali (es. MongoDB), ogni documento ha un identificatore unico (di solito il campo _id), che svolge il ruolo di chiave primaria.
- Nei database key-value, la ‚Äúchiave‚Äù √® sempre unica e identifica il valore associato.
- Nei database a colonne (es. Cassandra), si usano chiavi primarie composte per identificare in modo univoco le righe.
- Nei database a grafo, i nodi e le relazioni hanno identificatori unici.

Quindi, anche nei database non relazionali esiste un meccanismo per identificare univocamente i dati, ma la gestione e la struttura possono variare a seconda del modello.
