
# INTRODUZIONE: STORIA DI CLOUDERA E EVOLUZIONE VERSO CDP

## Pre-Cloudera: Il contesto tecnologico (2003-2008)

### Tecnologie pre-big data

Prima dell'avvento di Hadoop e Cloudera, il panorama del data management era dominato da soluzioni tradizionali.

**Data Warehouse tradizionali (anni '90-2000):**
- **Oracle Database** - leader enterprise RDBMS
- **IBM DB2** - mainframe e enterprise
- **Teradata** - appliance per analytics
- **Microsoft SQL Server** - piattaforma Windows

**Limitazioni critiche:**
- ‚ùå **Scalabilit√† verticale** - solo scale-up, hardware costoso
- ‚ùå **Gestione dati non strutturati** - difficile gestire log, testo come documenti articoli e commenti sui social media
- ‚ùå **Costi proibitivi** - milioni di dollari per petabyte
- ‚ùå **Schema rigido** - schema-on-write, no flessibilit√†
- ‚ùå **Vendor lock-in** - dipendenza da fornitori proprietari

## Differenza tra dati relazionali e non relazionali

### **Dati Relazionali**
I dati relazionali sono organizzati in un formato strutturato, seguendo uno schema rigido.

#### **Caratteristiche principali:**
1. **Struttura**:
   - Organizzano i dati in tabelle con righe e colonne.
   - Ogni tabella ha uno schema predefinito (schema-on-write).
   - Le relazioni tra i dati sono definite tramite chiavi primarie e chiavi esterne.

2. **Esempi di dati**:
   - Informazioni su clienti (nome, cognome, email, telefono).
   - Transazioni finanziarie (ID transazione, importo, data).
   - Inventari di prodotti (ID prodotto, quantit√†, prezzo).

3. **Database relazionali (RDBMS)**:
   - MySQL, PostgreSQL, Oracle Database, Microsoft SQL Server, Maria DB

4. **Vantaggi**:
   - **Integrit√† dei dati**: Garantita da vincoli (es. chiavi primarie, univocit√†).
   - **Query potenti**: Linguaggio SQL per interrogare i dati.
   - **Adatto a dati strutturati**: Ideale per applicazioni aziendali tradizionali.

5. **Svantaggi**:
   - **Scalabilit√† verticale**: Difficile scalare orizzontalmente (richiede hardware pi√π potente).
   - **Schema rigido**: Cambiare lo schema pu√≤ essere complesso.
   - **Non adatto a dati non strutturati**: Come immagini, video, log.

---

### **Dati Non Relazionali**
I dati non relazionali sono pi√π flessibili e non seguono uno schema rigido.

#### **Caratteristiche principali:**
1. **Struttura**:
   - Non usano tabelle (IMP).
   - organizzano i dati in documenti, grafi, colonne o chiavi-valori.
   - Schema dinamico o assente (schema-on-read).

2. **Esempi di dati**:
   - Log di sistema (timestamp, messaggio di errore).
   - Post sui social media (testo, immagini, video).
   - Dati IoT (sensori, eventi in tempo reale).

3. **Database non relazionali (NoSQL)**:
   - MongoDB (documenti), Cassandra (colonne), Redis (chiavi-valori), Neo4j (grafi).

4. **Vantaggi**:
   - **Scalabilit√† orizzontale**: Aggiungere nodi per gestire pi√π dati.
   - **Flessibilit√†**: Adatto a dati non strutturati o semi-strutturati.
   - **Performance**: Ottimizzato per specifici casi d'uso (es. letture/scritture rapide).

5. **Svantaggi**:
   - **Meno consistenza**: Non sempre garantisce transazioni ACID.
   - **Query limitate**: Non sempre supporta SQL.
   - **Meno adatto a dati strutturati**: Non ideale per applicazioni tradizionali.

---

HDFS (Hadoop Distributed File System) non √® un database relazionale ma √® un file system distribuito progettato per archiviare grandi quantit√† di dati su cluster di computer. HDFS gestisce file e directory, non tabelle relazionali, e non impone uno schema rigido ai dati. Quindi, HDFS √® considerato un sistema di archiviazione non relazionale.
Hive e Impala non sono database relazionali in senso stretto, ma sono motori di query che permettono di eseguire interrogazioni SQL su dati archiviati in HDFS (o altri file system distribuiti). Tuttavia, forniscono un‚Äôinterfaccia relazionale: i dati sono organizzati in tabelle e si usa SQL per interrogarli, quindi si comportano come sistemi relazionali dal punto di vista dell‚Äôutente, pur non essendo veri e propri RDBMS tradizionali.

La differenza principale tra database e filesystem √® la seguente:

Un filesystem gestisce l‚Äôarchiviazione e l‚Äôorganizzazione di file e cartelle su un disco. Permette di salvare, leggere, modificare e cancellare file, ma non offre funzionalit√† avanzate per la gestione strutturata dei dati.
Un database, invece, √® progettato per archiviare, organizzare e gestire dati strutturati (ad esempio, in tabelle) e offre funzionalit√† come query, transazioni, integrit√† dei dati e sicurezza. Permette di cercare e manipolare i dati in modo efficiente tramite linguaggi come SQL.
In sintesi: il filesystem gestisce file, il database gestisce dati strutturati.


### **Confronto database Tabellare**

| **Caratteristica**       | **Relazionale**                     | **Non Relazionale**               |
|---------------------------|-------------------------------------|----------------------------------|
| **Struttura**             | Tabelle (righe e colonne)          | Documenti, grafi, colonne, chiavi-valori |
| **Schema**                | Rigido (schema-on-write)*           | Flessibile (schema-on-read)      |
| **Scalabilit√†**           | Verticale                          | Orizzontale                       |
| **Adatto per**            | Dati strutturati                   | Dati non strutturati/semi-strutturati |
| **Esempi di database**    | MySQL, PostgreSQL, Oracle          | MongoDB, Cassandra, Neo4j         |
| **Query**                 | SQL                                | API specifiche o linguaggi NoSQL  |

* "Schema rigido on write" significa che, quando si scrivono dati in un database, questi devono rispettare una struttura (schema) predefinita e obbligatoria. Ogni record deve avere i campi, i tipi di dati e le regole stabilite dallo schema, altrimenti la scrittura viene rifiutata

In pratica:
- Prima di inserire dati, lo schema (ad esempio tabelle e colonne in SQL) deve essere gi√† definito.
- Non puoi aggiungere dati con campi diversi o mancanti rispetto allo schema.
- Questo garantisce coerenza e integrit√† dei dati, ma riduce la flessibilit√† rispetto a sistemi con schema dinamico (come MongoDB).

---

Tipologie di Schema
Nel contesto dei dati e dei database, esistono diverse tipologie di schema:
- Schema-on-write: Lo schema viene applicato ai dati al momento della scrittura. I dati devono rispettare una struttura predefinita (tipico dei database relazionali).
- Schema-on-read: Lo schema viene applicato solo quando i dati vengono letti. I dati possono essere archiviati in modo flessibile e la struttura viene imposta solo in fase di query (tipico di Hive, HDFS, sistemi Big Data).
- Schema rigido: Struttura fissa e obbligatoria, difficile da modificare (es. RDBMS).
- Schema flessibile/dinamico: Struttura variabile, adattabile a dati diversi (es. NoSQL, MongoDB).
Nei Data Warehouse:
- Star Schema: Tabella dei fatti centrale collegata a tabelle di dimensione.
- Snowflake Schema: Variante normalizzata dello star schema, con dimensioni suddivise in pi√π tabelle.
- Fact Constellation (Galaxy Schema): Pi√π tabelle dei fatti che condividono dimensioni comuni.
Queste tipologie influenzano la flessibilit√†, la scalabilit√† e le modalit√† di gestione dei dati nei diversi sistemi.
In sintesi, i dati relazionali sono ideali per applicazioni aziendali tradizionali con dati strutturati, mentre i dati non relazionali sono pi√π adatti per scenari moderni che richiedono flessibilit√† e scalabilit√†.

---

### **Concetto fondamentale: Database vs Schema**

#### **Spesso confusi, ma sono diversi:**

**Database (DB):**
- √à l'**intero contenitore** di dati e metadati
- √à il **livello pi√π alto di organizzazione**
- Raggruppa pi√π tabelle correlate (namespace Hive)
- Esempio: `hive_warehouse`, `analytics_db`

 **Schema:**
- √à la **struttura** di una singola tabella
- Definisce colonne, tipi di dati, vincoli
- √à l'**intestazione** di una tabella
- Esempio: `(id INT, name STRING, salary DECIMAL)`

#### **Analogia visiva:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Database: hive_warehouse               ‚îÇ  ‚Üê Intero cassetto
‚îÇ                                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Table: employees                  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Schema: id INT, name STRING,      ‚îÇ ‚îÇ  ‚Üê Struttura colonne
‚îÇ  ‚îÇ         salary DECIMAL            ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Data (rows):                      ‚îÇ ‚îÇ  ‚Üê Dati effettivi
‚îÇ  ‚îÇ 1, John, 50000                    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ 2, Jane, 60000                    ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Table: departments                ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Schema: dept_id INT,              ‚îÇ ‚îÇ
‚îÇ  ‚îÇ         dept_name STRING          ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### **In SQL/Hive:**

```sql
-- Creare un DATABASE (contenitore)
CREATE DATABASE hive_warehouse;

-- Creare una TABELLA con SCHEMA definito (struttura)
CREATE TABLE hive_warehouse.employees (
    id INT,                    -- ‚Üì Questo √® lo SCHEMA
    name STRING,               -- Definisce la struttura
    salary DECIMAL             -- della tabella
);

-- Inserire DATA (dati effettivi)
INSERT INTO employees VALUES (1, 'John', 50000);
```

#### **Differenze chiave:**

| **Aspetto**       | **Database**                     | **Schema**                         |  
| **Cos'√®?**        | Contenitore/namespace            | Struttura di una singola tabella   |
| **Livello**       | Alto (raggruppa tabelle)         | Basso (singola tabella)            |
| **Comando SQL**   | `CREATE DATABASE mydb;`          | `CREATE TABLE mydb.mytable (...)`  |
| **Contiene**      | Molteplici tabelle               | Definizione colonne + tipi + vincoli |
| **Esempio**       | `analytics_db`, `sales_db`       | `(id INT, name STRING, date DATE)` |
| **Modifica**      | Raro (cambio struttura db)       | Pi√π frequente (ALTER TABLE)        |

#### **Nel contesto Cloudera/Hive:**

- **Hive Database** = Namespace che raggruppa tabelle correlate
  ```sql
  CREATE DATABASE sales;  -- database per dati vendite
  CREATE TABLE sales.transactions (...);
  CREATE TABLE sales.customers (...);
  ```

- **Hive Schema** = Definizione della tabella (colonne + tipi)
  ```sql
  CREATE TABLE sales.transactions (
      transaction_id INT,
      customer_id INT,
      amount DECIMAL(10,2),
      transaction_date DATE
  );
  -- ‚Üë Questa √® la struttura (schema) della tabella
  ```



#### **Per l'esame CDP:**

‚ö†Ô∏è Assicurati di capire:
- **Database**: namespace logico che organizza tabelle correlate
- **Schema**: la struttura fisica di una tabella (colonne + tipi)
- **Metastore Hive**: dove vengono archiviati i metadati (info su database e schema)
- **Atlas**: catalogo che documenta database, schema, lineage, ownership

---

### Google: La rivoluzione (2003-2004)

#### **Timeline chiara: Da Google a Hadoop**

**2003‚Äì2004: Google pubblica i paper rivoluzionari**

**Google File System (GFS) - 2003**
Google pubblic√≤ un paper rivoluzionario sul **Google File System**.

**‚ö†Ô∏è Importante:** Nel 2003 **Hadoop non esisteva ancora**. Non si "parlava di Hadoop" mentre Google creava GFS.

**Problemi che GFS risolveva:**
- Storage distribuito su migliaia di server commodity
- Fault tolerance automatica
- Alta throughput per grandi file
- Gestione petabyte di dati web

**Paper:** "The Google File System" - Ghemawat, Gobioff, Leung (SOSP 2003)


**MapReduce (Google, 2004)**
- Google pubblica il paper "MapReduce: Simplified Data Processing on Large Clusters" (Dean, Ghemawat).
- Concetti chiave:
   - Map: elaborazione parallela dei dati
   - Reduce: aggregazione dei risultati
   - Scalabilit√† lineare: pi√π nodi = pi√π performance
   - Fault tolerance: retry automatico dei task falliti
- Google non rilascia codice open source, solo paper.

**2005‚Äì2006: Nasce Hadoop, implementazione open source di GFS**
- Doug Cutting (su Apache Nutch) crea l‚Äôimplementazione open source ispirata ai paper di Google:
   - HDFS (da GFS)
   - MapReduce (da Google MapReduce)
- Nel 2003 non esisteva Hadoop, ma si discutevano gi√† i problemi di Big Data e scalabilit√†.
- GFS (Google File System) viene prima (2003), Hadoop nasce dopo (2006) come reimplementazione open source.

**Apache Hadoop: La nascita 2006**
- Doug Cutting e Mike Cafarella (ex Yahoo!) implementano Hadoop per creare un motore di ricerca web scalabile.
- Nome "Hadoop": elefante di peluche del figlio di Doug Cutting.
- Componenti iniziali: HDFS e MapReduce.
- 2006: Hadoop come sottoprogetto di Apache Nutch.
- 2008: Hadoop diventa progetto Apache top-level.

Def. attuale di Hadoop:  √® un framework* open source per l‚Äôarchiviazione e l‚Äôelaborazione distribuita di grandi quantit√† di dati (Big Data) su cluster di computer. √à composto principalmente da:

HDFS (Hadoop Distributed File System): file system distribuito che memorizza i dati su pi√π nodi.
MapReduce: modello di programmazione per elaborare dati in parallelo.
Altri componenti: YARN (gestione delle risorse), Hive, Pig, ecc.
---
*Un framework √® una piattaforma software composta da un insieme di componenti utilizzabili (librerie, strumenti, regole e convenzioni) che fornisce una struttura di base per sviluppare applicazioni in modo pi√π semplice, veloce e standardizzato.
In pratica, un framework:
- Definisce l‚Äôarchitettura e il ‚Äúmodello‚Äù dell‚Äôapplicazione.
- Fornisce funzionalit√† gi√† pronte (es. gestione database, sicurezza, interfaccia utente).
- Impone delle regole e un flusso di lavoro (inversione del controllo: √® il framework che chiama il tuo codice, non viceversa).
Ad esempio posso citare le seguenti:
- Apache Hadoop: framework per l‚Äôelaborazione distribuita di Big Data.
- Spring: framework per lo sviluppo di applicazioni Java.
- Django: framework per applicazioni web in Python.
- Angular: framework per lo sviluppo di applicazioni web front-end in JavaScript.

### Yahoo!: Il primo grande utilizzatore (2006-2008)

**Yahoo! assunse Doug Cutting nel 2006** per sviluppare Hadoop internamente.

**Motivi:**
- Indicizzare miliardi di pagine web
- Competere con Google nella ricerca web
- Ridurre costi infrastrutturali

**Investimenti Yahoo! in Hadoop:**
- Team dedicato di sviluppo
- Cluster da migliaia di nodi
- Contributi open source massicci
- Test in produzione su scala web

**Risultato:** Yahoo! dimostr√≤ che Hadoop poteva scalare a livelli enterprise.

---

### Facebook: Big data sociale (2007-2008)

**Facebook** inizi√≤ ad usare Hadoop per analytics sui dati utenti.

**Contributi di Facebook:**
- **Apache Hive** (2008) - SQL su Hadoop
- Processing di log massivi
- Analytics comportamentali utenti
- Data warehouse distribuito

**Jeff Hammerbacher** (co-fondatore di Cloudera) era il data team lead di Facebook.

---

### Il problema che Hadoop risolse

**Prima di Hadoop (2003-2006):**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Aziende con big data (Google, Yahoo!)   ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ Opzioni:                                ‚îÇ
‚îÇ 1. Build custom distributed systems     ‚îÇ
‚îÇ    ‚Üí Costi: milioni $, anni sviluppo    ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ 2. Buy expensive appliance              ‚îÇ
‚îÇ    ‚Üí Costi: $$$, no flessibilit√†        ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ 3. Non fare analytics                   ‚îÇ
‚îÇ    ‚Üí Perdere insights business          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Dopo Hadoop (2006-2008):**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Hadoop open source                      ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ ‚úÖ Commodity hardware (economico)       ‚îÇ
‚îÇ ‚úÖ Scalabilit√† orizzontale infinita     ‚îÇ
‚îÇ ‚úÖ Fault tolerance nativa               ‚îÇ
‚îÇ ‚úÖ Open source (no vendor lock-in)      ‚îÇ
‚îÇ ‚úÖ Dati non strutturati (log, testo)    ‚îÇ
‚îÇ ‚úÖ Schema-on-read (flessibilit√†)        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

### La sfida: Hadoop era difficile (2006-2008)

**Problemi di Hadoop "raw":**
- ‚ùå No gestione centralizzata (manuale)
- ‚ùå Installazione complessa
- ‚ùå Security minima (no autenticazione/autorizzazione)
- ‚ùå No monitoring/alerting
- ‚ùå No supporto enterprise
- ‚ùå Solo per esperti Linux/Java
- ‚ùå No governance/auditing

**Opportunit√† per Cloudera:**
Rendere Hadoop **enterprise-ready** con:
- Manager centralizzato
- Distribuzione pacchettizzata
- Security integrata
- monitoring/alerting
- Supporto professionale
- Governance e compliance

---

## 0.0 Come √® nata Cloudera

### 0.0.1 Le origini (2008)

**Cloudera** √® stata fondata nel 2008 da:
- Doug Cutting (creatore di Hadoop)
- Christophe Bisciglia (ex-Google)
- Amr Awadallah (ex-Yahoo!)
- Jeff Hammerbacher (ex-Facebook)

**Missione originale:** commercializzare Apache Hadoop e renderlo enterprise-ready.

---

## 0.1 Prima di CDP: CDH e HDP

### 0.1.1 Cloudera Distribution for Hadoop (CDH)

**CDH** (2009-2020) era la distribuzione Hadoop di Cloudera.

**Caratteristiche:**
- Componenti: Hadoop, HDFS, MapReduce, YARN, Hive, Impala, HBase, Spark
- Versioni: CDH 4, CDH 5, CDH 6
- Manager: Cloudera Manager (GUI per gestione cluster)
- Security: Cloudera Navigator (audit/lineage), Sentry (authorization)
- Deployment: on-premise (bare metal)

**Limitazioni:**
- Solo on-premise
- Architettura monolitica
- Scaling verticale/orizzontale limitato
- Sicurezza frammentata (tool separati)

---

### 0.1.2 Hortonworks Data Platform (HDP)

**Hortonworks** (fondata 2011) era il competitor principale di Cloudera.

**HDP** caratteristiche:
- 100% open source (no codice proprietario)
- Componenti: Hadoop, YARN, Hive, HBase, Kafka, Storm, Ranger, Atlas
- Manager: Ambari (GUI cluster management)
- Security: Ranger (authorization), Knox (gateway), Atlas (metadata)
- Philosophy: "enterprise Hadoop without vendor lock-in"

**Differenze CDH vs HDP:**

| Aspetto | CDH (Cloudera) | --------------------------| HDP (Hortonworks) |
|---------|----------------|-------------------------- |-------------------|
| Filosofia | Enterprise + alcune feature proprietarie | 100% open source |
| SQL Engine | Impala (proprietario, veloce)           | Hive + Tez |
| Manager | Cloudera Manager                           | Ambari |
| Security | Sentry + Navigator                        | Ranger + Knox + Atlas |
| Target | Enterprise con budget                       | Open source enthusiast |
| Support | Subscription commerciale                   | Subscription + community |

---

## 0.2 La fusione Cloudera (CDH) + Hortonworks (HDP) (2019)

### 0.2.1 Merger announcement (Ottobre 2018)

**Motivo della fusione:**
- Competizione cloud (AWS, Azure, GCP stavano dominando)
- Necessit√† di unire forze contro cloud provider
- Combinare best-of-breed di entrambe le piattaforme

**Nuovo nome:** Cloudera (mantiene il brand)

**Valore:** ~$5.2 miliardi USD

---

### 0.2.2 Cosa √® cambiato dopo la fusione

‚úÖ **Combinazione tecnologie:**
- Impala (da CDH) + Ranger/Atlas (da HDP)
- Cloudera Manager + features di Ambari
- Best security/governance di entrambe

‚úÖ **Nuova vision:**
- Hybrid/multi-cloud (non solo on-premise)
- Enterprise Data Cloud
- Data lifecycle completo (ingest ‚Üí process ‚Üí serve ‚Üí protect)

---

## 0.3 Nascita di CDP (Cloudera Data Platform)

### 0.3.1 Lancio CDP (2019-2020)

**CDP** √® la piattaforma unificata che sostituisce CDH e HDP (Che prima erano unite).

**Novit√† rispetto a CDH/HDP:**
- ‚úÖ **Hybrid cloud** (on-premise + AWS + Azure + GCP)
- ‚úÖ **SDX integrato** (Shared Data Experience: security + governance unificate)
- ‚úÖ **Containerizzazione** (Kubernetes per Data Services)
- ‚úÖ **Separation of storage and compute** (invece di tight coupling)
- ‚úÖ **Cloud-native architecture** (auto-scaling, serverless)
- ‚úÖ **Data Services modulari** (CDE, CDW, COD, CML, CDF)

---

### 0.3.2 Versioni CDP

**CDP Private Cloud Base** (ex-CDH/HDP on-premise)
- Deployment: on-premise, bare metal
- Componenti: Cloudera Runtime (Hadoop, Spark, Hive, Impala, ecc.)
- Manager: Cloudera Manager
- Security: SDX (Ranger + Atlas integrati)
- Target: aziende con data center esistenti, compliance strict

**CDP Private Cloud Data Services** (nuovo, containerizzato, microservizi)
- Deployment: on-premise Kubernetes (OpenShift, ECS)
- Architettura: containerized, microservices
- Data Services: CDE, CDW, CML
- Target: aziende on-premise che vogliono cloud-like experience

**CDP Public Cloud** (cloud-native)
- Deployment: AWS, Azure, GCP
- Managed service (Cloudera gestisce control plane)
- Auto-scaling, elastic, pay-as-you-go
- Data Services: CDE, CDW, COD, CML, CDF
- Target: aziende cloud-first, workload variabili

---

Per ‚Äúdata services‚Äù si intendono servizi o componenti software che gestiscono, forniscono, trasformano o espongono dati a diverse applicazioni o utenti. 
I data services possono includere:
- Accesso e integrazione di dati da fonti diverse (database, file, API, ecc.)
- Trasformazione, pulizia e arricchimento dei dati
- Esposizione dei dati tramite API, servizi web o endpoint
- Sicurezza, controllo degli accessi e gestione delle autorizzazioni sui dati
- Monitoraggio, logging e auditing delle operazioni sui dati
In sintesi, i data services permettono di rendere i dati disponibili, affidabili e utilizzabili in modo centralizzato e controllato, spesso come parte di architetture moderne (es. microservizi, data lake, data warehouse, ecc.).

## 0.4 Differenze architetturali: CDH/HDP ‚Üí CDP

### 0.4.1 Differenze fisiche (infrastruttura)

| Aspetto | CDH/HDP (legacy) | CDP |
|---------|------------------|-----|
| **Deployment** | Bare metal on-premise | Hybrid: on-premise + cloud |
| **Architettura** | Monolitica (tutto su un cluster) | Modulare (Data Services separati) |
| **Storage/Compute** | Tightly coupled (HDFS locale) | Separated (S3/ADLS + compute elastico) |
| **Scaling** | Verticale/orizzontale hardware | Elastic cloud-native (auto-scaling) |
| **Containers** | No (bare metal JVMs) | S√¨ (Kubernetes) |
| **Hardware** | Commodity servers permanenti | Cloud VMs ephemeral |
| **Network** | Intra-cluster (rack-local) | Cloud VPC + cross-region |

---

### 0.4.2 Differenze logiche (software/architettura)

**Sicurezza e governance:**

| Aspetto | CDH | HDP | CDP |
|---------|-----|-----|-----|
| **Authorization** | Sentry | Ranger | Ranger (unified) |
| **Metadata/Lineage** | Navigator | Atlas | Atlas (unified) |
| **Gateway** | Knox (add-on) | Knox | Knox (integrated) |
| **Encryption** | Navigator Encrypt + HDFS TDE | HDFS TDE | HDFS TDE + cloud KMS |
| **Integrazione** | Tool separati | Tool separati | **SDX (tutto integrato)** |

**Management:**

| Aspetto | CDH | HDP | CDP |
|---------|-----|-----|-----|
| **Cluster manager** | Cloudera Manager | Ambari | Cloudera Manager (enhanced) |
| **Monitoring** | Cloudera Manager | Ambari + external | Cloudera Manager + Workload XM |
| **Replication** | Cloudera Manager | Ambari + Falcon | Replication Manager (unified) |

**Data Services (nuovo in CDP):**

CDH/HDP non avevano servizi modulari cloud-native.

CDP introduce i seguenti servizi modulari cloude-native:
- **CDE** (Cloudera Data Engineering) - Spark as a Service
- **CDW** (Cloudera Data Warehouse) - Hive/Impala virtual warehouses
- **COD** (Cloudera Operational DB) - HBase as a Service
- **CML** (Cloudera Machine Learning) - ML workspace unificato
- **CDF** (Cloudera DataFlow) - NiFi as a Service

Questi sono **containerizzati**, **auto-scaling**, **indipendenti**.

---

### 0.4.3 Storage: da HDFS locale a object storage

**CDH/HDP:**
```
Cluster on-premise
‚îÇ
‚îú‚îÄ‚îÄ Nodo 1: HDFS DataNode + YARN NodeManager + Compute
‚îú‚îÄ‚îÄ Nodo 2: HDFS DataNode + YARN NodeManager + Compute
‚îî‚îÄ‚îÄ Nodo 3: HDFS DataNode + YARN NodeManager + Compute

Storage e compute sono ACCOPPIATI (tightly coupled)
```

**CDP Public Cloud:**
```
Cloud Storage (S3/ADLS/GCS) ‚Üí Storage separato, persistente
          ‚Üì
Ephemeral Compute Cluster (auto-scaling)
- Spark executors
- Hive/Impala workers
- Containers Kubernetes

Storage e compute sono SEPARATI (decoupled)
```

**Vantaggi separation of storage/compute:**
- ‚úÖ Scale storage e compute indipendentemente
- ‚úÖ Compute ephemeral (crea/distruggi cluster on-demand)
- ‚úÖ Storage persistente (dati rimangono su S3/ADLS)
- ‚úÖ Costo ridotto (paga solo compute quando serve)
- ‚úÖ Durability cloud-native (11 nines su S3)

---

##### **1. CDP Public Cloud ‚òÅÔ∏è**
**‚úÖ S√å - Storage SEMPRE separato e SEMPRE in cloud**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  CDP Public Cloud Architecture                          ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  Compute Layer  ‚îÇ   ‚Üê‚Üí    ‚îÇ  Storage Layer       ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  (Ephemeral)    ‚îÇ         ‚îÇ  (Persistent)        ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ         ‚îÇ                      ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ CDE (Spark)   ‚îÇ         ‚îÇ ‚Ä¢ S3 (AWS)           ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ CDW (Hive)    ‚îÇ         ‚îÇ ‚Ä¢ ADLS (Azure)       ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ CML (ML)      ‚îÇ         ‚îÇ ‚Ä¢ GCS (Google Cloud) ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ COD (HBase)   ‚îÇ         ‚îÇ                      ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ         ‚îÇ Object Storage       ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ Auto-scaling    ‚îÇ         ‚îÇ Durable, scalable    ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Caratteristiche:**
- **Storage:** Object storage cloud (S3, ADLS Gen2, GCS)
- **Compute:** Cluster effimeri (EC2, Azure VMs, GCE instances)
- **Architettura:** Completamente disaccoppiata
- **Location:** Tutto in cloud (AWS/Azure/GCP)

**Vantaggi:**
- üöÄ **Elasticit√† totale:** scala compute senza toccare storage
- üí∞ **Costi ottimizzati:** paghi compute solo quando lo usi
- üîí **Durabilit√†:** dati persistono anche cancellando cluster
- ‚ôªÔ∏è **Multi-workload:** stessi dati accessibili da CDE, CDW, CML simultaneamente (Dai micro servizi visti ora)
- üåç **Global:** replica dati cross-region facilmente

**Esempio pratico:**
```
Data Lake su S3 (us-east-1)
    ‚Üì
‚îú‚îÄ CDE Virtual Cluster #1 (Spark batch)
‚îÇ   ‚îî‚îÄ Scala/scompare on-demand
‚îÇ
‚îú‚îÄ CDW Virtual Warehouse (Impala query)
‚îÇ   ‚îî‚îÄ Auto-scale basato su query load
‚îÇ
‚îî‚îÄ CML Workspace (data scientists)
    ‚îî‚îÄ Jupyter notebooks leggono/scrivono stesso Data Lake
```

---

##### **2. CDP Private Cloud Base üè¢**
**‚ùå NO - Storage e Compute ACCOPPIATI (architettura tradizionale Hadoop)**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  CDP Private Cloud Base Architecture                    ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  Ogni nodo ha STORAGE + COMPUTE insieme                 ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ Nodo 1: HDFS DataNode + YARN NodeManager         ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ         [Storage locale] + [Compute]             ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ Nodo 2: HDFS DataNode + YARN NodeManager         ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ         [Storage locale] + [Compute]             ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ Nodo 3: HDFS DataNode + YARN NodeManager         ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ         [Storage locale] + [Compute]             ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  On-premise, bare metal servers                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Caratteristiche:**
- **Storage:** HDFS locale sui nodi del cluster
- **Compute:** YARN NodeManager sugli stessi nodi
- **Architettura:** Tightly coupled (heritage da CDH/HDP)
- **Location:** On-premise (data center aziendale)

**Perch√© √® accoppiato:**
- üìç **Data locality:** compute preferisce elaborare dati locali (stessa macchina)
- üèóÔ∏è **Architettura legacy:** eredit√† da Hadoop originale (2006-2015)
- üîß **Hardware fisico:** server bare metal permanenti

**Limitazioni:**
- ‚ö†Ô∏è Non puoi scalare storage senza aggiungere nodi compute
- ‚ö†Ô∏è Non puoi scalare compute senza aggiungere storage HDFS
- ‚ö†Ô∏è Cluster sempre accesi (no elasticit√† on-demand)

---

##### **3. CDP Private Cloud Data Services üè¢‚òÅÔ∏è**
**‚úÖ S√å - Storage separato (on-premise ma cloud-like)**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  CDP Private Cloud Data Services Architecture           ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  Compute Layer  ‚îÇ   ‚Üê‚Üí    ‚îÇ  Storage Layer       ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  (Kubernetes)   ‚îÇ         ‚îÇ  (Object Storage)    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ         ‚îÇ                      ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ CDE Pods      ‚îÇ         ‚îÇ ‚Ä¢ Ozone              ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ CDW Pods      ‚îÇ         ‚îÇ ‚Ä¢ MinIO              ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ CML Pods      ‚îÇ         ‚îÇ ‚Ä¢ NetApp StorageGRID ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ         ‚îÇ ‚Ä¢ Dell ECS           ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ OpenShift/ECS   ‚îÇ         ‚îÇ                      ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  On-premise, but cloud-native architecture              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Caratteristiche:**
- **Storage:** Object storage on-premise (Ozone, MinIO, NetApp, Dell ECS),i dati risiedono in sistemi di object storage esterni, separati dal cluster di calcolo
- **Compute:** Container orchestration (Kubernetes: OpenShift o ECS Anywhere)
- **Architettura:** Separata, cloud-native in data center
- **Location:** On-premise ma con modello cloud

**Vantaggi:**
- ‚úÖ Separazione storage/compute come il cloud pubblico
- ‚úÖ Auto-scaling dei Data Services
- ‚úÖ Containerizzazione (portabilit√†)
- ‚úÖ Rimane on-premise (compliance/data sovereignty)

---

##### **Tabella Riepilogativa**

| **CDP Deployment**               | **Storage Separato?** | **In Cloud?** | **Storage Type**        | **Compute Type**          |
|----------------------------------|-----------------------|---------------|-------------------------|---------------------------|
| **CDP Public Cloud**             | ‚úÖ S√å                 | ‚úÖ S√å         | S3/ADLS/GCS (object)   | Cloud VMs (ephemeral)     |
| **CDP Private Cloud Base**       | ‚ùå NO                 | ‚ùå NO         | HDFS (local disks)     | Bare metal (permanent)    |
| **CDP Private Cloud Data Services** | ‚úÖ S√å              | ‚ùå NO         | Ozone/MinIO (object)   | Kubernetes pods (elastic) |

---

##### **In sintesi (rispondendo alla tua domanda):**

**"In CDP lo storage √® sempre separato dal compute ed in cloud?"**

**Risposta:**
- **CDP Public Cloud:** ‚úÖ S√å, sempre separato + sempre cloud (AWS/Azure/GCP)
- **CDP Private Cloud Base:** ‚ùå NO, accoppiato + on-premise (HDFS tradizionale)
- **CDP Private Cloud Data Services:** ‚úÖ Separato ma ‚ùå on-premise (cloud-like architecture ma on prem)

**Quindi:**
- ‚úÖ **Cloud = Sempre separato**
- ‚ùå **On-premise Base = Mai separato** (tightly coupled)
- ‚ö° **On-premise Data Services = Separato ma non cloud** (hybrid model)

---

### 0.4.4 Da monolite a microservizi

**CDH/HDP (monolite):**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Cluster unico on-premise            ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ ‚îÇ HDFS + YARN + Hive + Spark +    ‚îÇ ‚îÇ
‚îÇ ‚îÇ HBase + Kafka + tutto insieme   ‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```
- Un cluster fa tutto
- Upgrade = downtime di tutto
- Resource contention tra workload

**CDP (microservizi):**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ CDE (Spark)    ‚îÇ  ‚îÇ CDW (Hive)     ‚îÇ  ‚îÇ CML (ML)       ‚îÇ
‚îÇ Auto-scaling   ‚îÇ  ‚îÇ Auto-scaling   ‚îÇ  ‚îÇ Isolated       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚Üì                   ‚Üì                   ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ SDX (Shared Data Experience)                             ‚îÇ
‚îÇ Ranger + Atlas + Metastore                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Data Lake (S3/ADLS/GCS)                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```
- Servizi indipendenti
- Upgrade indipendenti (zero downtime)
- Isolamento risorse
- Governance condivisa (SDX)

---

## 0.5 Timeline evolutiva

```
2008 ‚Üí Cloudera fondata
2009 ‚Üí CDH 1 (prima distribuzione Hadoop commerciale)
2011 ‚Üí Hortonworks fondata
2012 ‚Üí CDH 4 (Impala lanciato)
2013 ‚Üí HDP 2.0 (Ranger, Atlas)
2014 ‚Üí CDH 5 (Spark integrato)
2017 ‚Üí CDH 6 (ultima major release CDH)
2018 ‚Üí Merger Cloudera + Hortonworks annunciato
2019 ‚Üí Merger completato, CDP annunciato
2020 ‚Üí CDP Public Cloud GA (General Availability)
2021 ‚Üí CDP Private Cloud Data Services GA
2023 ‚Üí CDP evoluzione continua (nuovi Data Services)
```
---
## 0.6 Perch√© CDP √® importante per l'esame

**L'esame CDP-0011 testa:**
1. Conoscenza componenti (heritage da CDH/HDP)
2. Architettura moderna (cloud-native, SDX)
3. Differenze Public vs Private Cloud
4. Data Services (nuovo in CDP)

**Non chiede:**
- Dettagli su CDH/HDP legacy (obsoleti)
- Ambari (sostituito da Cloudera Manager)
- Sentry (sostituito da Ranger)

**Focus:** CDP come piattaforma unificata moderna.

---

## 0.7 Riepilogo: cosa devi sapere

‚úÖ **CDP unisce best-of-breed di CDH e HDP**
‚úÖ **SDX √® il cuore (Ranger + Atlas + Metastore unificati)**
‚úÖ **Hybrid cloud: Private Cloud Base + Public Cloud**
‚úÖ **Separation of storage and compute (cloud-native)**
‚úÖ **Data Services containerizzati e auto-scaling**
‚úÖ **Security/governance integrate by design**

‚ùå **Non serve sapere:** dettagli CDH/HDP specifici, Ambari, Sentry

*SDX (Shared Data Experience) √® una componente della piattaforma Cloudera che gestisce in modo centralizzato la governance in cloudera, ossia:
- la sicurezza e privacy, 
- il catalogo dei dati, 
- e le policy di accesso ai dati nei cluster Big Data
- tracciamento e audit
- coerenza 

In pratica, SDX permette di centralizzare la gestione delle regole di sicurezza e privacy, assicurando che vengano applicate in modo coerente su tutti i servizi e i dati della piattaforma Cloudera, permettendo di:

- Definire e applicare regole di sicurezza e privacy sui dati (Mediante apache Ranger, Atlas e audit e monitoring).
- Gestire i metadati (informazioni sui dati) in modo unificato.
- Tracciare e monitorare chi accede ai dati e come vengono usati.
- Garantire coerenza e controllo su dati distribuiti tra diversi servizi (come Hadoop, Hive, Impala, ecc.).
- SDX semplifica la gestione dei dati in ambienti complessi, assicurando che le policy siano rispettate ovunque i dati vengano usati.

---

# PARTE 1: COMPONENTI PRINCIPALI CDP (15 domande)

---

## 0. HDFS ‚Äì Hadoop Distributed File System

### 0.1 Cos'√® HDFS

**HDFS** √® un **file system distribuito Java-based** per memorizzare grandi volumi di dati.

**Caratteristiche principali:**
- Storage scalabile su cluster di commodity server
- Replica automatica dei dati (default 3 copie)
- Fault tolerance nativa
- Write-once, read-many (ottimizzato per streaming)

### 0.2 Architettura HDFS

```
NameNode (master)
- Gestisce namespace del file system***
- Controlla metadata (nomi file, permessi, posizioni blocchi)
- Single point of failure (mitigato da HA)

DataNode (worker)
- Memorizza i blocchi di dati effettivi
- Invia heartbeat al NameNode
- Esegue letture/scritture su richiesta client
```

***‚ÄúGestisce namespace del file system‚Äù significa che il sistema (ad esempio HDFS) si occupa di organizzare e tenere traccia della struttura delle cartelle e dei file, dei loro nomi, delle gerarchie e dei percorsi. In pratica, il namespace √® l‚Äôinsieme di tutti i nomi (file e directory) e la loro organizzazione all‚Äôinterno del file system, come una mappa che dice dove si trova ogni file o cartella.
**Il file system √® il componente di un sistema operativo (o di una piattaforma come HDFS), ossia la componente logica che organizza, gestisce e memorizza i file e le cartelle su un dispositivo di archiviazione (come disco, SSD, ecc.). Permette di salvare, leggere, modificare e cancellare file, mantenendo la struttura gerarchica (cartelle, sottocartelle, percorsi) e gestendo i nomi e i permessi di accesso. In sintesi, √® il ‚Äúsistema‚Äù che tiene in ordine tutti i dati su un computer o cluster.
Si differenzia dal supporto di memorizzazione che √® la parte fisica.

### 0.3 Concetti chiave HDFS

| Concetto | Descrizione |
|----------|-------------|
| **Blocco** | Unit√† minima di storage (default 128MB/256MB) |
| **Replica** | Numero di copie di ogni blocco (default 3)   |
| **Rack Awareness** | Distribuisce repliche su rack diversi |
| **NameNode HA** | Secondary/Standby NameNode per failover  |

üëâ **Domanda tipica d'esame**
> HDFS √® ottimizzato per? ‚Üí **Grandi file, accesso sequenziale, throughput alto**
> Quante repliche default? ‚Üí **3**

---

## 0.5 Hue ‚Äì SQL Query Interface

### 0.5.1 Cos'√® Hue

**Hue** √® l'interfaccia web unificata interrogare dati con hive ed impala in CDP.

**Funzioni principali:**
- Editor SQL per Hive e Impala
- File browser HDFS
- Job browser (YARN, Oozie)
- Query history e saved queries

### 0.5.2 Hue e integrazione motori

Hue si connette a:
- **Hive** per query batch
- **Impala** per query interattive
- **YARN** per monitoring job
- **Oozie** per workflow

üëâ **Domanda tipica d'esame**
> Hue √® un motore SQL? ‚Üí **No, √® un'interfaccia web per Hive/Impala**

---

## 0.7 YARN ‚Äì Resource Manager

### 0.7.1 Cos'√® YARN

**Apache Hadoop YARN** √® il **resource manager** per applicazioni distribuite.

**Funzione principale:**
- Scheduling e allocazione risorse (CPU, RAM)
- Gestione container per applicazioni
- Monitoring e fault tolerance

### 0.7.2 Architettura YARN

```
ResourceManager (master)
- Scheduler globale
- Assegna risorse ai job

NodeManager (worker)
- Lancia container sui nodi
- Monitora utilizzo risorse

ApplicationMaster
- Negozia risorse per ogni applicazione
- Coordina esecuzione task
```

### 0.7.3 YARN e motori

YARN gestisce risorse per:
- MapReduce
- Spark
- Tez (Hive)

Al contrario, Impala non ha bisogno di YARN per funzionare, perch√© Impala √® composto da processi (daemon) che restano sempre attivi sui nodi del cluster.

YARN serve a gestire e schedulare risorse per applicazioni temporanee (come Spark o MapReduce), mentre Impala lavora come servizio sempre attivo, gestendo le query direttamente senza passare da YARN.

üëâ **Domanda tipica d'esame**
> YARN gestisce storage o compute? ‚Üí **Compute (CPU/RAM)**
> YARN √® necessario per Impala? ‚Üí **No, Impala √® long-running daemon**

---

## 0.9 Apache Spark

### 0.9.1 Cos'√® Spark

**Apache Spark** √® un **motore di elaborazione distribuita in-memory** per big data e analytics.

**Caratteristiche:**
- Elaborazione in-memory (10-100x pi√π veloce di MapReduce)
- API unificata*: batch**, streaming, ML, SQL, graph
- Supporta Scala, Java, Python, R
*permette di usare lo stesso insieme di comandi o funzioni per lavorare con diversi tipi di elaborazione dati: batch (dati statici), streaming (dati in tempo reale), machine learning (ML), SQL (query sui dati) e graph (analisi di grafi).
In pratica, con una sola interfaccia puoi gestire vari scenari e tecnologie senza dover imparare strumenti diversi per ogni tipo di elaborazione
** √® un‚Äôoperazione che esegue una serie di comandi o elaborazioni automaticamente, senza intervento umano, spesso su grandi quantit√† di dati.

### 0.9.2 Componenti Spark

| Componente | Funzione |
|------------|----------|
| **Spark Core** | Engine di base, RDD, task scheduling |
| **Spark SQL** | Query SQL su dati strutturati |
| **Spark Streaming** | Stream processing (micro-batch) |
| **MLlib** | Machine learning library |
| **GraphX** | Graph processing |

### 0.9.3 Spark vs MapReduce

| Aspetto | MapReduce | Spark |
|---------|-----------|-------|
| Storage intermedio | Disco (spill) | Memoria (RAM) |
| Latenza | Minuti | Secondi |
| Fault tolerance | Retry task | RDD lineage |
| API | Java MapReduce | Scala/Python/Java/R |

üëâ **Domanda tipica d'esame**
> Spark √® batch o streaming? ‚Üí **Entrambi**
> Perch√© Spark √® pi√π veloce? ‚Üí **Elaborazione in-memory**

---

## 0.11 Apache Oozie

### 0.11.1 Cos'√® Oozie

**Apache Oozie** √® un **workflow scheduler** per job Hadoop.

**Funzioni:**
- Orchestrazione job complessi (DAG - Directed Acyclic Graph)
- Scheduling basato su tempo o eventi
- Coordinamento dipendenze tra job

### 0.11.2 Tipi di job Oozie

| Tipo | Descrizione |
|------|-------------|
| **Workflow** | Sequenza di azioni (map, reduce, Spark, Hive, ecc.) |
| **Coordinator** | Workflow ricorrenti (schedule cron-like) |
| **Bundle** | Gruppi di coordinator |

### 0.11.3 Azioni supportate

Oozie supporta:
- MapReduce
- Spark
- Hive
- Sqoop
- Shell script
- Java

üëâ **Domanda tipica d'esame**
> Oozie √® un workflow scheduler? ‚Üí **S√¨**
> Combina job sequenzialmente? ‚Üí **S√¨**
> Supporta MiNiFi? ‚Üí **No**

---

## 0.13 Apache Kafka

### 0.13.1 Cos'√® Kafka

**Apache Kafka** √® una **piattaforma di streaming distribuita** ad alte prestazioni.

**Caratteristiche:**
- Publish-subscribe messaging*
- Storage persistente su disco
- Alta throughput (milioni msg/sec)
- Fault tolerance e replication

*Publish-subscribe messaging: √® un modello di comunicazione asincrona in cui i produttori (publisher) inviano messaggi a un canale o argomento (topic), senza conoscere i destinatari. I consumatori (subscriber) si iscrivono a uno o pi√π topic e ricevono solo i messaggi di loro interesse. Questo modello permette un forte disaccoppiamento tra chi produce e chi consuma i dati, ed √® molto usato in sistemi distribuiti, streaming e big data (es. Apache Kafka, RabbitMQ, Google Pub/Sub).
Un esempio concreto: in una piattaforma di e-commerce, quando un cliente effettua un ordine, il sistema invia un messaggio a un topic ‚Äúordini‚Äù. Diversi servizi (spedizioni, fatturazione, notifiche) sono iscritti a questo topic e ricevono automaticamente il messaggio per avviare le loro attivit√†, senza che il sistema di ordini debba conoscere i dettagli di ciascun servizio. Questo √® possibile grazie a tecnologie come Apache Kafka o Google Pub/Sub.

### 0.13.2 Concetti chiave Kafka

| Concetto | Descrizione |
|----------|-------------|
| **Topic** | Categoria/feed di messaggi |
| **Producer** | Pubblica messaggi su topic |
| **Consumer** | Legge messaggi da topic |
| **Broker** | Nodo Kafka che memorizza dati |
| **Partition** | Shard di un topic per parallelismo |

### 0.13.3 Kafka use cases

- Real-time streaming analytics
- Log aggregation
- Event sourcing
- Messaging tra microservizi

Ecco come Apache Kafka √® integrato nelle funzionalit√† di alcune aziende famose:

LinkedIn: quando un utente aggiorna il profilo, l‚Äôevento viene inviato da un producer (il servizio che gestisce i profili) a Kafka. Diversi consumer (ad esempio, sistemi di raccomandazione, notifiche, analytics) leggono questi eventi per aggiornare feed, suggerimenti o statistiche in tempo reale.

Netflix: i dati di visualizzazione degli utenti (cosa guardano, quando mettono in pausa, ecc.) vengono inviati dai servizi di streaming (producer) a Kafka. I consumer analizzano questi dati per suggerire nuovi contenuti o monitorare la qualit√† del servizio.

Uber: ogni volta che un utente richiede una corsa, l‚Äôevento viene pubblicato su Kafka. I consumer (servizi di calcolo prezzi, assegnazione autisti, notifiche) leggono questi messaggi per gestire la richiesta in tempo reale.

Airbnb: le attivit√† degli utenti (prenotazioni, recensioni, ricerche) sono inviate a Kafka dai vari servizi. I consumer usano questi dati per aggiornare la disponibilit√†, inviare conferme o analizzare le tendenze.

Twitter: i tweet, i like e i retweet sono inviati a Kafka dai servizi web (producer). I consumer (feed, analytics, sistemi di moderazione) leggono questi eventi per aggiornare le timeline e monitorare i contenuti.

In tutti questi casi, Kafka funge da ‚Äúponte‚Äù tra chi produce i dati e chi li consuma, garantendo scalabilit√† e affidabilit√†.

In sintesi, Kafka √® usato principalmente per gestire flussi di dati in tempo reale, logging, monitoraggio, analisi e integrazione tra microservizi.

Con Apache Kafka, i messaggi vengono distribuiti principalmente da server (broker Kafka) a client (consumer), ma anche da client (producer) a server (broker Kafka)

üëâ **Domanda tipica d'esame**
> Kafka √® storage o processing? ‚Üí **Entrambi (memorizza + distribuisce)**
> Kafka √® persistente? ‚Üí **S√¨, retention configurabile**

---

## 0.15 Apache NiFi

### 0.15.1 Cos'√® NiFi

**Apache NiFi** √® un **sistema per automatizzare il flusso di dati** tra sistemi.

**Caratteristiche:**
- GUI web drag-and-drop (visual programming)
- Connessioni a 300+ sorgenti/destinazioni
- Data provenance (tracciabilit√† completa)
- Backpressure handling

### 0.15.2 NiFi use cases

- Ingestione dati da sorgenti multiple
- Routing e trasformazione dati
- Data enrichment
- Push/pull da/verso sistemi esterni

### 0.15.3 NiFi vs Kafka

| Aspetto | NiFi | Kafka |
|---------|------|-------|
| Focus | Data flow orchestration | Messaging/streaming |
| GUI | S√¨ (visual) | No |
| Trasformazioni | S√¨ (native) | No (serve Kafka Streams) |
| Throughput | Medio/alto | Altissimo |

###La differenza pi√π distintiva tra Apache NiFi e Apache Kafka √® il loro scopo principale:

NiFi √® progettato per l‚Äôorchestrazione e l‚Äôautomazione dei flussi di dati, con una GUI visuale per il routing, la trasformazione e l‚Äôarricchimento dei dati tra sistemi diversi.
Kafka √® una piattaforma di messaging/streaming ad altissimo throughput, pensata per la distribuzione e la persistenza di flussi di messaggi in tempo reale tra produttori e consumatori.
In sintesi:
NiFi = orchestrazione e automazione dei flussi di dati
Kafka = distribuzione e streaming di messaggi

Ecco alcune aziende che usano Apache NiFi e le attivit√† per cui lo integrano:

- Cloudera: NiFi √® parte della piattaforma CDP per orchestrare flussi di dati tra sistemi, ingestione, routing, trasformazione e arricchimento dati.
- ING Bank: Usa NiFi per la gestione e l‚Äôautomazione dei flussi di dati tra sistemi bancari, compliance e data lineage.
- US Army: NiFi √® impiegato per la raccolta, il trasferimento e la trasformazione di dati provenienti da sensori e sistemi di intelligence.
- Leidos: Utilizza NiFi per integrare dati da fonti eterogenee in ambito difesa e intelligence.
- Oath (Yahoo): NiFi gestisce pipeline di dati per analisi, monitoraggio e data enrichment.
- Telefonica: NiFi √® usato per orchestrare flussi di dati tra sistemi di telecomunicazione, monitoraggio e analisi.

Le attivit√† principali sono: ingestione dati da molteplici sorgenti, orchestrazione e automazione dei flussi, trasformazione e arricchimento dati, data lineage, routing, compliance e integrazione tra sistemi diversi.

üëâ **Domanda tipica d'esame**
> NiFi ha GUI? ‚Üí **S√¨, web-based drag-and-drop**
> NiFi √® no-code? ‚Üí **S√¨, visual programming**

---

## 0.17 Apache HBase e Phoenix

### 0.17.1 Cos'√® HBase

**Apache HBase** √® un **database NoSQL* distribuito** per accesso real-time a big data.

**Caratteristiche:**
- Modello wide-column (colonne sparse)
- Accesso random read/write veloce
- Scalabilit√† orizzontale automatica
- Consistency strong (non eventual)

### 0.17.2 HBase use cases

- Time-series data
- Real-time analytics
- Messaggistica e social media feed
- IoT sensor data

*La differenza principale tra database SQL e NoSQL √® nel modello dei dati e nella flessibilit√†:

Database SQL (relazionali):

- Usano tabelle con schema rigido (colonne e tipi fissi).
- Supportano SQL per query, JOIN, transazioni ACID.
- Ideali per dati strutturati e relazioni complesse.

Esempi: MySQL, PostgreSQL, Oracle.

Database NoSQL:

- Modelli flessibili: documenti, key-value, colonne, grafi (Si fa presente quindi esiste anche lo schema colonnale nei NOSQL).
- Schema dinamico o assente, adatti a dati semi-strutturati o non strutturati.
- Scalabilit√† orizzontale, performance su grandi volumi e accessi distribuiti.
- Non usano SQL standard, niente JOIN classiche.

Esempi: MongoDB (documentale), Cassandra (colonnare), Redis (key-value), Neo4j (grafi).
In sintesi:

SQL = schema rigido, relazioni forti, query potenti
NoSQL = schema flessibile, scalabilit√†, adatto a dati variabili

## Casi D'uso

NoSQL:

- Facebook usa Cassandra (colonnare) per gestire messaggi e feed in tempo reale.
- Netflix usa DynamoDB (key-value/documentale) per la gestione delle sessioni utente e raccomandazioni.
- Twitter usa Redis (key-value) per caching e timeline degli utenti.
- LinkedIn usa HBase (colonnare) per analytics e messaggistica.

SQL:

- Bank of America usa Oracle Database per la gestione delle transazioni bancarie.
- Airbnb usa MySQL per gestire prenotazioni e dati degli utenti.
- Wikipedia usa MariaDB per l‚Äôarchiviazione delle pagine e delle revisioni.

In sintesi:

NoSQL √® scelto per attivit√† che richiedono alta scalabilit√†, gestione di grandi volumi di dati variabili, real-time e flessibilit√†.
SQL √® scelto per attivit√† che richiedono integrit√† dei dati, transazioni sicure e relazioni complesse tra dati.

## Ecco la comparazione tra HBase, Impala e Hive:

- HBase:
a) Database NoSQL wide-column
b) Accesso random veloce a singoli record
c) Scritture/letture in tempo reale
d) Schema flessibile
e) Ideale per time-series, IoT, social feed
- Impala:
a) Motore SQL MPP per query interattive
b) Analisi esplorativa su dati strutturati
c) Latenza molto bassa
d) Lavora su dati in HDFS, Parquet, ORC
e) Non adatto a scritture frequenti o accesso random
- Hive:
a) Data warehouse SQL sopra Hadoop
b) Analisi batch su grandi dataset
c) Latenza elevata (non adatto a query rapide)
d) Schema-on-read
e) Ideale per ETL, reporting massivo

Sintesi:
HBase = NoSQL, accesso random, real-time
Impala = SQL, query interattive, bassa latenza
Hive = SQL, analisi batch, alta latenza

### 0.17.3 Cos'√® Phoenix

**Apache Phoenix** √® un **layer SQL sopra HBase**.

Apache Phoenix √® un layer che permette di usare il linguaggio SQL sopra HBase, trasformando il database NoSQL in una piattaforma interrogabile con query simili a quelle di un database relazionale.

** Funzionalit√† principali di Phoenix:
- Consente di creare, modificare e interrogare tabelle HBase usando SQL standard (SELECT, INSERT, UPDATE, DELETE).
- Traduce le query SQL in operazioni native HBase, ottimizzando l‚Äôaccesso ai dati.
- Supporta indici secondari per velocizzare le ricerche.
- Offre un driver JDBC, cos√¨ applicazioni e strumenti BI possono collegarsi a HBase come a un normale database SQL.
- Gestisce transazioni e batch di operazioni.
- Permette di sfruttare la scalabilit√† e la velocit√† di HBase, ma con la semplicit√† di SQL.

üëâ **Domanda tipica d'esame**
> HBase √® relazionale? ‚Üí **No, NoSQL wide-column**
> Phoenix cosa fa? ‚Üí **SQL interface per HBase**

---

## 0.19 Apache Kudu

### 0.19.1 Cos'√® Kudu

**Apache Kudu** √® un **columnar storage engine** per Hadoop.

Kudu √® un database il quale serve in Cloudera serve per memorizzare e gestire dati che devono essere sia letti che scritti velocemente, anche in tempo reale. √à un database pensato per analisi veloci: permette di aggiungere, modificare e leggere dati subito, senza dover aspettare lunghi tempi di caricamento. Kudu √® ideale quando hai bisogno di aggiornare spesso i dati e fare analisi rapide, ad esempio per dashboard, report o applicazioni che lavorano con dati sempre aggiornati.
I dati vengono memorizzati in formato "colonnare" (orientato alle colonne), anzich√© "row-oriented" (orientato alle righe) come nei database tradizionali. In un database colonnare, i valori di ciascuna colonna sono memorizzati insieme, il che rende molto efficiente leggere solo alcune colonne di una tabella, tipico nelle analisi dati.

**Caratteristiche:**
- Memorizza in maniera colonnare i dati (come Parquet, ma mutabile), perch√® kudu memorizza i dati organizzandoli per colonne invece che per righe, come fanno i database tradizionali
- Fast analytics (scan) + fast updates/inserts
- Integrazione nativa con Impala e Spark
- ACID compliant

Ecco un esempio schematico di storage colonnare (come in Kudu) rispetto a quello tradizionale (row-based):

# Storage per righe (row-based):

|¬†ID¬†|¬†Nome¬†¬†¬†|¬†Et√†¬†|¬†Citt√†¬†¬†¬†¬†|
|----|--------|-----|----------|
|¬†1¬†¬†|¬†Anna¬†¬†¬†|¬†30¬†¬†|¬†Milano¬†¬†¬†|
|¬†2¬†¬†|¬†Marco¬†¬†|¬†25¬†¬†|¬†Roma¬†¬†¬†¬†¬†|
|¬†3¬†¬†|¬†Lucia¬†¬†|¬†28¬†¬†|¬†Torino¬†¬†¬†|

I dati sono memorizzati riga per riga.

# Storage per colonne (columnar, come Kudu):

Colonna¬†ID:¬†¬†¬†¬†1,¬†2,¬†3
Colonna¬†Nome:¬†¬†Anna,¬†Marco,¬†Lucia
Colonna¬†Et√†:¬†¬†¬†30,¬†25,¬†28
Colonna¬†Citt√†:¬†Milano,¬†Roma,¬†Torino
I dati sono memorizzati colonna per colonna.

Vantaggio:
Se vuoi analizzare solo la colonna ‚ÄúEt√†‚Äù, Kudu legge solo quella colonna, rendendo le query pi√π veloci ed efficienti.

### 0.19.2 Kudu vs HBase vs HDFS

| Aspetto | HDFS | HBase | Kudu |
|---------|------|-------|------|
| Workload | Batch analytics | Random access | Hybrid (analytics + updates) |
| Updates | Immutabile | Veloce | Veloce |
| Scans | Veloce | Lento | Veloce |
| Formato | File-based | Row-based | Column-based |

üëâ **Domanda tipica d'esame**
> Kudu √® colonnare? ‚Üí **S√¨**
> Kudu supporta update? ‚Üí **S√¨, ACID**
> Kudu sostituisce HDFS? ‚Üí **No, √® complementare**

---

# La lettura √® pi√π veloce nei database colonnari (come Kudu) perch√©:

1.‚ÄØSolo le colonne richieste vengono lette:
Se una query richiede solo 2 colonne su 20, il database legge solo quei dati, riducendo drasticamente il volume di dati da trasferire e processare.

2.‚ÄØMigliore compressione:
I dati simili (della stessa colonna) sono memorizzati insieme, facilitando la compressione e riducendo ulteriormente i dati da leggere.

3.‚ÄØAccesso sequenziale:
Le colonne sono memorizzate in blocchi contigui, permettendo letture sequenziali pi√π rapide dal disco.

Principi di una lettura colonnare:

Si selezionano solo le colonne necessarie.
Si leggono blocchi di dati compressi.
Si sfrutta la localit√† dei dati (tutti i valori di una colonna sono vicini tra loro).
Si evita di caricare dati inutili (le altre colonne).
Questo rende i database colonnari ideali per analisi e reportistica, dove spesso si lavora su poche colonne ma molte righe.

# Ecco perch√©, in uno storage per righe, la lettura di una singola colonna √® meno efficiente:

I dati di una riga sono memorizzati tutti insieme, uno dopo l‚Äôaltro (es: Col1, Col2, Col3, Col4 per la riga 1, poi Col1, Col2, Col3, Col4 per la riga 2, ecc.).
Se chiedi solo Col2, il database deve comunque leggere ogni riga intera dal disco, perch√© i valori di Col2 sono ‚Äúmischiati‚Äù con quelli delle altre colonne.
Dopo aver letto tutte le righe, estrae solo i valori di Col2, ma ha gi√† caricato anche gli altri dati (Col1, Col3, Col4), sprecando tempo e risorse di I/O.
Questo succede perch√© i dischi leggono blocchi di dati contigui: in uno storage per righe, ogni blocco contiene tutte le colonne di una riga, non solo quelle richieste.

In sintesi:

Lo storage per righe √® ottimale per operazioni che coinvolgono tutte le colonne di una riga (es. inserimenti, aggiornamenti, transazioni).
√à meno efficiente per analisi su poche colonne e molte righe, perch√© legge sempre dati in eccesso.

## 1. Ruolo di Hive e Impala nella Cloudera Data Platform

In **In cloudera**, **Hive** e **Impala** non sono alternative, ma **complementari**.

| Motore | Tipo di accesso | Caso d‚Äôuso principale |
|------|----------------|----------------------|
| Hive | SQL batch | ETL, reporting massivo |
| Impala | SQL interattivo | Analisi a bassa latenza |

üëâ **Domanda tipica d‚Äôesame**  
> Quale scegliere per query interattive? ‚Üí **Impala**  
> Quale per ETL batch? ‚Üí **Hive**

---

## 2. Apache Hive ‚Äì Approfondimento completo

## 2.1 Cos‚Äô√® Apache Hive

**Apache Hive** √® un **data warehouse distribuito** che fornisce:
- un livello SQL sopra Hadoop (Consente di scrivere query SQL-like per analizzare i dati in HDFS)
- √® uno strato sopra HDFS (Hive organizza i dati in tabelle e schemi, ossia le strutture delle tabelle), fornendo una struttura logica ai file grezzi in HDFS)
- uno schema-on-read (Lo schema viene applicato ai dati solo quando vengono letti (non al momento della scrittura).

Hive **non √® un database** e **non √® OLTP**.

---

## 2.2 Hive come strato semantico del Data Lake

Senza Hive, il Data Lake √® solo un insieme di file.  

Hive introduce:
- tabelle
- colonne
- tipi di dato
- partizioni

‚û°Ô∏è **Hive d√† significato al dato**

Questo √® fondamentale anche lato governance (Atlas, Ranger, auditing).

---

## 2.3 Hive Metastore (concetto CHIAVE per l‚Äôesame)

Il **Metastore** √® il componente pi√π importante di Hive.

### **Cosa memorizza il Metastore?**
1. **Definizione delle tabelle:**
   - Nomi delle tabelle e dei database.
2. **Schema delle tabelle:**
   - Colonne, tipi di dati*, vincoli.
3. **Partizioni:**
   - Informazioni sulle partizioni delle tabelle (es. `year=2025`, `region=EU`).
4. **Formati dei file:**
   - Specifica il formato di archiviazione (es. Parquet, ORC, TextFile).
5. **Location su HDFS / Object Storage:**
   - Percorso fisico dei dati (es. `hdfs://data/employees`).
6. **Metadati aggiuntivi:**
   - Statistiche (es. numero di righe, dimensione dei dati).

*le categorie che definiscono la natura dei valori che una colonna pu√≤ contenere in una tabella (esempi: interi, stringhe, date, booleani)
**Per vincoli si intendono le regole che limitano o controllano i valori che possono essere inseriti in una colonna o tabella.
Ad esempio 
NOT NULL: la colonna non pu√≤ avere valori nulli
UNIQUE: i valori devono essere unici
PRIMARY KEY: identifica univocamente ogni riga
FOREIGN KEY: collega una colonna a una chiave primaria di un‚Äôaltra tabella
CHECK: impone una condizione sui valori (es. et√† > 0)

### **Perch√© √® importante per l‚Äôesame?**
- **Concetto chiave:** Il Metastore √® il cuore di Hive, senza di esso non √® possibile interrogare i dati.
- **Domande tipiche:**
  - Cosa memorizza il Metastore?
  - Dove sono archiviati i metadati di Hive?

### **Esempio pratico:**
Per una tabella Hive:
```sql
CREATE TABLE employees (
    id INT,
    name STRING,
    salary DECIMAL
)
PARTITIONED BY (department STRING)
STORED AS PARQUET
LOCATION 'hdfs://data/employees';
```
Il Metastore memorizza:
- **Schema delle colonne:** `id INT`, `name STRING`, `salary DECIMAL`.
- **Partizioni:** `department STRING`.
- **Formato file:** `PARQUET`.
- **Percorso:** `hdfs://data/employees`.

---

## 2.4 Schema-on-read (concetto fondamentale)

Hive applica lo schema **in lettura**, non in scrittura.

Vantaggi:
- ingestione rapida
- flessibilit√†
- adattabilit√† a sorgenti diverse

Svantaggi:
- errori di schema emergono a query time
- maggiore responsabilit√† sullo strato analitico

üëâ **Domanda tipica d‚Äôesame**  
> Hive usa schema-on-read o schema-on-write? ‚Üí **schema-on-read**

---

## 2.5 Tipi di tabelle Hive

### Managed Tables
- Hive gestisce dati e metadati
- `DROP TABLE` elimina anche i file
- pi√π rischiose in ambienti enterprise

### External Tables
- Hive gestisce solo i metadati
- i dati restano esterni
- preferite nei Data Lake

üëâ **Domanda tipica d'esame**  
> Quali tabelle sono consigliate per Data Lake? ‚Üí **External**

---

## 2.6 Hive e performance

-‚ÄØBatch-oriented: Hive √® progettato per elaborare grandi quantit√† di dati tutti insieme, in grandi blocchi (batch), non per rispondere a singole query in tempo reale. √à ideale per analisi massive, come report o aggregazioni su tabelle molto grandi. Hive √® pensato per fare analisi su milioni o miliardi di righe tutte in una volta (ad esempio, calcolare la somma delle vendite di tutto l‚Äôanno). Non √® adatto per ottenere una risposta immediata a una domanda semplice (come ‚Äúquanti prodotti ha comprato Mario?‚Äù).
√à perfetto per creare report, statistiche o aggregazioni su grandi quantit√† di dati, anche se ci mette qualche minuto a rispondere.

-‚ÄØAdatto a scansioni complete: Hive lavora bene quando deve leggere e analizzare intere tabelle o grandi porzioni di dati, ad esempio per calcolare totali, medie o altre statistiche su dataset estesi.

-‚ÄØMeno performante su query rapide: Se hai bisogno di risposte immediate su pochi record (come una ricerca puntuale), Hive non √® la scelta migliore, perch√© il suo motore (basato su MapReduce o Tez) ha una latenza di avvio elevata.In altri termini anche per una semplice ricerca, Hive deve preparare e lanciare un job distribuito.Questo processo pu√≤ richiedere diversi secondi o minuti, indipendentemente dalla quantit√† di dati da leggere.Per questo motivo, Hive √® ottimo per analisi su grandi volumi di dati, ma non per ottenere risposte immediate su pochi record.

Ottimizzazioni comuni:
-‚ÄØPartizionamento: suddivide le tabelle in ‚Äúparti‚Äù (es. per data, paese, ecc.), cos√¨ le query leggono solo i dati necessari, riducendo i tempi di scansione.
-‚ÄØFormati colonnari (ORC, Parquet): questi formati memorizzano i dati per colonne invece che per righe, migliorando la compressione e la velocit√† di lettura per le query analitiche.
-‚ÄØPredicate pushdown: permette di applicare i filtri (WHERE) direttamente durante la lettura dei dati, evitando di caricare dati inutili e velocizzando le query.

---

## 2.7 Quando usare Hive 

Usa Hive quando:
- i dati sono molto grandi
- la latenza non √® critica
- stai facendo ETL o reporting batch
- la priorit√† √® la scalabilit√†

---

## 3. Apache Impala ‚Äì Approfondimento completo

## 3.1 Cos‚Äô√® Apache Impala

**:contentReference[oaicite:2]{index=2}** √® un **motore SQL MPP (Massively Parallel Processing)** progettato per:
- query interattive
- bassa latenza
- analisi esplorativa

Impala **non usa MapReduce**.

---

## 3.2 Architettura di Impala

Impala utilizza:
- daemon su ogni nodo
- esecuzione in parallelo
- elaborazione in memoria

Caratteristiche:
- niente job batch
- niente scritture temporanee su HDFS
- risposta immediata

üëâ **Domanda tipica d‚Äôesame**  
> Impala √® batch o interattivo? ‚Üí **interattivo**

---

## 3.3 Impala e Metastore condiviso

Impala:
- usa lo stesso Metastore di Hive
- vede le stesse tabelle
- usa gli stessi file su HDFS

‚ö†Ô∏è **Punto d‚Äôesame importante**
> Non esiste duplicazione dei dati tra Hive e Impala

---

## 3.4 Impala e performance

Impala √® molto veloce perch√©:
- legge direttamente i file. A differenza di Hive, infatti, non avvia un job MapReduce o Tez per ogni query. Invece, accede direttamente ai file dei dati (ad esempio su HDFS o su un Data Lake) e li legge in modo nativo, senza passaggi intermedi.
- usa memoria
- sfrutta MPP

Ma:
- consuma molte risorse
- √® sensibile a query inefficienti
- va governato (YARN, admission control)

---

## 3.5 Impala e sicurezza

In Cloudera, Impala:
- usa Kerberos
- applica policy Ranger
- √® soggetto ad auditing

‚ö†Ô∏è Impala **espone dati velocemente** ‚Üí rischio maggiore se mal configurato.

---

## 3.6 Quando usare Impala (riassunto da esame)

Usa Impala quando:
- serve risposta rapida
- analisi interattiva
- dashboard
- esplorazione dati

---

## 4. Confronto Hive vs Impala (TABELLA DA MEMORIZZARE)

| Caratteristica | Hive | Impala |
|--------------|------|--------|
| Tipo | Data Warehouse | SQL Engine |
| Latenza | Alta | Bassa |
| Uso | Batch / ETL | Interattivo |
| Motore | Job batch | MPP |
| Metastore | S√¨ | S√¨ (condiviso) |
| Schema | Schema-on-read | Schema-on-read |
| Query rapide | ‚ùå | ‚úÖ |

üëâ **Questa tabella copre il 90% delle domande Hive/Impala all‚Äôesame**

---

## 5. Scenario tipico d‚Äôesame (ragionamento)

**Domanda**  
Un analista deve eseguire query SQL rapide su grandi volumi di dati gi√† strutturati. Quale strumento scegliere?

**Risposta corretta**
‚Üí **Impala**

**Perch√©**
- bassa latenza
- SQL interattivo
- dati gi√† nel Data Lake

---

## 6. Errori comuni da evitare all‚Äôesame

‚ùå Dire che Hive √® interattivo  
‚ùå Dire che Impala √® un data warehouse  
‚ùå Pensare che Hive e Impala abbiano storage separato  
‚ùå Confondere Metastore con HDFS  

---

## 7. Sintesi finale (da memorizzare)

- Hive = significato + batch
- Impala = velocit√† + interattivit√†
- Metastore = cuore semantico
- HDFS = storage comune
- CDP = governance unica

---

## 8. Frase chiave da esame (memorizzala)

> **Hive e Impala sono due motori SQL diversi che condividono gli stessi dati e lo stesso Metastore, ma servono casi d‚Äôuso differenti.**
---
# PARTE 2: SICUREZZA CDP (12 domande)

## 9. Shared Data Experience (SDX)

### 9.1 Cos'√® SDX

**SDX** √® l'architettura di sicurezza e governance integrata di CDP.

La differenza tra sicurezza e governance, in ambito IT e dati, √® la seguente:

Sicurezza: riguarda la protezione dei dati e dei sistemi da accessi non autorizzati, minacce, attacchi, perdita o furto. Include misure tecniche (come crittografia, autenticazione, firewall) e procedure per garantire la riservatezza, l‚Äôintegrit√† e la disponibilit√† delle informazioni.

Governance: riguarda la gestione, il controllo e la supervisione delle risorse informative e dei processi aziendali. Include la definizione di politiche, ruoli, responsabilit√†, regole di accesso, conformit√† normativa e monitoraggio delle attivit√† per assicurare che i dati siano usati in modo corretto, etico e conforme alle leggi.

In sintesi: la sicurezza protegge, la governance gestisce e controlla. Spesso lavorano insieme per garantire un uso sicuro e conforme delle informazioni.

**Componenti SDX:**
- **Apache Ranger** - Authorization 
- **Apache Atlas** - Metadata management & data lineage
- **Apache Knox** - Perimeter security (gateway)
- **Hive Metastore** - Schema centrale
- **Data Catalog** - Discovery & search
- **Replication Manager** - Backup & DR
- **Workload Manager** - Monitoring & optimization

### 9.2 Perch√© SDX √® importante

‚úÖ **Sicurezza integrata by design**
‚úÖ **Governance centralizzata**
‚úÖ **Policy consistenti su tutti i servizi**
‚úÖ **Audit trail completo**

üëâ **Domanda tipica d'esame**
> SDX include Ranger e Atlas? ‚Üí **S√¨**
> SDX √® solo per security? ‚Üí **No, anche governance e metadata**

---
# 10. Apache Ranger ‚Äì Authorization
# 10.1 Cos'√® Ranger

Apache Ranger √® il componente di Cloudera Data Platform (CDP) che gestisce l‚Äôauthorization centralizzata per l‚Äôecosistema Hadoop. Ranger consente di definire, applicare e monitorare policy di accesso granulari su dati e servizi Big Data.

Importante: Ranger si occupa solo di authorization (cosa pu√≤ fare l‚Äôutente), mentre l‚Äôautenticazione (chi √® l‚Äôutente) √® gestita da sistemi esterni come Kerberos, LDAP, SSO.

10.2 Funzionalit√† principali di Ranger
- Policy-based access control (PBAC): gestione delle regole di accesso per utenti, gruppi e ruoli.
- Controllo granulare: autorizzazione a livello di database, tabella, colonna, riga.
- Data masking: offuscamento di dati sensibili per conformit√† (es. GDPR).
- Row-level filtering: limitazione delle righe visibili in base all‚Äôutente/gruppo.
- Audit centralizzato: tracciabilit√† di tutte le operazioni di accesso e modifica sui dati.


### 11.2 Servizi supportati da Ranger

Ranger gestisce accessi per:
- HDFS
- Hive
- Impala
- HBase
- Kafka
- Solr
- YARN
- Atlas

### 11.3 Ranger policies

**Tipi di policy:**
- **Access policies** - chi pu√≤ fare cosa (SELECT, INSERT, UPDATE, DELETE)
- **Masking policies** - offusca dati sensibili (es. GDPR)
- **Row filter policies** - limita righe visibili per utente/gruppo

üëâ **Domanda tipica d'esame**
> Ranger fa authentication o authorization? ‚Üí **Authorization** (l'authentication √® gestita da Kerberos/LDAP)
> Ranger supporta masking? ‚Üí **S√¨**

---

## 12. Apache Atlas ‚Äì Metadata & Governance

### 12.1 Cos'√® Atlas

**Apache Atlas** √® la piattaforma di **metadata management e data governance**.

**Funzioni:**
- Metadata repository (catalogo dati), √® un sistema che memorizza e gestice le informazioni sui dati, non i dati stessi*
- Data lineage (da dove viene il dato)
- Data classification (PII, sensibile, pubblico)
- Business glossary
- Search & discovery

*In Cloudera, Atlas √® il sistema di data governance che gestisce i metadati, la catalogazione e la tracciabilit√† dei dati, inclusi quelli di Hive. Atlas pu√≤ raccogliere, arricchire e visualizzare tutte le informazioni sulle tabelle, colonne, permessi, lineage (origine e trasformazioni) e relazioni tra i dati di Hive.

Tuttavia:

Le informazioni tecniche di base (schemi, tabelle, colonne, percorsi) sono memorizzate principalmente nel Metastore di Hive.
Atlas si integra con il Metastore e aggiunge funzionalit√† avanzate: catalogo centralizzato, ricerca, lineage, classificazione, policy di sicurezza e auditing.
Quindi:
S√¨, tutte le informazioni necessarie per la governance, la ricerca e la gestione avanzata dei dati di Hive sono disponibili tramite Atlas, che si appoggia anche al Metastore per i dettagli tecnici.

### 12.2 Atlas e lineage

**Data Lineage** traccia:
- Origine dati (source)
- Trasformazioni (ETL)
- Destinazione (target)
- Dipendenze tra entit√†

Esempio: `Salesforce ‚Üí Sqoop ‚Üí HDFS ‚Üí Hive ‚Üí Impala ‚Üí BI Report`

### 12.3 Atlas integration

Atlas traccia automaticamente:
- Hive queries (CREATE TABLE, INSERT)
- Spark jobs
- Sqoop imports
- NiFi flows

üëâ **Domanda tipica d'esame**
> Atlas fa security o governance? ‚Üí **Governance (metadata)**
> Atlas traccia lineage? ‚Üí **S√¨**

---

## 13. Apache Knox ‚Äì Perimeter Security

### 13.1 Cos'√® Knox

**Apache Knox** √® un **gateway di sicurezza perimetrale** per cluster Hadoop.

**Funzioni:**
- Single point of access (reverse proxy)
- Authentication (LDAP, SSO, Kerberos)
- SSL/TLS termination
- Token-based authentication (JWT)
- Topology-based routing

### 13.2 Knox use cases

- Esporre servizi Hadoop (Hive, HBase) all'esterno del cluster
- Integrazione con enterprise SSO
- Protezione endpoint REST API
- Load balancing

üëâ **Domanda tipica d'esame**
> Knox √® un gateway? ‚Üí **S√¨**
> Knox fa authentication? ‚Üí **S√¨**

---

## 14. CDP Public Cloud ‚Äì Integration SSO

### 14.1 Identity Federation

CDP Public Cloud supporta **identity federation** con SAML-based IdP.

**IdP supportati:**
- Okta
- Azure AD
- Google Workspace
- Ping Identity
- ADFS (Active Directory Federation Services)

### 14.2 Vantaggi SSO

‚úÖ Single sign-on (un login per tutti i servizi)
‚úÖ No account Cloudera necessario
‚úÖ Gestione utenti centralizzata
‚úÖ MFA (Multi-Factor Authentication) support

üëâ **Domanda tipica d'esame**
> CDP Public supporta SAML SSO? ‚Üí **S√¨**
> Serve account Cloudera con SSO? ‚Üí **No**

---

## 14. CDP Private Cloud ‚Äì LDAP e Kerberos

### 14.1 Authentication in Private Cloud

CDP Private Cloud integra:
- **LDAP** (Lightweight Directory Access Protocol) per identity
- **Kerberos** per authentication
- **Active Directory** (LDAP + Kerberos combinati)

### 14.2 LDAP

**Funzioni:**
- User/group management
- Directory services
- Integrazione con AD aziendale

### 14.3 Kerberos

**Funzioni:**
- Strong authentication (ticket-based)
- Mutual authentication (client ‚Üî server)
- Protection contro replay attacks
- Single sign-on (SSO)

üëâ **Domanda tipica d'esame**
> Private Cloud usa Kerberos? ‚Üí **S√¨**
> LDAP √® per identity o authentication? ‚Üí **Identity (Kerberos per auth)**

---

## 15. Encryption ‚Äì Data at Rest

### 15.1 HDFS Transparent Encryption

**HDFS TDE** (Transparent Data Encryption):
- Cifratura automatica dei dati su HDFS
- Trasparente per applicazioni (no code change)
- Key management via KMS (Key Management Service)
- Per-zone encryption (encryption zones)

### 15.2 Cloudera Navigator Encrypt

**Navigator Encrypt**:
- Full-disk encryption per nodi del cluster
- Cifratura a livello OS (sotto HDFS), i dati vengono cifrati direttamente dal sistema operativo, indipendentemente da dove sono salvati. Tutti i file sul disco sono protetti, anche quelli non gestiti da HDFS.
- Protection anche se disco rubato
- Transparent per applicazioni

### 15.3 Cloud Storage Encryption

**Cloud providers:**
- **AWS S3** - SSE (Server-Side Encryption), KMS
- **Azure ADLS** - Storage Service Encryption
- **GCP GCS** - Default encryption at rest

üëâ **Domanda tipica d'esame**
> HDFS supporta encryption at rest? ‚Üí **S√¨ (TDE)**
> Cloud storage √® cifrato? ‚Üí **S√¨ (di default nei cloud provider)**

---

## 16. Encryption ‚Äì Data in Transit

### 16.1 TLS/SSL

**Transport Layer Security** (TLS 1.2+):
- Sostituisce SSL
- Cifratura traffico di rete
- Certificati X.509 (I certificati TLS si occupano di
a)Autenticazione -> verificano che il server (e a volte anche il client) sia davvero chi dice di essere, grazie a una firma digitale rilasciata da una Certification Authority (CA) fidata.
b)Cifratura -> Cifratura:‚ÄØforniscono le chiavi pubbliche necessarie per avviare la comunicazione cifrata tra client e server.
c)Integrit√† -> Aiutano a garantire che i dati scambiati non siano stati alterati durante il trasferimento. )
- Protection contro man-in-the-middle

**Servizi con TLS:**
- HDFS (NameNode ‚Üî DataNode)
- Hive/Impala (client ‚Üî server)
- HTTP/REST API
- JDBC/ODBC connections

üëâ **Domanda tipica d'esame**
> TLS cifra data in transit? ‚Üí **S√¨**
> CDP supporta TLS? ‚Üí **S√¨ (1.2+)**

---

# PARTE 3: DATA SERVICES (9 domande)

## 17. Cloudera Data Engineering (CDE)

### 17.1 Cos'√® CDE

**Cloudera Data Engineering** √® un servizio per **gestire e schedulare job Apache Spark**.

**Caratteristiche:**
- Auto-scaling cluster Spark
- No overhead di gestione cluster manuale
- Supporto batch e streaming
- Integrato con SDX (security/governance)

### 17.2 CDE Public vs Private Cloud

| Aspetto | Public Cloud | Private Cloud |
|---------|--------------|---------------|
| Infrastructure | Cloud provider managed | On-premise Kubernetes |
| Scaling | Elastico (cloud-native) | Limitato da hardware |
| Deployment | Managed service | Self-service virtual cluster |

üëâ **Domanda tipica d'esame**
> CDE √® per Spark? ‚Üí **S√¨**
> CDE fa auto-scaling? ‚Üí **S√¨**

---

## 18. Cloudera Data Warehouse (CDW)

### 18.1 Cos'√® CDW

**Cloudera Data Warehouse** √® un servizio per creare **data warehouse indipendenti e auto-scaling**.

**Caratteristiche:**
- Containerizzato (Kubernetes)
- Hive e Impala virtual warehouses
- Auto-scaling dinamico
- Indipendenti e isolati (multi-tenancy)
- Upgrade indipendenti

### 18.2 CDW Virtual Warehouses

**Tipi:**
- **Hive Virtual Warehouse** - batch ETL
- **Impala Virtual Warehouse** - query interattive

Ogni VW pu√≤ scalare indipendentemente.

### 18.3 CDW Public vs Private Cloud

| Aspetto | Public Cloud | Private Cloud |
|---------|--------------|---------------|
| Infrastructure | AWS/Azure/GCP | OpenShift/ECS/Kubernetes |
| Scaling | Elastic cloud-native | Limitato da capacity |
| Storage | S3/ADLS/GCS | HDFS/Ozone |

üëâ **Domanda tipica d'esame**
> CDW √® containerizzato? ‚Üí **S√¨ (Kubernetes)**
> CDW supporta Hive e Impala? ‚Üí **S√¨ (virtual warehouses)**

---

## 19. Cloudera Operational Database (COD)

### 19.1 Cos'√® COD

**Cloudera Operational Database** √® un servizio di **database operazionali real-time, scalabili e always-available**, √® un servizio di database operativo, progettato per gestire dati in tempo reale, con accessi rapidi, scritture e letture immediate, alta disponibilit√† e scalabilit√† automatica. √à pensato per applicazioni che richiedono risposte istantanee (es. app, transazioni, sistemi online). Al contrario HDFS (Hadoop Distributed File System) √® un file system distribuito, usato per archiviare grandi quantit√† di dati in modo affidabile e scalabile, ma non √® ottimizzato per accessi in tempo reale o per gestire transazioni rapide. √à ideale per analisi batch, data lake e archiviazione di file di grandi dimensioni.

**Tecnologie:**
- Powered by **Apache HBase** (storage)
- **Apache Phoenix** (SQL interface)

### 19.2 COD use cases

- Low-latency random access
- Store/retrieve authentication details
- Time-series data (IoT, logs)
- Real-time analytics
- Session management

### 19.3 COD caratteristiche

‚úÖ Auto-scaling
‚úÖ Always-on (HA nativa)
‚úÖ SQL via Phoenix
‚úÖ NoSQL via HBase API

üëâ **Domanda tipica d'esame**
> COD √® per low-latency? ‚Üí **S√¨**
> COD usa HBase? ‚Üí **S√¨**
> COD √® per authentication data? ‚Üí **S√¨ (domanda campione esame)**

---

## 20. Cloudera Machine Learning (CML)

### 20.1 Cos'√® CML

**Cloudera Machine Learning** unifica **data science e data engineering** in un servizio integrato.

**Funzioni:**
- Workspace collaborativo per data scientist
- Supporto Python, R, Scala
- Model training e deployment
- Jupyter, RStudio, VS Code integration
- MLOps (CI/CD per modelli)

### 20.2 CML caratteristiche

- **Workspace isolati** per progetti
- **Experiments tracking** (modelli, hyperparameter)
- **Model deployment** (REST API)
- **Model monitoring** (drift detection)

### 20.3 CML Public vs Private Cloud

| Aspetto | Public Cloud | Private Cloud |
|---------|--------------|---------------|
| Infrastructure | Cloud managed | OpenShift/Kubernetes |
| GPU support | S√¨ | S√¨ (se disponibile) |
| Scaling | Elastico | Limitato da cluster |

üëâ **Domanda tipica d'esame**
> CML √® per ML? ‚Üí **S√¨**
> CML supporta Python/R? ‚Üí **S√¨**

---

## 21. Cloudera DataFlow (CDF)

### 21.1 Cos'√® CDF

**Cloudera DataFlow** √® un servizio **cloud-native per distribuzione universale di dati**.

**Tecnologia:**
- Powered by **Apache NiFi**

**Caratteristiche:**
- Connect to any data source
- Process and deliver to any destination
- GUI drag-and-drop
- Auto-scaling flow deployments

### 21.2 CDF use cases

- Real-time data ingestion
- Data routing e enrichment
- Edge-to-cloud data movement
- IoT data collection

üëâ **Domanda tipica d'esame**
> CDF usa NiFi? ‚Üí **S√¨**
> CDF √® cloud-native? ‚Üí **S√¨ (Public Cloud)**

---

# PARTE 4: DEPLOY CDP PUBLIC CLOUD (9 domande)

## 22. CDP Public Cloud ‚Äì Concetti Core

### 22.1 Cos'√® un Environment

**Environment** √® un **subset logico del cloud provider account** che include:
- Virtual network (VPC/VNet)
- Security groups
- Storage locations (S3/ADLS/GCS)
- SDX (Data Lake)

‚úÖ Puoi registrare **quanti environment vuoi**
‚úÖ Ogni environment √® isolato

üëâ **Domanda tipica d'esame** (domanda campione esame)

> Environment √® un subset del cloud account? ‚Üí **S√¨**
> Quanti environment posso creare? ‚Üí **Quanti voglio**

---

## 22.2 Credential

**Credential** permette a CDP di **autenticarsi con il cloud provider**.

**Prerequisiti:**
- AWS: IAM role, cross-account access
- Azure: Service Principal, Managed Identity
- GCP: Service Account

---

## 22.3 Data Lake

**Data Lake** in CDP Public Cloud:
- Storage centralizzato (S3/ADLS/GCS)
- SDX (Ranger + Atlas)
- Hive Metastore
- Shared tra tutti i Data Hub dello stesso environment

---

## 23. CDP Public Cloud ‚Äì Cloud Providers

### 23.1 AWS Requirements

**Prerequisites:**
- AWS account con privilegi sufficienti
- VPC con subnet (pubbliche/private)
- S3 bucket per storage
- IAM roles/policies
- Cross-account trust

**Services usati:**
- EC2 (compute)
- S3 (storage)
- RDS (Metastore/Ranger DB)
- EKS (Kubernetes per Data Services)

---

### 23.2 Azure Requirements

**Prerequisites:**
- Azure subscription
- Resource group
- VNet con subnet
- ADLS Gen2 storage account
- Service Principal o Managed Identity

**Services usati:**
- VMs (compute)
- ADLS Gen2 (storage)
- Azure Database (Postgres/MySQL)
- AKS (Kubernetes per Data Services)

---

### 23.3 GCP Requirements

**Prerequisites:**
- GCP project
- VPC network
- GCS bucket per storage
- Service Account

**Services usati:**
- Compute Engine (VMs)
- GCS (storage)
- Cloud SQL (databases)
- GKE (Kubernetes per Data Services)

---

üëâ **Domanda tipica d'esame**
> CDP Public supporta AWS/Azure/GCP? ‚Üí **S√¨, tutti e tre**
> Serve VPC/VNet? ‚Üí **S√¨**

---

# PARTE 5: DEPLOY CDP PRIVATE CLOUD BASE (6 domande)

## 24. CDP Private Cloud Base ‚Äì System Requirements

### 24.1 Hardware Requirements

**Per production cluster:**
- Minimum 3 nodi (5+ raccomandati)
- CPU: 4+ core per nodo (8+ raccomandati)
- RAM: 16GB+ per nodo (32GB+ raccomandati)
- Disk: 
  - OS: 100GB+
  - Data: dipende da workload (TB+)
- Network: 10 Gigabit Ethernet (raccomandato)

---

### 24.2 OS supportati

**Operating Systems:**
- Red Hat Enterprise Linux (RHEL) 7.x, 8.x
- CentOS 7.x, 8.x
- Ubuntu 18.04, 20.04
- SUSE Linux Enterprise Server (SLES) 12, 15

---

### 24.3 Java supportati

**Java Providers:** (domanda campione esame)
- ‚úÖ **Oracle JDK** 8, 11
- ‚úÖ **OpenJDK** 8, 11
- ‚úÖ **Azul Zulu JDK** 8, 11
- ‚ùå Closed JDK (non esiste)

üëâ **Domanda tipica d'esame** (domanda campione esame)
> Oracle JDK supportato? ‚Üí **S√¨**
> OpenJDK supportato? ‚Üí **S√¨**
> Azul/Zulu supportato? ‚Üí **S√¨**

---

### 24.4 Database supportati

**Databases per Metastore/Ranger:** (domanda campione esame)
- ‚úÖ **PostgreSQL** 10, 11, 12
- ‚úÖ **MySQL** 5.7, 8.0
- ‚úÖ **MariaDB** 10.x
- ‚úÖ **Oracle Database** 12c, 19c

üëâ **Domanda tipica d'esame** (domanda campione esame)
> PostgreSQL supportato? ‚Üí **S√¨**
> MS SQL Server supportato? ‚Üí **S√¨**
> Oracle DB supportato? ‚Üí **S√¨**
> MySQL supportato? ‚Üí **S√¨**

---

### 24.5 Networking

**Requirements:**
- Forward and reverse DNS
- NTP (Network Time Protocol) sincronizzato
- Firewall rules per comunicazione inter-nodi
- No conflitti di porte

---

# PARTE 6: CLOUDERA MANAGER (3 domande)

## 25. Cloudera Manager

### 25.1 Cos'√® Cloudera Manager

**Cloudera Manager** √® l'applicazione per **gestire, configurare e monitorare cluster CDP Private Cloud Base**.

**Architettura:**
```

Cloudera Manager Server
- Gira su un host dedicato
- Web UI + API REST
- Gestisce uno o pi√π cluster

Cloudera Manager Agent
- Gira su ogni nodo del cluster
- Esegue comandi dal Server
- Invia metriche e heartbeat
```

---

### 25.2 Funzioni principali

**Configurazione:**
- Install/upgrade servizi (Hive, HDFS, YARN, ecc.)
- Configurazione centralizzata
- Rolling restart

**Monitoring:**
- Metriche real-time (CPU, disk, network)
- Health checks automatici
- Alerts e notifications

**Troubleshooting:**
- Log aggregation
- Diagnostics
- Performance tuning

---

### 25.3 Cloudera Manager e database

Cloudera Manager richiede un database esterno per:
- Configuration metadata
- Monitoring data
- User/role management

**Databases supportati:** (gi√† visto sopra)
- PostgreSQL
- MySQL / MariaDB
- Oracle DB
- MS SQL Server

üëâ **Domanda tipica d'esame**
> Cloudera Manager gestisce cluster? ‚Üí **S√¨**
> Serve database? ‚Üí **S√¨**
> Dove gira? ‚Üí **Su host dedicato**

---

# PARTE 7: WORKLOAD XM (3 domande)

## 26. Workload XM

### 26.1 Cos'√® Workload XM

**Workload XM** √® uno strumento per **monitorare, analizzare e ottimizzare workload** su cluster CDP.

**Funzioni:**
- Understand workloads (Hive, Impala, Spark)
- Troubleshoot failed jobs
- Optimize slow queries
- Capacity planning
- Cost optimization

---

### 26.2 Workload XM caratteristiche

**Analisi:**
- Query performance analysis
- Resource utilization (CPU, memory, I/O)
- Baseline comparison
- Anomaly detection

**Recommendations:**
- Query optimization suggestions
- Configuration tuning
- Resource allocation

---

### 26.3 Telemetry Publisher e redaction

**Telemetry Publisher** raccoglie dati diagnostici e li invia a Workload XM.

**Dati sensibili - redaction supportata:** (domanda campione esame)
- ‚úÖ **Log and query** text
- ‚úÖ **MapReduce job properties**
- ‚úÖ **Spark event and executor log**
- ‚ùå HBase users (non redactable in questo contesto)
- ‚ùå Kafka topics (non redactable in questo contesto)

üëâ **Domanda tipica d'esame** (domanda campione esame)
> Workload XM ottimizza query? ‚Üí **S√¨**
> Telemetry Publisher supporta redaction? ‚Üí **S√¨**
> Log and query possono essere redatti? ‚Üí **S√¨**

---

# PARTE 8: REPLICATION MANAGER (3 domande)

## 27. Replication Manager

### 27.1 Cos'√® Replication Manager

**Replication Manager** √® uno strumento per **replicare e migrare dati tra ambienti CDP**.

**Funzioni:**
- Copy HDFS data
- Replicate Hive external tables
- Backup HBase tables
- Disaster Recovery (DR)
- Cloud migration

Ecco la differenza tra distcp e Replication Manager in Cloudera:

distcp (Distributed Copy) √® un comando da riga di comando usato per copiare grandi quantit√† di dati tra cluster Hadoop o all‚Äôinterno dello stesso cluster. √à manuale: devi avviarlo tu, specificando sorgente e destinazione. √à utile per trasferimenti una tantum o occasionali.

Replication Manager √® uno strumento di Cloudera Manager che permette di gestire, pianificare e monitorare la replica dei dati tra cluster in modo automatico e centralizzato. Offre funzionalit√† avanzate come la pianificazione, il monitoraggio, la gestione degli errori e la reportistica. √à pensato per repliche regolari, continue e affidabili.

In sintesi:

distcp = copia manuale, da terminale, per operazioni singole
Replication Manager = gestione automatica e centralizzata delle repliche, con interfaccia grafica e funzionalit√† avanzate


---

### 27.2 Replication Manager ‚Äì Private Cloud

**Private Cloud:**
- Replica HDFS tra cluster CDP Private Cloud Base 7.1.8+
- Replica Hive external tables
- Replica Ozone data

---

### 27.3 Replication Manager ‚Äì Public Cloud

**Public Cloud:**
- Replica da CDH ‚Üí CDP Public Cloud
- Replica da CDP Private Cloud Base ‚Üí CDP Public Cloud
- Supporta HDFS, Hive, HBase
- Cloud storage (S3/ADLS/GCS) come destination

---

### 27.4 HDFS Replication Policies

Quando vuoi replicare dati HDFS su uno storage cloud (come S3, ADLS, GCS) usando Replication Manager, ci sono alcuni requisiti fondamentali:

Devi registrare le credenziali cloud (cloud credentials) in Replication Manager, cos√¨ il sistema pu√≤ accedere allo storage di destinazione.
Devi verificare che il cluster abbia accesso al cloud e che le porte di rete minime siano configurate correttamente.
Non serve configurare Hive, perch√© la replica riguarda solo i dati HDFS, non le tabelle Hive.
Non √® vero che ‚Äúfunziona senza configurazione‚Äù: serve sempre configurare almeno le credenziali e l‚Äôaccesso.
In sintesi: per replicare HDFS su cloud serve configurare le credenziali cloud e l‚Äôaccesso del cluster, ma non serve configurare Hive.


**Requirements per replicare HDFS su cloud storage:** (domanda campione esame)
- ‚úÖ **Register cloud credentials** in Replication Manager
- ‚úÖ **Verify cluster access** e configure minimum ports
- ‚ùå Non serve configurare Hive (HDFS √® indipendente)
- ‚ùå Non √® vero che "works without configuration"

üëâ **Domanda tipica d'esame** (domanda campione esame)
> Cosa serve per HDFS replication su cloud? ‚Üí **Cloud credentials + cluster access**
> Serve configurare Hive? ‚Üí **No (HDFS ‚â† Hive)**

---

# RIEPILOGO FINALE

## Distribuzione domande per topic

| Topic | Domande | Focus |
|-------|---------|-------|
| **Componenti CDP** | 15 | HDFS, Hive, Impala, YARN, Spark, Oozie, Kafka, NiFi, HBase, Kudu |
| **Sicurezza** | 12 | SDX, Ranger, Atlas, Knox, encryption, SSO, Kerberos |
| **Data Services** | 9 | CDE, CDW, COD, CML, CDF |
| **Deploy Public Cloud** | 9 | AWS, Azure, GCP, environment, credential |
| **Deploy Private Cloud** | 6 | System requirements, Java, DB, OS |
| **Cloudera Manager** | 3 | Gestione cluster, configurazione |
| **Workload XM** | 3 | Monitoring, optimization, telemetry |
| **Replication Manager** | 3 | Backup, DR, migration |

**Totale:** 60 domande  
**Pass Score:** 60% (36 domande corrette su 60)

---

## Strategie per l'esame

### ‚úÖ Cosa memorizzare

1. **Tabelle comparative** (Hive vs Impala, MapReduce vs Spark, ecc.)
2. **Use cases specifici** (quando usare quale strumento)
3. **Domande campione** (Oozie supporta MiNiFi? ‚Üí No)
4. **Liste supportate** (Java providers, databases, cloud providers)
5. **Acronimi** (SDX, CDE, CDW, COD, CML, CDF, TDE, RBAC)

### ‚ùå Errori comuni da evitare

- Confondere Hive (batch) con Impala (interattivo)
- Pensare che Ranger faccia authentication (fa authorization)
- Credere che Atlas faccia security (fa governance/metadata)
- Confondere NiFi (data flow) con Kafka (messaging)
- Dimenticare che Hive e Impala condividono Metastore
- Non conoscere i database supportati da Cloudera Manager

### üìö Risorse da studiare

1. **Questo documento** (coverage completa 60 domande)
2. **CDP documentation** ufficiale (link per approfondimenti)
3. **Cloudera Essentials for CDP** (corso video)
4. **Hands-on experience** (importante per domande pratiche)

---

## Frasi chiave da memorizzare

> **Hive e Impala** condividono dati e Metastore, ma servono casi d'uso differenti.

> **SDX** √® l'architettura di sicurezza e governance integrata (Ranger + Atlas + Knox + Metastore).

> **COD** √® ideal per low-latency, highly scalable storage/retrieval (authentication, IoT).

> **Environment** √® un logical subset del cloud account con virtual network.

> **Oozie** √® un workflow scheduler che combina job sequenzialmente.

> **Workload XM** ottimizza workload e troubleshoota failed jobs.

> **Replication Manager** replica dati tra ambienti CDP (serve cloud credentials + cluster access).

---

### **Cos'√® lo Schema?**

Lo **schema** √® una definizione strutturale che descrive l'organizzazione e il formato dei dati in un sistema di gestione dei dati. Esso specifica come i dati sono strutturati, quali colonne (O campi) esistono, e quali tipi di dati sono associati a ciascun campo.
Piu semplicemente lo schema √® la struttura della tabella, ossia:
- quali colonne esistono 
- e quali tipi di dati sono associati a ciascun campo (Con ‚Äútipi di dati‚Äù si intendono le categorie che definiscono che tipo di valori pu√≤ contenere una colonna o un campo in una tabella o in un database
Esempi di tipi di dati:
INTEGER: numeri interi (es. 5, 100)
FLOAT/DOUBLE: numeri decimali (es. 3.14)
STRING/VARCHAR: testo (es. ‚ÄúMario‚Äù)
DATE: date (es. 2026-01-30)
BOOLEAN: vero/falso (TRUE/FALSE))

ad es.

CREATE TABLE vendite (
  id INT,
  cliente STRING,
  importo DOUBLE,
  data_vendita DATE
)
STORED AS PARQUET;

In questo esempio:

- La tabella si chiama vendite.
- Ha quattro colonne: id (intero), cliente (testo), importo (decimale), data_vendita (data).
- i tipi di dati sono definiti accanto a ciascuna colonna:
a) id INT ‚Üí il tipo di dato √® INT (numero intero)
b) cliente STRING ‚Üí il tipo di dato √® STRING (testo)
c) importo DOUBLE ‚Üí il tipo di dato √® DOUBLE (numero decimale)
d) data_vendita DATE ‚Üí il tipo di dato √® DATE (data)
Quindi, ogni colonna ha il suo tipo di dato specificato subito dopo il nome.
- I dati saranno salvati in formato Parquet (un formato colonnare).

#### **Caratteristiche principali dello Schema:**
1. **Definizione della struttura:**
   - Specifica i campi (colonne) e i loro tipi di dati (es. stringa, intero, data).
   - Definisce le relazioni tra i dati (es. chiavi primarie, univocit√†, ecc.) nei database relazionali.

2. **Tipi di Schema:**
   - **Schema-on-write:**
     - Lo schema √® definito prima che i dati vengano scritti nel sistema.
     - Richiede che i dati rispettino la struttura predefinita:
    a) Prima di scrivere i dati, si definiscono le colonne, i tipi di dati e le regole (es: nome STRING, et√† INT).
    b) Quando provi a inserire un dato, il database controlla che rispetti questa struttura (es: non puoi mettere un testo nella colonna et√† se √® definita come INT).
    c) Se i dati non rispettano lo schema, il database rifiuta l‚Äôinserimento.
     - Utilizzato nei database relazionali (es. MySQL, PostgreSQL).
   - **Schema-on-read:**
     - Lo schema viene applicato solo al momento della lettura o dell'analisi dei dati.
     - Permette di gestire dati non strutturati o semi-strutturati.
     - Utilizzato in strumenti di big data come Hadoop e Hive.

3. **Flessibilit√†:**
   - Nei sistemi relazionali, lo schema √® rigido e deve essere rispettato.
   - Nei sistemi non relazionali, lo schema pu√≤ essere flessibile o assente.

4. **Esempi di Schema:**
   - **Database relazionale:**
     ```sql
     CREATE TABLE Clienti (
       ID INT PRIMARY KEY,
       Nome VARCHAR(50),
       Cognome VARCHAR(50),
       Email VARCHAR(100)
     );
     ```
     Questo schema definisce una tabella con colonne e tipi di dati specifici.
   - **Big Data (Hive):**
     ```sql
     CREATE EXTERNAL TABLE LogDati (
       Timestamp STRING,
       Messaggio STRING
     )
     STORED AS TEXTFILE;
     ```
     Questo schema viene applicato ai dati gi√† esistenti in HDFS.

### **Esempio di Schema**

Uno schema definisce la struttura di una tabella, specificando i nomi delle colonne e i tipi di dati associati. 
Ecco un esempio:

```sql
CREATE TABLE employees (
    id INT,          -- Identificativo univoco
    name STRING,     -- Nome del dipendente
    salary DECIMAL   -- Stipendio
);
```

#### **Dettagli dello schema:**
- **`id INT`**: Colonna `id` con tipo di dato intero (integer).
- **`name STRING`**: Colonna `name` con tipo di dato stringa (testo).
- **`salary DECIMAL`**: Colonna `salary` con tipo di dato decimale (numerico con precisione).

#### **Cosa rappresenta uno schema?**
- Lo schema √® la **struttura logica** di una tabella.
- Specifica:
  1. **Nomi delle colonne** (es. `id`, `name`, `salary`).
  2. **Tipi di dati** (es. `INT`, `STRING`, `DECIMAL`).
  3. (Opzionale) **Vincoli** come chiavi primarie, univocit√†, ecc.

#### **Nota per l'esame CDP:**
- Ogni tabella in Hive o SQL richiede uno schema.
- Lo schema √® obbligatorio per definire come i dati vengono archiviati e interrogati.

#### **Perch√© lo Schema √® Importante?**
- **Organizzazione:** Permette di dare struttura ai dati, rendendoli pi√π facili da interrogare e analizzare.
- **Validazione:** Garantisce che i dati rispettino determinati vincoli (es. tipi di dati corretti).
- **Governance:** Aiuta a mantenere coerenza e integrit√† nei sistemi di gestione dei dati.

---

In sintesi, lo schema √® il "progetto" che descrive come i dati sono organizzati e strutturati in un sistema, influenzando il modo in cui vengono archiviati, letti e analizzati.

---

# Chiave primaria e chiave esterna

## Introduzione

In un database, l‚Äôorganizzazione, l‚Äôidentificazione e la coerenza dei dati dipendono sia dal **modello di database adottato** sia dall‚Äôuso corretto di **chiavi** e **metadati**.

In questo documento vengono spiegati:

* chiave primaria e chiave esterna nei database relazionali
* come vengono identificate tabelle e record
* le differenze tra **database relazionali (RDBMS)** e **non relazionali (NoSQL)**
* il collegamento con i sistemi **Big Data** come Hive

---

## Differenza tra database relazionali e non relazionali

### Database relazionali (RDBMS)

I database relazionali (**Relational Database Management System**) organizzano i dati in **tabelle** composte da **righe (record)** e **colonne (attributi)**, seguendo uno **schema fisso** definito a priori.

Ogni tabella:

* rappresenta un‚Äô**entit√†** del dominio applicativo
* √® identificata dal **nome della tabella all‚Äôinterno di uno schema**
* utilizza una **chiave primaria** per identificare univocamente i record
* pu√≤ essere collegata ad altre tabelle tramite **chiavi esterne**

Le relazioni tra tabelle sono **esplicite** e il database garantisce la coerenza dei dati tramite le propriet√† **ACID**:

* **Atomicit√†**
* **Consistenza**
* **Isolamento**
* **Durabilit√†**

üìå Esempi di RDBMS:

* MySQL
* PostgreSQL
* Oracle

Si chiamano database relazionali perch√© organizzano i dati in tabelle che possono essere messe in relazione tra loro tramite chiavi (primarie e esterne). Il termine ‚Äúrelazionale‚Äù deriva dal concetto matematico di ‚Äúrelazione‚Äù, che in questo contesto indica una tabella composta da righe e colonne. Le relazioni tra le tabelle permettono di collegare e integrare dati diversi in modo strutturato e coerente.

---

### Database non relazionali (NoSQL)

I database non relazionali (**NoSQL**):
- non si basano sul modello tabellare classico 
- non utilizzano chiavi esterne formali (Le relazioni tra i dati sono infatti spesso incorporate nei dati stessi oppure gestite a livello applciativo)
- e **non richiedono uno schema rigido**. 
Sono progettati per gestire **grandi volumi di dati**, **alta scalabilit√† orizzontale** e dati **semi-strutturati o non strutturati**.

Non utilizzano chiavi esterne formali e le relazioni tra dati sono spesso:

* incorporate nei dati stessi
* oppure gestite a livello applicativo

I principali modelli NoSQL sono:

* **Documentali** (es. MongoDB)
  I dati sono memorizzati come documenti JSON/BSON. Ogni documento ha un identificatore univoco (es. `_id`), simile a una chiave primaria, ma senza vincoli relazionali.

* **Key-Value** (es. Redis)
  I dati sono coppie chiave‚Äìvalore. Il modello √® estremamente veloce, ma non supporta relazioni strutturate.

* **A colonne** (es. Cassandra, HBase)
  I dati sono organizzati per colonne e partizioni. √à adatto a grandi volumi e carichi distribuiti.

* **A grafo** (es. Neo4j)
  I dati sono nodi e relazioni esplicite, ideali per rappresentare reti complesse (social network, recommendation system).

---

### Confronto sintetico RDBMS vs NoSQL

| Aspetto           | Database relazionali            | Database NoSQL                           |
| ----------------- | ------------------------------- | ---------------------------------------- |
| Modello dati      | Tabelle (righe/colonne)         | Documenti, key-value, colonne, grafi     |
| Schema            | Rigido                          | Flessibile o assente                     |
| Chiave primaria   | S√¨ (vincolo reale)              | Identificatore univoco                   |
| Chiave esterna    | S√¨                              | No                                       |
| Coerenza          | Forte (ACID)                    | Eventuale (BASE)                         |
| Scalabilit√†       | Verticale                       | Orizzontale                              |
| Caso d‚Äôuso tipico | Transazioni, sistemi gestionali | Big Data, analytics, sistemi distribuiti |

---

## Cos‚Äô√® una tabella

Una **tabella** rappresenta un‚Äô**entit√†** del mondo reale (ad esempio: Studente, Cliente, Ordine).
√à composta da:

* **righe (record)** ‚Üí singole istanze dell‚Äôentit√†
* **colonne (attributi)** ‚Üí caratteristiche dell‚Äôentit√†

### Identificazione di una tabella

Una tabella **non √® identificata dalla chiave primaria**.

üëâ **La tabella √® identificata dal suo nome all‚Äôinterno di uno schema (o database).**

Formalmente, l‚Äôidentificatore univoco di una tabella √®:

```
(schema, nome_tabella)
```

Questo significa che due tabelle possono avere lo stesso nome se appartengono a schemi diversi.

### Esempio

```
public.studente
didattica.studente
```

Queste due tabelle:

* hanno lo stesso nome (`studente`)
* appartengono a schemi diversi
* sono **tabelle distinte**

---

## Chiave primaria (Primary Key)

### Definizione

La **chiave primaria** √® un attributo (o un insieme di attributi) che **identifica univocamente ogni record di una tabella**.

üëâ **La chiave primaria identifica un record, non la tabella.**

### Propriet√† fondamentali

Una chiave primaria deve essere:

* **Univoca** (nessun duplicato)
* **Non nulla** (NOT NULL)
* **Stabile** (non dovrebbe cambiare nel tempo)

Pu√≤ essere:

* **Semplice** ‚Üí una sola colonna
* **Composta** ‚Üí pi√π colonne insieme

---

## Esempio pratico: chiave primaria

### Tabella STUDENTE

| matricola (PK) | nome  | cognome |
| -------------- | ----- | ------- |
| 12345          | Mario | Rossi   |
| 12346          | Luca  | Bianchi |

* `matricola = 12345` identifica **Mario Rossi**
* `matricola = 12346` identifica **Luca Bianchi**

---

## Chiave esterna (Foreign Key)

### Definizione

La **chiave esterna** √® un attributo di una tabella che fa riferimento alla **chiave primaria di un‚Äôaltra tabella**.

Serve a:

* collegare dati tra tabelle diverse
* garantire l‚Äô**integrit√† referenziale**

üëâ Un valore di chiave esterna **deve corrispondere a una chiave primaria esistente**.

---

## Esempio pratico: chiave primaria e chiave esterna

### Tabella CLIENTE

| id_cliente (PK) | nome  |
| --------------- | ----- |
| 10              | Anna  |
| 11              | Paolo |

### Tabella ORDINE

| id_ordine (PK) | data       | id_cliente (FK) |
| -------------- | ---------- | --------------- |
| 501            | 2026-01-10 | 10              |
| 502            | 2026-01-12 | 10              |
| 503            | 2026-01-13 | 11              |

* `id_cliente` √® **PK** in CLIENTE
* `id_cliente` √® **FK** in ORDINE
* ogni ordine √® associato a un cliente esistente

---

## Rappresentazione grafica concettuale

```
CLIENTE (1) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ< ORDINE (N)
```

* una riga di CLIENTE pu√≤ essere collegata a molte righe di ORDINE
* la relazione √® realizzata tramite la chiave esterna

---

## Chiave primaria composta

In alcuni casi, una singola colonna non √® sufficiente a identificare un record.

### Esempio: ISCRIZIONE_ESAME

| matricola | id_esame |
| --------- | -------- |
| 12345     | 1        |
| 12345     | 2        |
| 12346     | 1        |

Qui la chiave primaria √® **composta**:

```
PK = (matricola, id_esame)
```

Questa coppia identifica univocamente una singola iscrizione.

---
## Il nome della colonna
Il nome della colonna si chiama attributo

## Valore di una colonna in una riga

Il contenuto di una riga dentro una colonna si chiama **valore** o **dato dell‚Äôattributo**. In altre parole, √® il valore specifico che quella colonna (attributo) assume per una determinata riga (record o tupla).

**Esempio:**
- Tabella: Persone
- Colonna/Attributo: Nome
- Riga 1, colonna Nome: ‚ÄúMario‚Äù ‚Üí ‚ÄúMario‚Äù √® il valore dell‚Äôattributo Nome per quella riga.

## Confronto con database non relazionali (NoSQL)

Nei database non relazionali:

* esiste solitamente un **identificatore univoco** del dato (es. `_id` in MongoDB)
* **non esistono chiavi esterne formali**
* le relazioni sono gestite dall‚Äôapplicazione o tramite strutture annidate

### Esempio MongoDB

```
{
  _id: "u1",
  nome: "Anna",
  ordini: [501, 502]
}
```

* `_id` svolge un ruolo simile alla chiave primaria
* le relazioni non sono vincolate dal database

---

## Schema gerarchico di identificazione

```
Database
 ‚îî‚îÄ‚îÄ Schema
      ‚îî‚îÄ‚îÄ Tabella
           ‚îî‚îÄ‚îÄ Record (riga)
```

* **Database** ‚Üí identificato dal suo nome
* **Schema** ‚Üí identificato dal suo nome all‚Äôinterno del database
* **Tabella** ‚Üí identificata dalla coppia *(schema, nome_tabella)*
* **Record** ‚Üí identificato dalla **chiave primaria**

---

## Confronto: chiave primaria vs nome della tabella

| Aspetto                | Chiave primaria (PK)                    | Nome della tabella                     |
| ---------------------- | --------------------------------------- | -------------------------------------- |
| Cosa identifica        | Un **record (riga)**                    | Una **tabella**                        |
| Ambito                 | Interno alla tabella                    | All‚Äôinterno di uno **schema/database** |
| Unicit√†                | Deve essere **univoca** per ogni record | Deve essere univoco nello schema       |
| Pu√≤ cambiare?          | No (o fortemente sconsigliato)          | S√¨ (rinomina tabella)                  |
| Serve per le relazioni | S√¨ (referenziata dalle FK)              | No                                     |
| Esempio                | `id_cliente = 10`                       | `public.cliente`                       |

üëâ **Errore comune da evitare**: pensare che la chiave primaria identifichi la tabella.

---

## Collegamento a Hive Metastore e Big Data

Nei sistemi Big Data basati su **Hive** (e pi√π in generale su Hadoop/Cloudera), i concetti di database e tabella esistono ancora, ma il ruolo delle chiavi cambia.

### Hive Metastore

L' **Hive Metastore** √® il servizio che mantiene i **metadati** delle tabelle, tra cui:

* database
* nome della tabella
* colonne e tipi di dato
* partizioni
* percorso fisico dei dati su HDFS o Object Storage

üìå In Hive:

* una tabella √® identificata da **(database, nome_tabella)**
* esattamente come negli RDBMS con *(schema, nome_tabella)*

### Gerarchia in Hive

```
Hive Metastore
 ‚îî‚îÄ‚îÄ Database
      ‚îî‚îÄ‚îÄ Table
           ‚îú‚îÄ‚îÄ Schema (nome colonna, tipo dato)
           ‚îî‚îÄ‚îÄ Partition (opzionale)
                ‚îî‚îÄ‚îÄ File / Record
```

### Chiavi primarie in Hive

* Hive **supporta sintatticamente** PRIMARY KEY e FOREIGN KEY, non sono vincoli applicati** (non viene garantita l‚Äôunicit√†)
Hive accetta la sintassi, ma non fa nessun controllo: non garantisce l‚Äôunicit√† della primary key, n√© verifica che la foreign key corrisponda a una chiave primaria in un‚Äôaltra tabella. Questo significa che il sistema il sistema non controlla davvero che:
a) I valori della primary key siano unici (cio√® che non ci siano duplicati nella colonna dichiarata come chiave primaria)
b) I valori della foreign key esistano davvero come chiave primaria in un‚Äôaltra tabella (cio√® non viene garantita l‚Äôintegrit√† referenziale)
In pratica, Hive accetta la sintassi ma non applica nessun vincolo: puoi avere duplicati nella primary key o valori ‚Äúorfani‚Äù nella foreign key senza che Hive dia errore. Queste dichiarazioni servono solo come informazione, non come regola obbligatoria.
* servono principalmente per:
  * informazione, non come regola obbligatoria.
  * ottimizzazioni del query planner
  * integrazione con strumenti di BI

üëâ In Hive:

> **la chiave primaria non garantisce l‚Äôunicit√† dei record**, ma descrive l‚Äôintenzione logica del modello.

### Confronto RDBMS vs Hive

| Aspetto                | RDBMS                  | Hive / Big Data            |
| ---------------------- | ---------------------- | -------------------------- |
| Identit√† tabella       | (schema, nome)         | (database, nome)           |
| PK applicata           | S√¨ (vincolo reale)     | No (solo metadato)         |
| FK applicata           | S√¨                     | No                         |
| Integrit√† referenziale | Garantita              | Demandata all‚Äôapplicazione |
| Focus                  | Coerenza transazionale | Analisi su grandi volumi   |

### Collegamento concettuale chiave

* **RDBMS** ‚Üí PK/FK = vincoli forti
* **Hive/Big Data** ‚Üí PK/FK = informazione logica
* **Metastore** ‚Üí ‚Äúcatalogo‚Äù delle tabelle, non dei record  (I dati sono nel datalake)


-------|----------------------|-------------------|
| Cosa identifica | Un **record (riga)** | Una **tabella** |
| Ambito | Interno alla tabella | All‚Äôinterno di uno **schema/database** |
| Unicit√† | Deve essere **univoca** per ogni record | Deve essere univoco nello schema |
| Pu√≤ cambiare? | No (o fortemente sconsigliato) | S√¨ (rinomina tabella) |
| Serve per le relazioni | S√¨ (referenziata dalle FK) | No |
| Esempio | `id_cliente = 10` | `public.cliente` |

üëâ **Errore comune da evitare**: pensare che la chiave primaria identifichi la tabella.

---

## Quando scegliere RDBMS, NoSQL o Hive

La scelta tra **database relazionali**, **NoSQL** e **Hive/Big Data** dipende principalmente dal **tipo di dati**, dal **carico di lavoro** e dai **requisiti di coerenza e scalabilit√†**.

---

### Quando scegliere un database relazionale (RDBMS)

Scegli un **RDBMS** quando:

* i dati sono **altamente strutturati**
* lo schema √® **stabile nel tempo**
* sono richieste **transazioni affidabili**
* l‚Äôintegrit√† dei dati √® **critica**

üìå Casi d‚Äôuso tipici:

* sistemi gestionali (ERP, CRM)
* contabilit√† e fatturazione
* sistemi bancari e finanziari
* applicazioni OLTP

üëâ Perch√©: PK e FK garantiscono **coerenza forte** e **integrit√† referenziale**.

---

### Quando scegliere un database NoSQL

Scegli un **NoSQL** quando:

* i dati sono **eterogenei o semi-strutturati**
* lo schema cambia frequentemente
* √® richiesta **alta scalabilit√† orizzontale**
* le prestazioni sono pi√π importanti della coerenza immediata

üìå Casi d‚Äôuso tipici:

* applicazioni web ad alto traffico
* caching e session management (Redis)
* IoT e time series
* sistemi distribuiti globali

üëâ Perch√©: maggiore **flessibilit√†** e **scalabilit√†**, accettando coerenza eventuale.

---

### Quando scegliere Hive / Big Data

Scegli **Hive** (o sistemi Big Data simili) quando:

* i dati sono **molto voluminosi** (Big Data)
* il carico √® principalmente **analitico** (OLAP) -> Significa che il focus √® sulla lettura e aggregazione di grandi volumi di dati   (somme, medie, conteggi su milioni/miliardi di record), non su modifiche frequenti di singoli record
* non servono transazioni riga-per-riga -> Hive non √® ottimizzato per aggiornamenti, inserimenti o eliminazioni frequenti su singoli record.
* l‚Äôobiettivo √® l‚Äôanalisi storica e batch -> I dati elaborati sono storici (gi√† accumulati), e l'elaborazione avviene in lotti pianificati (batch processing) piuttosto che in tempo reale.

**Approfondimento sui tre punti:**

- **Carico analitico (OLAP):** OLAP (Online Analytical Processing) √® progettato per analizzare grandi quantit√† di dati, eseguendo operazioni di aggregazione, raggruppamento e calcolo su dataset estesi. Non √® pensato per gestire modifiche frequenti di singoli record, ma per rispondere a domande complesse come "Qual √® la media delle vendite per regione negli ultimi 5 anni?".
- **Nessuna transazione riga-per-riga:** Hive non √® adatto a gestire aggiornamenti, inserimenti o cancellazioni frequenti su singoli record. Se l'applicazione richiede di modificare dati individuali in tempo reale (es. aggiornare il saldo di un conto bancario), √® meglio usare un RDBMS. Hive √® pensato per elaborare dati stabili e consolidati.
- **Analisi storica e batch:** L'elaborazione avviene su dati storici, gi√† accumulati, e viene eseguita in modalit√† batch, cio√® in lotti pianificati (ad esempio, analizzare le vendite di tutto l'anno ogni notte). Non √® pensato per operazioni in tempo reale, ma per analisi approfondite su grandi volumi di dati.

üìå Casi d‚Äôuso tipici:

* data warehouse
* data lake
* reportistica e BI
* analisi su grandi dataset storici

üëâ Perch√©: Hive separa **storage e compute** e scala su grandi volumi, ma non applica vincoli PK/FK.

---

### Confronto decisionale rapido

| Esigenza                | Tecnologia consigliata |
| ----------------------- | ---------------------- |
| Transazioni critiche    | RDBMS                  |
| Schema flessibile       | NoSQL                  |
| Altissimo volume dati   | Hive / Big Data        |
| Integrit√† referenziale  | RDBMS                  |
| Scalabilit√† orizzontale | NoSQL / Hive           |
| Analytics e BI          | Hive                   |

---

## Riassunto finale

* **La tabella rappresenta un‚Äôentit√†**
* **La chiave primaria identifica un record della tabella**
* **La chiave esterna collega record di tabelle diverse**
* Nei database relazionali, PK e FK garantiscono coerenza e integrit√† dei dati

### Esempio tabellare: attributo, colonna, contenuto, record

| Nome   | Et√† | Citt√†     |
|--------|-----|-----------|
| Luca   | 25  | Milano    |
| Anna   | 30  | Roma      |
| Marco  | 40  | Torino    |

- Gli attributi sono: Nome, Et√†, Citt√† (le caratteristiche dell‚Äôentit√† ‚Äúpersona‚Äù).
- Le colonne sono: ‚ÄúNome‚Äù, ‚ÄúEt√†‚Äù, ‚ÄúCitt√†‚Äù (ogni colonna contiene i valori di un attributo).
- I contenuti delle colonne sono: Luca, Anna, Marco (per ‚ÄúNome‚Äù), 25, 30, 40 (per ‚ÄúEt√†‚Äù), Milano, Roma, Torino (per ‚ÄúCitt√†‚Äù).
- Ogni riga √® un record, cio√® una persona con i suoi valori per ogni attributo.

üëâ Frase chiave da ricordare:

> *La chiave primaria identifica univocamente una riga di una tabella; la chiave esterna realizza le relazioni tra tabelle.*

---

## Chiave primaria nei database non relazionali

Nei database non relazionali, il concetto di chiave primaria esiste ma pu√≤ essere diverso rispetto ai database relazionali:
- Nei database documentali (es. MongoDB), ogni documento ha un identificatore unico (di solito il campo _id), che svolge il ruolo di chiave primaria.

Es. Database documentale 

{
   "_id": "507f1f77bcf86cd799439012",
   "nome": "Luca",
   "cognome": "Bianchi"
}
{
   "_id": "507f1f77bcf86cd799439013",
   "nome": "Giulia",
   "cognome": "Verdi"
}
{
   "_id": "507f1f77bcf86cd799439014",
   "nome": "Anna",
   "cognome": "Neri"
}

- Nei database key-value, la ‚Äúchiave‚Äù √® sempre unica e identifica il valore associato.
- Nei database a colonne (es. Cassandra), si usano chiavi primarie composte per identificare in modo univoco le righe.
- Nei database a grafo, i nodi e le relazioni hanno identificatori unici.

Quindi, anche nei database non relazionali esiste un meccanismo per identificare univocamente i dati, ma la gestione e la struttura possono variare a seconda del modello.

### Differenza tra database relazionali e non relazionali

- **Relazioni**: nei relazionali usi chiavi esterne e JOIN; nei non relazionali le relazioni esistono ma si modellano in altri modi (embed dei dati nei documenti, denormalizzazione, chiavi composte nei columnar, archi nei grafi) senza le JOIN tradizionali.
- **Schema**: i relazionali hanno schemi rigidi; i non relazionali permettono schemi flessibili o schema-less.
- **Consistenza**: i relazionali offrono transazioni ACID complete; molti non relazionali privilegiano scalabilit√† e disponibilit√†, adottando modelli di consistenza configurabili (eventuale o per-partizione).
- **Scalabilit√†**: i relazionali scalano tipicamente in verticale o con sharding pi√π complesso; i non relazionali sono progettati per scalare orizzontalmente in modo nativo.

Quindi ‚Äúnon relazionale‚Äù non significa che non puoi mettere in relazione i dati in  tabelle diverse, ma che il modo di modellare e interrogare le relazioni √® diverso rispetto al modello tabellare con JOIN.
Piu semplicmente significa che non usano il modello relazionale a tabelle con schema rigido e JOIN/chiavi esterne. Nei NoSQL le relazioni ci sono, ma si modellano diversamente a seconda del motore: embed/denormalizzazione nei documentali, chiavi composte e clustering nei columnar, archi nei grafi, pattern applicativi nei key-value. Il nome evidenzia che non adottano il paradigma relazionale classico, non che i dati restino isolati.


# Documento riassuntivo
# File, Oggetto logico, DistCp e Replication

# 1.Cos‚Äô√® un file

Un file √® un oggetto fisico gestito dal filesystem del sistema operativo.

# Definizione:

Un file √® una sequenza di byte memorizzata su un supporto fisico, identificata da un nome e da un percorso, e gestita dal filesystem.

Caratteristiche:

- Oggetto fisico

- Gestito dal sistema operativo

- Non ha significato sul contenuto

- Contiene solo dati grezzi (byte)

Esempi:

/data/clienti.csv

/warehouse/db/table/part-0001.parquet

# 2. Cos‚Äô√® un oggetto logico

Un oggetto logico √® un‚Äôunit√† di dati definita dal sistema applicativo, indipendente dalla sua rappresentazione fisica su file.

Definizione:

Un oggetto logico √® un‚Äôentit√† concettuale che ha significato per il sistema che la gestisce (database, HDFS, Hive, Kafka).

Esempi di oggetti logici:

- Database

- Tabella

- Record

- Topic Kafka

- Partizione Hive

üëâ Anche se fisicamente sono salvati come file, logicamente non sono file.

# 3.Il database: √® logico o fisico?

Il database √® un oggetto logico, questo perch√©:

- √à definito da schema, tabelle, vincoli

- √à gestito dal DBMS (Un DBMS (Database Management System, ovvero Sistema di Gestione di Basi di Dati) √® un software che consente la creazione, gestione, manipolazione e interrogazione di database)

- Non coincide con un singolo file

Parte fisica:

- File di dati

- File di log

- File di indice

üëâ I file sono rappresentazione fisica, non il database in s√©.

Un database √® costituito quindi anche da file. I dati, gli indici, i log delle transazioni e i metadati di un database vengono fisicamente memorizzati su uno o pi√π file gestiti dal DBMS. Tuttavia, questi file sono organizzati e gestiti in modo strutturato dal DBMS, che fornisce funzionalit√† avanzate di accesso, sicurezza e integrit√†, rendendo il database molto pi√π di una semplice raccolta di file.

# 4Ô∏è.DistCp (Distributed Copy)
Cos‚Äô√®

DistCp √® uno strumento di copia distribuita che lavora a livello di filesystem.

Oggetto trattato

File

Directory

üëâ DistCp non conosce oggetti logici.

Copia:

- File e cartelle

- Dati grezzi

- (opzionalmente) permessi e timestamp

Cosa NON copia:

- Database logici

- Tabelle come entit√†

- Schema

- Metadati applicativi

üìå DistCp copia una fotografia dei dati, non mantiene sincronizzazione.

5Ô∏è‚É£ Replication
Cos‚Äô√®

La replication √® un meccanismo automatico e continuo per mantenere pi√π copie coerenti dei dati.

Oggetto trattato:

Oggetti logici del sistema

Esempi:

Database ‚Üí tabelle, record

HDFS ‚Üí blocchi

Kafka ‚Üí topic, partizioni

Caratteristiche:

- Automatica

- continua

Mantiene i dati aggiornati

Gestisce metadati e coerenza

6Ô∏è‚É£ Confronto finale: DistCp vs Replication
Aspetto	DistCp |	Replication
Livello	Filesystem |	Logico / applicativo
Oggetto	File / directory | Oggetto logico
Schema	‚ùå No | ‚úÖ S√¨
Aggiornamenti	‚ùå No | ‚úÖ S√¨
Uso tipico	Migrazione, backup	Alta disponibilit√†
7Ô∏è‚É£ Frasi pronte da esame

Il file √® un oggetto fisico del filesystem.

Il database √® un oggetto logico gestito dal DBMS.

DistCp copia file, non oggetti logici.

La replication replica oggetti logici mantenendoli sincronizzati.

con distcp puoi spostare solo file e cartelle a livello di filesystem distribuito (come HDFS), ma non puoi spostare un database nel senso logico gestito da un DBMS. Spostando solo i file, non vengono trasferite le informazioni di metadati, permessi, configurazioni e strutture interne che il DBMS gestisce. Per spostare un database in modo corretto, occorre utilizzare strumenti specifici del DBMS (come dump, export/import, backup/restore) che garantiscono la coerenza e l‚Äôintegrit√† dei dati e dei metadati.
Questo perch√© un database non √® solo un insieme di file, ma comprende anche metadati, strutture interne, permessi, configurazioni e informazioni di gestione che sono mantenute dal DBMS. Spostando solo i file con distcp, questi elementi non vengono trasferiti o ricostruiti correttamente, rischiando di compromettere la coerenza, l‚Äôintegrit√† e la funzionalit√† del database. Solo gli strumenti specifici del DBMS garantiscono che tutti i componenti necessari vengano esportati e importati in modo sicuro e completo.
Metadati, strutture interne, permessi, configurazioni e informazioni di gestione di un database sono generalmente contenuti:
All‚Äôinterno di file specifici gestiti dal DBMS, separati dai dati veri e propri.
In tabelle di sistema (dette anche cataloghi o system tables) che il DBMS utilizza per memorizzare informazioni su tabelle, indici, utenti, permessi, configurazioni e struttura del database.
In file di configurazione esterni (ad esempio, file .conf o .ini) per parametri di funzionamento del DBMS.
Nei log di sistema e di transazione, che tengono traccia delle operazioni e garantiscono il recupero e la coerenza.
Questi elementi sono gestiti in modo trasparente dal DBMS e non sono accessibili o modificabili direttamente come semplici file di dati.
La replica a livello di DBMS (ad esempio, la replica integrata di un database) garantisce la coerenza e l‚Äôintegrit√† di dati e metadati, perch√© avviene tramite meccanismi controllati dal DBMS stesso. Invece, la semplice replica o copia dei file a livello di filesystem (come con distcp) non garantisce la corretta replica di tutte le informazioni necessarie al funzionamento del database. Solo la replica gestita dal DBMS assicura che il database sia utilizzabile e integro nella destinazione.