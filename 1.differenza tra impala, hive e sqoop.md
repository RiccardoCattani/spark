# DIFFERENZA TRA HIVE, IMPALA E SQOOP
(E TRA DATA WAREHOUSE E MOTORE SQL)

## CONCETTO FONDAMENTALE: GOVERNA VS POSSIEDE

**Storage** (HDFS, S3, ADLS)
- Possiede fisicamente i dati (file che contengono le righe effettive)
- Garantisce durabilità, replica e accesso distribuito
- Non conosce schemi, tabelle, strutture: vede solo byte e blocchi

**Data Warehouse** (Hive, Snowflake, BigQuery, Redshift)
Governa i metadati:
a) Organizza metadati: Ossia definisce schemi, tabelle, partizioni, sicurezza e processi ETL (Extract, trasform, load*)
b) Cataloga dove stanno i dati e come interpretarli
c) I file fisici rimangono nello storage sottostante
- Nota: alcuni DW cloud (Snowflake, BigQuery) integrano anche lo storage, ma il principio resta

*Extract (Estrazione): consiste nel prelevare dati da una o più fonti eterogenee (database, file, API, ecc.).
Transform (Trasformazione): i dati estratti vengono puliti, arricchiti, aggregati o convertiti in un formato adatto all’analisi o all’archiviazione. Questa fase può includere la normalizzazione, la deduplicazione, la conversione di tipi di dato, il calcolo di nuovi campi, ecc.
Load (Caricamento): i dati trasformati vengono caricati nel sistema di destinazione, tipicamente un data warehouse, un database analitico o un data lake, dove saranno disponibili per analisi, reportistica o altre applicazioni.

**Motori SQL** (Impala, Hive, Spark SQL, Trino)

Creano, modificano ed eliminano dati e strutture, tramite comandi SQL:

CREATE: crea tabelle, schemi, database, viste, indici (es. CREATE TABLE ...)
INSERT: aggiunge nuove righe (es. INSERT INTO ...)
UPDATE: modifica dati esistenti (es. UPDATE ... SET ...)
DELETE: elimina righe (es. DELETE FROM ...)
DROP: elimina tabelle, schemi, database (es. DROP TABLE ...)
ALTER: modifica la struttura (aggiunge/rimuove colonne, cambia tipi, ecc.)

## DATA LAKE VS DATA WAREHOUSE VS DATA CATALOG

| Aspetto                | Data Lake                   | Data Warehouse              | Data Catalog                              |
|------------------------|-----------------------------|-----------------------------|----------------------------------------   |
| Possiede/Governa       | Possiede i dati fisicamente | Governa metadati tecnici (non possiede i dati)| Governa metadati di business (non possiede i dati)|
| Funzione principale    | Storage (memorizza)         | Query + Governance tecnica  | Documenta + Governance business           |
| Esegue query SQL       | No (solo storage)           | Sì (SELECT, JOIN, ecc.)     | No (non esegue query)                     |
| Tipo dati              | Grezzi, strutturati e misti | Strutturati                 | Non applicabile (cataloga, non memorizza) |
| Schema                 | On-read (al momento della query)| On-write (alla scrittura)  | Documenta schemi da altri sistemi      |
| Dove stanno i metadati | N/A: ha solo file fisici  |  database relazionali esterni tramite il servizio Hive Metastore | DB del Catalog (es. Postgres/MySQL/Atlas+ES) |
| Governance tecnica     | Limitata o assente          | Elevata (schemi, permessi, ETL) | No (cataloga quella degli altri)      |
| Governance business    | Assente (serve Catalog)     | Assente (serve Catalog)     | Sì (ownership, policy, lineage, qualità)  |
| Utenti                 | Data scientist, ingegneri dati | Analisti, BI, business      | Data steward, governance, business     |
| Esempi                 | Hadoop, S3, ADLS            | Hive, Snowflake, BigQuery   | Alation, Collibra, Apache Atlas           |

**⚠️ Attenzione: Data Lake ≠ Data Catalog**

| Aspetto              | Data Lake                                    | Data Catalog                                      |
|----------------------|--------------------------------------------|------------------------------------------------     |
| **Cosa è**           | Storage system (memorizza dati fisicamente)| Metadata/Governance platform (documenta dati)       |
| **Possiede/Governa** | Possiede (memorizza file)                  | Governa metadati (non possiede dati; conserva i propri metadati in un DB interno) |
| **Contiene**         | Dati grezzi, strutturati e misti           | Definizioni business, ownership, policy, lineage    |
| **Esempi**           | Hadoop/HDFS, S3, ADLS                      | Alation, Collibra, Apache Atlas                     |
| **Funzione**         | Memorizzare dati durevolmente              | Catalogare dove stanno i dati e cosa significano    |
| **Conosce schemi**   | No (on-read)                               | Sì (documenta schemi e strutture)                   |
| **Esegue query**     | No (solo storage)                          | No (cataloga, non esegue query)                     |

### DIFFERENZA TRA GOVERNANCE E MANAGEMENT###

- Gestione (management): riguarda l’amministrazione operativa quotidiana di risorse, processi e attività. Si occupa di eseguire, monitorare e ottimizzare le operazioni.
- Governance: indica l’insieme di regole, politiche, responsabilità e controlli che definiscono come vengono prese le decisioni, chi è responsabile, come si garantisce la conformità e la qualità, e come si gestiscono rischi e sicurezza.

### ANALOGIA CON IL SUPERMERCATO (PRATICO E CHIARO)

**Data Lake = Mercato all'ingrosso (disordinato)**
- Verdure sporche appena raccolte
- Carni non ancora pulite  
- Ingredienti di tutti i tipi ammassati insieme
- Nessuna organizzazione, tutto mischiato
- Informazioni incomplete o duplicate
- **Concetto**: dati grezzi, senza struttura, come arrivano dalle sorgenti

**Data Warehouse = Ristorante pulito e organizzato**
- Verdure lavate, tagliate e organizzate
- Carni già porzionate e etichettate
- Tutto catalogato negli scaffali giusti (reparto verdure, carni, latticini, ecc.)
- Pronto per essere cucinato/usato
- Schema rigoroso, dati puliti e strutturati
- **Concetto**: dati trasformati, pronti per l'analisi, con schemi definiti

**Data Catalog = depliant/menu del Ristorante**
- Ti dice: "Il tonno fresco è nel reparto pesce, arrivato stamattina, biologico"
- Ti dice: "Il latte ha scadenza tra 5 giorni, contiene lattosio"
- Non stai mangiando lì, stai solo **leggendo informazioni su cosa c'è**
- Documenta significato, proprietario, regole, qualità
- **Concetto**: metadati di business, non i dati effettivi

Nell’analogia:

- Il Data Catalog è come il depliant/menu del ristorante: ti dice dove si trova ogni ingrediente, a cosa serve, chi lo gestisce, ecc. (ma non contiene la verdura stessa).
- Il Data Warehouse è la cucina/dispensa dove la verdura è effettivamente organizzata, pulita e pronta per essere usata.


### ESEMPIO PRATICO: RICERCA DI DATI SU VENDITE

**Scenario**: "Quali sono i clienti che hanno speso più di 1000€?"

**Step 1: Consulti il Data Catalog** (per scoprire dove trovare i dati)
- Cerchi: "Dove trovo le spese dei clienti?"
- Risposta dal Catalog: 
  - ✅ Esiste una tabella chiamata `ORDINI`
  - ✅ Ha le colonne: `id_cliente`, `importo`, `data`
  - ✅ È nel Data Warehouse (tabella strutturata)
  - ✅ È aggiornata ogni 6 ore
  - ✅ Proprietario: Team Finance

**Step 2: Interroghi il Data Warehouse** (per ottenere i dati veri)
```sql
SELECT id_cliente, SUM(importo) as spesa_totale
FROM ORDINI
WHERE SUM(importo) > 1000
GROUP BY id_cliente;
```
- Risultato: lista effettiva di clienti e loro spese (righe reali)

**NON ricerchi la spesa nel Data Catalog**, ricerchi il **NOME E LA POSIZIONE** della tabella nel Catalog, poi interroghi il Warehouse per i dati effettivi.

**⚠️ Data Catalog NON è un contenitore**

Il Data Catalog **non memorizza dati**, non è un contenitore:
- **Non contiene** dati effettivi (righe, file, tabelle)
- **Non contiene** metadati tecnici (se non come riferimenti/indici)
- **Documenta e cataloga** i dati/tabelle che vivono in altri sistemi (Data Warehouse, Storage, Database)
- **Punta a** e aggrega informazioni da altre piattaforme
66
**⚠️ Data Catalog ≠ Data Warehouse**

| Aspetto              | Data Warehouse (Hive, Snowflake, BigQuery) | Data Catalog (Alation, Collibra, Atlas) |
|----------------------|--------------------------------------------|-----------------------------------------|
| **Esegue query SQL** | Sì: SELECT, INSERT, UPDATE, DELETE         | No: non esegue query                    |
| **Governa dati**     | Sì: schemi, tabelle, partizioni, permessi  | No: cataloga informazioni da altri sistemi |
| **Memorizza dati**   | No (governa, non possiede); dati in storage | No (non memorizza dati, solo metadati business) |
| **Controlla accesso**| Sì: RBAC/ABAC, masking, filtri riga/colonna | No: eventuali preview passano per il motore |
| **Metadati**         | Tecnici: information_schema, statistiche, indici | Business: significato, ownership, policy, lineage |
| **Utenti**           | Ingegneri, analisti, BI (query e trasformazioni) | Data steward, governance, business (ricerca significato) |
| **Esempio di query** | `SELECT * FROM vendite WHERE anno=2024` → righe reali | `search("vendite", filter="PII")` → metadati business |

**In una frase:**
- **Data Warehouse** = motore che esegue query e governa la struttura tecnica (schemi, permessi SQL)
- **Data Catalog** = libreria che documenta il significato business e la governance (non possiede né interroga dati)

**Dove vivono fisicamente i metadati?**

I metadati del Data Catalog si trovano **nel database interno del Catalog stesso**, non nei sistemi che cataloga:

```
┌─────────────────────────┐
│ Storage (S3, HDFS)      │
│ file_vendite.parquet    │
└─────────────────────────┘
           ↑
           
┌──────────────────────────────┐
│ Data Warehouse (Hive)        │
│ TABLE vendite (schema)       │
│ Hive Metastore (metadati)    │
└──────────────────────────────┘
           ↑
           
┌────────────────────────────────────────┐
│ Data Catalog (Alation/Collibra/Atlas)  │
│ ┌──────────────────────────────────┐   │
│ │ Database interno del Catalog:    │   │
│ │ - "vendite = reddito lordo"      │   │
│ │ - "owner: Mario Rossi"           │   │
│ │ - "sensibile GDPR"               │   │
│ │ - "usata in 5 report"            │   │
│ │ - "lineage: Salesforce→Hive"     │   │
│ └──────────────────────────────────┘   │
└────────────────────────────────────────┘
```

**Di seguito i Datacatalog/governance e relativo DB:**
 
- **Alation (Data Catalog)**: usa database relazionale interno (tipicamente PostgreSQL; supporta MySQL/Oracle) + repository per documenti/descrizioni
- **Collibra (Data Catalog)**: usa database interno (PostgreSQL) + repository metadati centralizzato
- **Apache Atlas (Data Catalog)**: usa HBase (per metadati, NoSQL a colonne) + Elasticsearch (per ricerca) nel cluster Hadoop

**Caratteristica importante: indipendenza**
- Se il Data Warehouse (Hive) cade, il Data Catalog rimane online (documenta comunque cosa c'era)
- Se il Data Catalog cade, i dati rimangono intatti nel Storage/DW (il Catalog non li controlla, solo li documenta)
- I metadati del Catalog sono **completamente separati** e indipendenti dall'architettura dati


## DATABASE RELAZIONALE VS NON RELAZIONALE VS TRANSAZIONALE (RIASSUNTO)

| Aspetto            | Relazionale (RDBMS)                                 | Non relazionale (NoSQL)                                        | Transazionale (ACID)                                               |
|--------------------|------------------------------------------------------|----------------------------------------------------------------|---------------------------------------------------------------------|
| Modello dati       | Tabelle, righe, colonne                             | Documenti JSON, key-value, wide-column, grafo                  | Qualsiasi modello che offra ACID                                    |
| Schema             | Rigoroso (schema-on-write)                          | Flessibile/schema-on-read, spesso denormalizzato               | Rigoroso dove serve coerenza transazionale                          |
| Transazioni        | ACID native (commit/rollback)                       | Variabile: spesso eventual consistency; alcune piattaforme ACID | Focus su atomicità/isolamento/durabilità                            |
| Scalabilità        | Tipicamente verticale (sharding possibile)          | Orizzontale nativa                                             | Dipende dal motore: RDBMS scalano meno orizzontalmente; alcuni NewSQL/NoSQL ACID scalano orizzontalmente |
| Casi d’uso tipici  | OLTP classico: ordini, fatture, anagrafiche, ERP    | Contenuti web/mobile, log/IoT, cataloghi prodotti, time-series, grafi | Qualsiasi caso con requisiti di scrittura atomica (pagamenti, ordini, inventory) |
| Esempi             | PostgreSQL, MySQL, Oracle, SQL Server               | MongoDB (documenti), Redis (KV), Cassandra/HBase (wide-column), Neo4j (grafo) | PostgreSQL/MySQL/Oracle/SQL Server; Google Spanner, CockroachDB, Yugabyte; MongoDB transazioni multi-doc |

In sintesi:
- **Relazionale** = schema rigido, JOIN forti, ACID nativo.
- **Non relazionale** = schema flessibile, denormalizzazione, scala orizzontale facile, coerenza configurabile.
- **Transazionale (ACID)** = requisito di atomicità e coerenza: può essere RDBMS o alcune piattaforme NoSQL/NewSQL che offrono transazioni.


## DATI, METADATI E GOVERNANCE

**Dati (Righe)**
- Contenuto informativo vero: righe 
- Memorizzati nei file (Parquet, ORC, CSV, ecc.) su storage
- Vivono in: HDFS, S3, ADLS (mai in Hive Metastore né in Impala)

**Metadati**
- Informazioni che descrivono i dati
- Schema, tabelle, colonne, tipi, partizioni, percorsi, permessi, statistiche
- Nota: la "tabella" come oggetto (nome, schema, proprietà, location, formati) è metadato; le righe contenute sono dati
- Gestiti da: Hive Metastore (per Hive/Impala)

### SQL vs Data Catalog (Riassunto veloce)

| Aspetto         | SQL (motore)                                               | Data Catalog (Alation/Collibra/Atlas)                          |
|-----------------|-------------------------------------------------------------|-----------------------------------------------------------------|
| Scopo           | Leggere/scrivere dati, eseguire query, gestire schema       | Documentare significato, ownership, policy, lineage             |
| Gestisce        | Tabelle, colonne, tipi, DDL/DML, permessi (GRANT/REVOKE)    | Definizioni business, KPI, classificazioni (PII), qualità, glossario |
| Enforcement     | Sì: controlli d’accesso, masking, filtri a livello riga/colonna | No: non esegue query; eventuali preview rispettano i permessi della sorgente |
| Preview dati    | Nativo (via query)                                          | Facoltativo; passa tramite la connessione al motore             |
| Dove vive       | Motore dati (Hive/Impala/Snowflake/PostgreSQL/…)            | Piattaforma separata                                            |
| Utenti          | Ingegneri, analisti, BI                                     | Data steward, governance, business                              |
| Esempi          | Hive, Impala, Spark SQL, Snowflake, BigQuery                | Alation, Collibra, Apache Atlas                                 |

In una frase: SQL governa struttura e accesso; il Catalog governa significato e regole.

**Gerarchia organizzativa: Database > Schema > Tabella**

```
DATABASE (contenitore generale)
│
├── SCHEMA (gruppo logico / namespace)
│   │
│   └── TABELLA (struttura dati con righe/colonne)
│       │
│       ├── COLONNA (campo: nome + tipo)
│       └── RIGA (record singolo)
```

**Schema (o Database in Hive)** = Contenitore/Namespace
- Raggruppa tabelle correlate logicamente
- Evita conflitti di nome (es. `finance.vendite` vs `marketing.vendite`)
- Gestisce permessi a livello di gruppo

**Tabella** = Struttura dati effettiva
- Contiene righe (record) e colonne (campi)
- Ha schema definito (nomi colonne + tipi di dato)

**Esempio pratico:**
```sql
-- Creare uno schema (in Hive si chiama DATABASE)
CREATE DATABASE finance;
CREATE DATABASE marketing;

-- Creare tabelle in schemi diversi
CREATE TABLE finance.vendite (id INT, importo DECIMAL, data DATE);
CREATE TABLE marketing.vendite (id INT, prodotto VARCHAR, campagna VARCHAR);
-- ↑ Stesso nome "vendite", ma tabelle diverse!

-- Accedere alle tabelle
SELECT * FROM finance.vendite;      -- Tabella del team Finance
SELECT * FROM marketing.vendite;    -- Tabella diversa del team Marketing
```

**Analogia rapida:**
```
Database = Biblioteca intera
Schema = Piano della biblioteca (es. Piano 1: Narrativa, Piano 2: Tecnica)
Tabella = Scaffale con libri (es. Romanzi, Poesia, Informatica)
```

**Governance del Data Warehouse** (governance TECNICA)

Il Data Warehouse gestisce la governance **tecnica**, ma non quella **di business**:

✅ **Governance TECNICA** (gestita dal Data Warehouse):
- Schemi, tabelle, partizioni e tipi di dato
- Sicurezza di accesso: permessi SQL (GRANT/REVOKE su tabelle)
- Storico tecnico: versioni, snapshot (con Delta/Iceberg)
- Processi ETL: orchestrazione di trasformazioni e caricamenti
- Metadati tecnici: formati (Parquet/ORC), paths, statistiche

❌ **Governance DI BUSINESS** (serve un Data Catalog esterno):
- Significato aziendale: cosa rappresenta ogni campo per l'azienda
- Ownership: chi è il data owner, chi è responsabile
- Policy aziendali: GDPR, retention, classificazione (pubblico/riservato)
- Lineage completo: provenienza e tutte le trasformazioni subite
- Qualità: anomalie, duplicati, completezza, validità
- Strumenti: Alation, Collibra, Apache Atlas

**Esempio pratico:**
```sql
-- Data Warehouse gestisce (governance tecnica):
CREATE TABLE vendite (id INT, importo DECIMAL, data DATE);
GRANT SELECT ON vendite TO utente_finance;
-- ✅ Sa: schema, permessi SQL

-- Data Catalog gestisce (governance business):
"vendite.importo = reddito lordo mensile (include bonus)"
"Owner: Mario Rossi (CFO), sensibile GDPR, retention 7 anni"
-- ✅ Sa: significato, policy, ownership
```

**Accesso a dati sensibili (GDPR): Alation vs SQL**
- **Alation** è un Data Catalog: non memorizza né elabora i dati; mo

- In Hadoop (Hive/Impala) usare **Apache Ranger** per:
  - Column masking (es. mascherare `email` o offuscare parzialmente `codice_fiscale`)
  - Row filter (limitare righe visibili per reparto/paese)
  - Audit centralizzato delle query
- Alternative/varianti: **Sentry** (legacy), **Lake Formation** (AWS), **Unity Catalog** (Databricks) con tag/policy.
- Per GDPR (diritto all’oblio/retention): usare **Delta/Iceberg/Hudi** per `DELETE` e gestione snapshot/`VACUUM`.

**Esempi pratici: masking e filtri (GDPR)**
- **Ranger – Column Masking**: imposta una policy sulla colonna `email` di `finance.vendite` (azione SELECT) con mascheramento parziale (es. mostra solo i primi 3 caratteri e il dominio) o totale (NULL/hash). La maschera si applica a tutte le query, viste incluse.
- **Ranger – Row-level Filter**: definisci un filtro di riga, ad es. `cntry_cd = 'IT'` per il ruolo `FINANCE_IT`, oppure usa attributi utente (es. `${USER.country}`) per filtri dinamici per paese/reparto.
- **Ranger + Atlas (Tag-based)**: tagga in Atlas le colonne PII (es. `email`, `codice_fiscale`) e crea in Ranger una policy “per tag” che applica maschere/filtri automaticamente a tutte le tabelle con quel tag.

*Pattern SQL-only (viste sicure), se non hai Ranger:*
```sql
-- Mascheramento colonna email tramite vista (Hive/Impala)
CREATE SCHEMA IF NOT EXISTS secure;
CREATE OR REPLACE VIEW secure.vendite_masked AS
SELECT
  id,
  CONCAT(SUBSTR(email, 1, 3), '***', SUBSTR(email, LOCATE('@', email))) AS email_mascherata,
  data,
  cntry_cd
FROM finance.vendite;

-- Filtro per righe (versione statica)
CREATE OR REPLACE VIEW secure.vendite_it AS
SELECT * FROM finance.vendite WHERE cntry_cd = 'IT';

-- Filtro per righe basato sull'utente (mappa utente→paese)
-- Nota: in Hive usa CURRENT_USER(); in Impala la funzione è USER()
CREATE TABLE IF NOT EXISTS security.user_country (utente STRING, cntry_cd STRING);
CREATE OR REPLACE VIEW secure.vendite_per_utente AS
SELECT v.*
FROM finance.vendite v
JOIN security.user_country m
  ON m.utente = CURRENT_USER()
 AND v.cntry_cd = m.cntry_cd;
```

Suggerimenti operativi:
- Preferisci policy centralizzate (Ranger/Lake Formation/Unity Catalog) a logica applicativa nelle viste: sono auditate e coerenti.
- Abilita audit di query e usa cifratura a riposo/in transito (HDFS Transparent Encryption, S3/KMS, TLS).
- Per GDPR “right to be forgotten”, combina `DELETE` su formati transazionali (Delta/Iceberg/Hudi) con procedure di compattazione/`VACUUM` secondo le policy di retention.

**Cosa SI trova con SQL** (il database conosce)

*I dati effettivi*
```sql
SELECT nome, importo FROM vendite WHERE anno = 2024;
-- Restituisce: Ana | 150€, Marco | 200€, Sofia | 300€, ...
-- SQL accede ai dati fisici e li legge
```

*Metadati tecnici* (il database conosce la sua struttura)
```sql
-- Nome colonne e tipi (Hive/Impala)
DESCRIBE vendite;
-- Oppure più dettagliato:
DESCRIBE EXTENDED vendite;
-- Risultato: nome_colonna | tipo_dato | commento
-- importo (DECIMAL), data (DATE), nome (VARCHAR), ecc.

-- Elencare tutte le colonne con formato dettagliato
SHOW COLUMNS FROM vendite;
-- Risultato: column_name, data_type, comment

-- Struttura completa della tabella (DDL)
SHOW CREATE TABLE vendite;
-- Risultato: lo statement CREATE TABLE completo con location, formato, partizioni

-- Nota: information_schema esiste in DB relazionali (MySQL, PostgreSQL)
-- ma Hive/Impala usano DESCRIBE, SHOW COLUMNS, SHOW CREATE TABLE
```

**Cosa NON si trova con SQL** (serve un Data Catalog esterno)

*Metadati di business* (il significato aziendale dei dati)
- "La colonna `importo` rappresenta il **reddito lordo annuale** (comprende bonus e incentivi)"
- "Il KPI `conversion_rate` è calcolato come **(ordini / visitatori) * 100**"
- "La tabella `vendite` è **proprietà del team Finance** e curata da Mario Rossi (data owner)"
- "Questo dato è **sensibile: GDPR**, accesso limitato al solo team Finance e Compliance"

*Governance e compliance* (regole aziendali e tracciabilità)
- **Lineage**: "Da dove viene questo dato? Salesforce → ETL → Hadoop → report finale (con 3 trasformazioni)"
- **Qualità**: "Questo dato ha problemi? 5% di valori duplicati, 2% di null anomali, 1 outlier rilevato"
- **Audit trail**: "Chi ha modificato questa colonna? (storico completo di cambiamenti e responsabili)"
- **Retention policy**: "Quanto tempo conservo questi dati? Cancellare dopo 5 anni (GDPR 'right to be forgotten')"
- **Classificazione**: "Questo è pubblico, ristretto, sensibile o strettamente confidenziale?"

*Strumenti specializzati* (dove mettere questi metadati)
- **Alation**: Catalogo di business - documenta significato, ownership, KPI, criticità
- **Collibra**: Governance platform - policy complete, compliance, audit trail
- **Apache Atlas**: Metadata repository - lineage, dipendenze, trasformazioni (open-source)

**Perché SQL non può contenere questi dati?**
- SQL è disegnato per dati strutturati (tabelle, righe, colonne) e query transazionali
- I metadati di business sono semantica e regole: difficili da organizzare in tabelle SQL
- Cambian frequentemente: le regole aziendali si aggiornano, ma il database rimane stabile
- Gestiti da team diversi: DBA gestisce il DB, Data Governance gestisce le policy

**Esempio completo: una colonna `email`**
```
NEL DATABASE (SQL):
├─ Data type: VARCHAR(255)
├─ Is nullable: YES
├─ Primary Key: NO
└─ Foreign Key: NO

NEL DATA CATALOG (Alation/Collibra):
├─ Proprietario (Data Owner): Antonio Bianchi (Marketing)
├─ Significato: Email di contatto del cliente per comunicazioni di marketing
├─ GDPR sensitivity: SENSIBILE (diritto all'oblio, consenso richiesto)
├─ Qualità: 97% filled, 0.5% duplicati, valido come email
├─ Lineage: Salesforce → Sqoop → HDFS → Hive table → Report BI
├─ Retention: Cancellare dopo 3 anni di inattività (GDPR compliance)
├─ Usato in: 12 report BI, 3 model ML, Dashboard Executive
└─ Ultimo aggiornamento: 2 ore fa (batch notturno da Salesforce)
```

**Riassunto finale**

| Aspetto | Dove | Chi lo gestisce |
|---------|------|-----------------|
| **Dati effettivi** | Database (SELECT) | Developers, analisti |
| **Metadati tecnici** (schema, tipi, indici) | Database (information_schema) | DBA, SQL |
| **Metadati di business** (significato, ownership) | Data Catalog | Data Steward, Domain Expert |
| **Governance** (GDPR, lineage, audit, qualità) | Data Governance Platform | Compliance Officer, Data Governance |

**In una frase**: SQL gestisce la **struttura e i contenuti**, il Data Catalog gestisce il **significato e le regole aziendali**.

---

## MODELLI DI ESECUZIONE: BATCH VS INTERATTIVO

**Esecuzione Batch (Hive)**
- Ogni query scatena più fasi (map/shuffle/reduce) con startup di container YARN
- Overhead di avvio: secondi/decine di secondi per fase
- Dati letti da HDFS in blocchi, spesso riscritti su disco tra fasi (spill/shuffle)
- Fault tolerance: task falliti si riavviano automaticamente
- Latenza: secondi/minuti su grandi volumi
- Throughput: massimo, parallelizzazione su molti nodi
- Ideale per: ETL pesanti, elaborazioni notturne, grandi join/aggregazioni con shuffle massivi

**Esecuzione Interattiva (Impala)**
- In-memory, no MapReduce, motore MPP (Massively Parallel Processing)
- Long-running: i daemon Impala rimangono accesi, nessun startup YARN per query
- Latenza: secondi o millisecondi
- Limits: dati devono stare in RAM totale del cluster
- Non robusto per: job lunghi, riscritture massive, fault recovery
- Ideale per: BI, dashboard, analisi esplorativa, query puntuali

**Confronto rapido**
| Aspetto           | Hive (Batch)              | Impala (Interattivo)         |
|-------------------|---------------------------|------------------------------|
| Esecuzione        | MapReduce/Tez/Spark       | In-memory MPP                |
| Latenza           | Secondi/minuti            | Secondi/millisecondi         |
| Startup YARN      | Sì, overhead               | No, daemon long-running     |
| Throughput        | Massimo, altamente scalabile | Minore, limitato da RAM   |
| Fault tolerance   | Ottima (retry task)       | Scarsa (fine query)          |
| Adatto per        | ETL, batch notturni       | BI, analisi interattiva      |
| Non adatto per    | Query real-time / BI rapido | ETL pesanti, volumi enormi |

**One-liner**: Usa **Hive per trasformazioni pesanti**, **Impala per letture veloci**.

---

## COME FUNZIONA MAPREDUCE

**Cos'è MapReduce**: Framework di programmazione distribuita per elaborare grandi volumi di dati in parallelo su cluster.

**Architettura a 2 fasi principali:**

### **FASE 1: MAP (Mapping/Proiezione)**

```
Input data (file HDFS)
│
├─ Split 1 (blocco 1) → Mapper 1 → (chiave, valore) intermedi
├─ Split 2 (blocco 2) → Mapper 2 → (chiave, valore) intermedi
└─ Split 3 (blocco 3) → Mapper 3 → (chiave, valore) intermedi
```

**Cosa fa Mapper:**
- Legge dati da HDFS in **blocchi paralleli** (default 128/256 MB)
- Applica una **funzione user-defined** a ogni riga
- Emette coppie **(chiave, valore)** intermedie
- Scrive risultati su **disco locale** del nodo

**Esempio pratico (contare parole):**
```
Mapper riceve:
"apple banana apple cherry"

Emette:
(apple, 1)
(banana, 1)
(apple, 1)
(cherry, 1)
```

---

### **FASE 2: SHUFFLE & SORT (Mescolamento e ordinamento)**

```
(apple, 1)     \
(banana, 1)     |─── Shuffle & Sort ───→ (apple, [1, 1])
(apple, 1)     /                         (banana, [1])
(cherry, 1)    /                          (cherry, [1])
```

**Cosa fa Shuffle & Sort:**
- Raggruppa tutti i valori per la **stessa chiave**
- **Ordina le chiavi**
- Trasferisce dati tra nodi (I/O di rete pesante)
- Scrive nuovamente su **disco locale**

---

### **FASE 3: REDUCE (Riduzione/Aggregazione)**

```
(apple, [1, 1])     → Reducer 1 → (apple, 2)
(banana, [1])       → Reducer 2 → (banana, 1)
(cherry, [1])       → Reducer 3 → (cherry, 1)

Output finale: apple=2, banana=1, cherry=1
```

**Cosa fa Reducer:**
- Riceve coppie **(chiave, [lista_valori])**
- Applica una **funzione aggregazione**
- Emette risultati finali
- Scrive su **HDFS**

**Esempio (somma dei valori):**
```
Reducer riceve:
(apple, [1, 1])

Applica SUM:
result = 1 + 1 = 2

Emette:
(apple, 2)
```

---

### **Diagramma completo:**

```
┌──────────────────────────────────────────────────────┐
│ INPUT FILE (1 GB, 8 blocchi HDFS)                   │
└──────────────────────────────────────────────────────┘
                        │
        ┌───────────────┼───────────────┐
        │               │               │
        ▼               ▼               ▼
    ┌────────┐      ┌────────┐      ┌────────┐
    │Mapper 1│      │Mapper 2│      │Mapper 3│
    │(Blocco1)      │(Blocco2)      │(Blocco3)
    └────────┘      └────────┘      └────────┘
        │               │               │
        ▼               ▼               ▼
   (k1,v1)          (k2,v2)          (k1,v3)
   (k3,v4)          (k1,v5)          (k4,v6)
        │               │               │
        └───────────────┼───────────────┘
                        │
            ┌─────────────────────────┐
            │  SHUFFLE & SORT         │
            │  (raggruppa per chiave) │
            └─────────────────────────┘
                        │
        ┌───────────────┼───────────────┐
        │               │               │
        ▼               ▼               ▼
    ┌────────┐      ┌────────┐      ┌────────┐
    │Reduce1 │      │Reduce2 │      │Reduce3 │
    │(k1,all)       │(k2,all)       │(k3,all)
    └────────┘      └────────┘      └────────┘
        │               │               │
        ▼               ▼               ▼
    (k1,sum)        (k2,sum)        (k3,sum)
        │               │               │
        └───────────────┼───────────────┘
                        │
                        ▼
            ┌─────────────────────────┐
            │  OUTPUT (HDFS)          │
            │  part-00000             │
            └─────────────────────────┘
```

---

### **Caratteristiche chiave di MapReduce:**

| Aspetto | Descrizione |
|---------|-------------|
| **Parallelismo** | N mapper = N blocchi HDFS (parallelizzazione massima) |
| **Fault tolerance** | Task fallito = riavvio automatico su altro nodo |
| **Data locality** | Mapper avviato sul nodo che contiene il blocco (minimizza rete) |
| **Spill to disk** | Shuffle scrive su disco (I/O pesante, latenza alta) |
| **Network I/O** | Shuffle trasferisce dati tra nodi (bottleneck) |
| **Latenza** | Secondi/minuti (overhead avvio container YARN) |
| **Throughput** | Massimo su volumi grandi (scalabilità orizzontale) |

---

### **Flusso completo in Hive:**

```
1. Utente scrive query HiveQL:
   SELECT categorie, COUNT(*) as cnt FROM vendite GROUP BY categoria;

2. Hive Metastore controlla schema di "vendite"

3. Hive Optimizer traduce in piano di esecuzione MapReduce:
   │
   ├─ MAP TASK: leggi HDFS, emetti (categoria, 1) per ogni riga
   ├─ SHUFFLE: raggruppa per categoria
   └─ REDUCE TASK: somma per categoria

4. YARN schedula mapper su nodi (data locality)

5. Mapper legge blocchi in parallelo
   Esempio output:
   (Electronics, 1)
   (Clothing, 1)
   (Electronics, 1)
   (Clothing, 1)

6. Shuffle trasferisce e ordina:
   (Clothing, [1, 1, 1])
   (Electronics, [1, 1])

7. Reducer aggrega:
   (Clothing, 3)
   (Electronics, 2)

8. Output scritto su HDFS

9. Hive restituisce risultato all'utente
```

---

### **Quando MapReduce è lento:**

❌ **Problemi di latenza:**
1. **Startup overhead**: YARN crea container Java (secondi)
2. **Spill to disk**: Shuffle scrive/legge da disco (I/O pesante)
3. **Network I/O**: Shuffle trasferisce dati tra nodi
4. **Multiple fasi**: Query con molti JOIN = molti MapReduce consecutivi

**Esempio (query con 2 JOIN):**
```
MapReduce 1: A JOIN B  → risultato temporaneo su HDFS
MapReduce 2: risultato TEMP JOIN C → risultato finale
Latenza totale: 2 * (startup + map + shuffle + reduce) = minuti
```

---

### **Soluzione moderna: Spark e Tez**

**Apache Spark**
- In-memory execution (skipping disk I/O del shuffle)
- DAG (Directed Acyclic Graph) optimizer
- Latenza 10-100x migliore di MapReduce puro
- Ancora batch, ma più veloce

**Apache Tez**
- Migliora MapReduce con DAG execution
- Reduce pipeline execution
- Ancora su disco, ma ottimizzato
- Intermedio tra MapReduce e Spark

**Hive moderno usa Spark o Tez per default**, non MapReduce puro.

---

## APACHE HIVE

**Cos'è**: Data Warehouse + SQL-on-Hadoop

**Cosa fa**
- Definisce e governa tabelle, schemi, partizioni
- Gestisce metadati via Hive Metastore
- Traduce query HiveQL in MapReduce, Tez o Spark
- Interroga HDFS, S3, ADLS

**Quando usarlo**
- ETL complessi con molte fasi: join, aggregazioni, dedupliche, spill su disco
- Analisi su grandi volumi di dati (terabyte+)
- Batch notturni programmati
- Quando serve scalabilità orizzontale e fault tolerance
- NON per interrogazioni real-time (latenza troppo alta)

---

## APACHE IMPALA

**Cos'è**: Motore SQL MPP in-memory (Quindi non ha la parte wharehouse)

**Cosa fa**
- Interroga gli stessi dati di Hive (su HDFS/S3)
- Usa gli stessi metadati (Hive Metastore)
- Fornisce SQL interattivo con bassa latenza

**Quando usarlo**
- BI, dashboard, report
- Analisi esplorativa e ad-hoc
- Query puntuali e veloci
- NON per ETL pesanti (limiti di memoria, nessuna fault tolerance)
- NON per batch notturni lunghi (architettura in-memoria, richiede query snelle)

---

## APACHE SQOOP

**Cos'è**: Strumento di data transfer (non motore SQL)

**Cosa fa**
- Importa dati da database relazionali (Oracle, MySQL, PostgreSQL, SQL Server, ecc.) verso Hadoop (HDFS/Hive)
- Esporta dati da Hadoop verso database relazionali
- Basato su MapReduce

**Quando usarlo**
- Ingestione iniziale da DB a Hadoop
- Estrazione da Hadoop verso DB
- NON per query o analisi

---

## TRANSAZIONI E ACID

**Database Relazionali Classici** (Oracle, MySQL, PostgreSQL)
- Architettura integrata: storage + motore SQL + gestore transazioni in un sistema unico
- UPDATE/DELETE puntuali: localizzazione veloce di singole righe via indici
- **ACID garantito**:
  - **A**tomicity: update intera o non accade
  - **C**onsistency: database rimane in stato valido
  - **I**solation: operazioni concorrenti non interferiscono
  - **D**urability: dati committed sono persistenti anche se crash
- Scalabilità: verticale (server potente)
- Caso d'uso: transazioni online (OLTP), e-commerce, CRM

**Hadoop/Hive/Impala**
- Architettura separata: storage (HDFS/S3) + motori SQL
- UPDATE/DELETE implicano riscrivere file interi (molto lento per volumi grandi)
- **ACID non nativo**: due scritture concorrenti = risultato imprevedibile; crash durante scrittura = dati parziali rimangono
- Scalabilità: orizzontale (molti nodi a basso costo)
- Caso d'uso: big data analytics (OLAP), ETL batch, machine learning
- Soluzione moderna: **Delta Lake**, **Iceberg**, **Hudi** aggiungono log transazionali e snapshot per ACID su Hadoop

**Quando scegliere**
- **Relazionali**: transazioni critiche, UPDATE/DELETE frequenti, latenza bassa, volume moderato (GB/TB)
  - Esempi: banca (prelievi atomici), e-commerce (ordini), CRM (contatti aggiornati)
- **Hadoop**: big data, elaborazioni batch, dati immutabili (insert-once), latenza accettabile, volume enorme (TB/PB)
  - Esempi: analytics, ML su terabyte di dati, log analysis, reporting notturni


# Perché non si usa ACID non nativo nelle transazioni bancarie?
Le transazioni bancarie richiedono la massima affidabilità: ogni operazione (es. bonifico, prelievo) deve essere completata interamente o non avvenire affatto, senza possibilità di errori o dati parziali.
Un sistema “ACID non nativo” (come Hadoop/Impala/Hive senza Delta/Iceberg/Hudi) non garantisce atomicità, isolamento e durabilità in modo rigoroso: in caso di crash, scritture concorrenti o errori, i dati potrebbero risultare incompleti o corrotti.
Per questo, in ambito bancario si usano solo database relazionali classici (Oracle, PostgreSQL, MySQL, ecc.) che implementano ACID in modo nativo e robusto.
Impala ha delle somiglianze con i database relazionali classici?
Sì, Impala offre un’interfaccia SQL molto simile (SELECT, JOIN, GROUP BY, ecc.) e permette di interrogare dati strutturati come un database relazionale.
Tuttavia, a differenza dei DB classici:
Non gestisce transazioni ACID su singole righe (no UPDATE/DELETE atomici)
Non ha indici o constraint come PK/FK
I dati sono su file distribuiti (HDFS/S3), non su storage integrato
Ottimizzato per analisi su grandi volumi, non per OLTP
In sintesi: Impala “sembra” un database relazionale per chi scrive SQL, ma sotto è progettato per analisi big data, non per transazioni critiche. Vuoi aggiungere queste spiegazioni al documento?

---

## DISEGNO LOGICO A STRATI

```
┌─────────────────────────┐
│   UTENTI / BI           │
│ (report, dashboard, SQL)│
└────────────┬────────────┘
             │
             ▼
┌─────────────────────────┐
│    MOTORI SQL           │
│ (Impala, Hive, Spark)   │
└────────────┬────────────┘
             │
             ▼
┌─────────────────────────┐
│     METADATI            │
│   (Hive Metastore)      │
└────────────┬────────────┘
             │
             ▼
┌─────────────────────────┐
│      STORAGE            │
│  (HDFS / S3 / ADLS)     │
│  ▶ QUI STANNO LE RIGHE  │
└─────────────────────────┘
```

---

## CASO REALE: AMAZON (ARCHITETTURA IBRIDA)

Amazon usa entrambi i sistemi:

**MySQL/Aurora** (DB relazionale - OLTP)
- Carrello acquisti: UPDATE immediato (ACID)
- Ordini: INSERT + UPDATE stock (transazione atomica)
- Pagamenti: atomicità critica (tutto o nulla)
- Inventario real-time: decremento immediato
- Latenza: millisecondi

**Hadoop/EMR/S3** (Data lake/warehouse - OLAP)
- Raccomandazioni: miliardi di transazioni storiche analizzate
- Analytics e BI: report su vendite, trend, previsioni
- Click-stream analysis: miliardi di click e navigazioni
- Machine learning: terabyte di dati per addestrare modelli
- Data science: A/B test, segmentazione, pricing
- Latenza: secondi/minuti/ore

**Flusso**:
1. Cliente ordina → **MySQL** registra (real-time, ACID)
2. Di notte → **Sqoop** esporta ordini a **S3** (Ossia datastore distribuito)
3. **EMR**(servizio che gestisce cluster hadoop) elabora milioni di ordini
4. Risultati in **Redshift** (DW) o **S3** (data lake)
5. Analytics, ML e BI leggono da Redshift/S3

**Sintesi**: MySQL = sistema operativo (transazioni live); Hadoop = sistema analitico (big data, ML, BI su dati storici).

---

## RIEPILOGO FINALE

| Componente    | Ruolo                                | Possiede/Governa Dati | Latenza           |
|---------------|--------------------------------------|----------------------|------------------- |
| **Storage**   | Memorizza file fisici                | Possiede              | N/A               |
| **Metastore** | Catalogo e governance (tecnica?)     | Governa metadati      | N/A               |
| **Hive**      | DW + query batch                     | Governa (non possiede) | Secondi/minuti   |
| **Impala**    | Query interattivo MPP in-memory      | Governa (non possiede) | Secondi/milli    |
| **Sqoop**     | Data transfer DB ↔ Hadoop            | Trasporta (non governa) | Batch           |

**Governance vs Possesso**:
- Lo **storage possiede** fisicamente i dati (file su HDFS/S3/ADLS)
- Il **data warehouse governa** i dati (metadati, schemi, tabelle, sicurezza, processi)
- I **motori SQL leggono/scrivono** i dati secondo il governo del warehouse

**Nota importante:**
- **Data Warehouse** (Hive, Snowflake) = esegue query SQL e governa tecnicamente
- **Data Catalog** (Alation, Collibra) = documenta significato business (NON esegue query)

# Cloudera runtime

Cloudera Runtime è l'insieme completo degli strumenti open source per storage distribuito, elaborazione batch/streaming, SQL, NoSQL, ML, ingestion e orchestrazione dati.


Cloudera Runtime comprende:

Storage:

HDFS (Hadoop Distributed File System)
Apache Ozone (object store)
Elaborazione Dati:

Apache Hadoop MapReduce (batch processing)
Apache Spark (batch + streaming + ML)
Apache Hive (SQL data warehouse)
Apache Impala (interactive SQL)
Apache Pig (data flow scripting)
Streaming e Real-time:

Apache Kafka (messaging/streaming)
Apache Flink (stream processing)
Spark Streaming
Apache NiFi (data flow automation)
Database NoSQL:

Apache HBase (wide-column store)
Apache Kudu (columnar storage engine)
Resource Management:

Apache YARN (cluster resource manager)
Data Ingestion:

Apache Sqoop (DB ↔ Hadoop transfer)
Apache Flume (log aggregation)
Search e Indexing:

Apache Solr (full-text search)
Coordinamento:

Apache ZooKeeper (distributed coordination)
Workflow:

Apache Oozie (job scheduling/orchestration)
Metadata:

Hive Metastore (catalog centrale)
Machine Learning:

Spark MLlib
In sintesi: Cloudera Runtime è l'insieme completo degli strumenti open source per storage distribuito, elaborazione batch/streaming, SQL, NoSQL, ML, ingestion e orchestrazione dati.


Cloudera Runtime può essere concettualmente paragonato a vSphere nel mondo VMware, in quanto rappresenta il livello di runtime che abilita l’esecuzione dei carichi di lavoro. Tuttavia, mentre vSphere opera a livello infrastrutturale come piattaforma di virtualizzazione, Cloudera Runtime opera a livello applicativo come runtime per workload Big Data e analytics, collocandosi sopra lo strato di virtualizzazione o cloud.

# VMware stack
Hardware
↓
vSphere
↓
VM / OS
↓
Applicazioni

# Cloudera stack
Hardware / Cloud
↓
OS / Container / VM
↓
Cloudera Runtime
↓
Spark / Hive / Hadoop / ML
↓
Data workload

| **Dimensione**               | **Cloudera Runtime (CDP)**                             | **vSphere (VMware)**                          |
| ---------------------------- | ------------------------------------------------------ | ----------------------------------------------|
| **Dominio**                  | Data Platform / Big Data / Analytics                   | Virtualizzazione infrastrutturale             |
| **Livello dello stack**      | Applicativo–dati                                       | Infrastrutturale                              |
| **Funzione principale**      | Eseguire workload dati distribuiti                     | Eseguire macchine virtuali                    |
| **Tipo di workload**         | Spark, Hive, Hadoop, Impala, ML                        | VM generiche (applicazioni, database, servizi)|
| **Astrazione fornita**       | Cluster dati e motori di elaborazione                  | CPU, memoria, storage, rete                   |
| **Gestione risorse**         | Scheduling e resource management (es. YARN)            | Scheduling e resource management (DRS)        |
| **Unità di esecuzione**      | Job, query, applicazioni distribuite                   | Macchine virtuali                             | 
| **Dipendenza dall’OS**       | Richiede un OS sottostante (bare metal, VM, container) | Include un hypervisor che sostituisce l’OS host|
| **Rapporto con l’hardware**  | Indiretto                                              | Diretto                                       |
| **Collocazione tipica**      | Sopra VM / container / cloud                           | Direttamente sopra l’hardware                 |
| **Ruolo nella piattaforma**  | Runtime dei dati                                       | Runtime dell’infrastruttura                   |
| **Ambiente di riferimento**  | CDP (Public Cloud / Data Center)                       | Data center virtualizzato                     |
| **Esempi di componenti**     | Hadoop, Spark, Hive, Impala                            | ESXi, vMotion, HA, DRS                        |
| **Obiettivo architetturale** | Standardizzare l’elaborazione dei dati                 | Standardizzare l’uso dell’hardware            |
| **Governance e sicurezza**   | Integrata tramite SDX (Ranger, Atlas)                  | Demandata a strumenti esterni o superiori     |
| **Relazione reciproca**      | Può girare sopra vSphere                               | Può ospitare Cloudera Runtime                 |

## CDP Public Cloud vs CDP Private Cloud

| **Dimensione**                | **CDP Public Cloud**                                    | **CDP Private Cloud**                                  |
| ----------------------------- | ------------------------------------------------------- | ------------------------------------------------------ |
| **Infrastruttura**            | AWS, Azure, Google Cloud (gestita dal provider)         | On-premise o cloud privato (gestita dall'azienda)      |
| **Deployment**                | SaaS-like, provisioning automatico                      | Installazione manuale su cluster dedicati             |
| **Gestione cluster**          | Automatica (Cloudera gestisce upgrade e patching)       | Manuale (IT interno gestisce tutto)                    |
| **Scalabilità**               | Elastica, scale up/down on-demand                       | Limitata dalla capacità fisica del data center         |
| **Costi**                     | Pay-as-you-go (consumo effettivo)                       | CapEx: hardware + licenze + manutenzione               |
| **Time-to-value**             | Rapido (minuti/ore)                                     | Lento (settimane/mesi per setup)                       |
| **Manutenzione**              | Cloudera gestisce infrastruttura e runtime              | IT interno gestisce hardware, OS, runtime              |
| **Sicurezza dati**            | Multi-tenant, dati su cloud pubblico (cifratura)        | Single-tenant, dati rimangono on-premise               |
| **Compliance**                | Conforme a standard cloud (SOC2, ISO, GDPR)             | Controllo totale per requisiti specifici (HIPAA, PCI)  |
| **Networking**                | VPC, connessioni cloud-native                           | Rete aziendale interna                                 |
| **Disaster Recovery**         | Nativo cloud (multi-region, backup automatici)          | Richiede setup dedicato (backup, replica)              |
| **Flessibilità hardware**     | Provider cloud decide (preset configurazioni)           | Controllo totale su hardware e configurazione          |
| **Workload ideali**           | Analytics, ML, BI con carichi variabili                 | Workload critici, dati sensibili, compliance rigoroso  |
| **Esempi casi d'uso**         | Startup, progetti sperimentali, burst capacity          | Banche, sanità, governativi, legacy integration        |
| **Dipendenza vendor**         | Forte (Cloudera + cloud provider)                       | Moderata (Cloudera software, hardware proprio)         |
| **Aggiornamenti**             | Automatici, gestiti da Cloudera                         | Pianificati e applicati dall'IT interno                |
| **Costo prevedibilità**       | Variabile (dipende dall'uso)                            | Fisso (hardware ammortizzato)                          |
| **Skills richiesti**          | Cloud-native, meno sysadmin                             | Sysadmin, networking, storage management               |

**Scelta strategica:**
- **Public Cloud**: velocità, elasticità, riduzione complessità operativa
- **Private Cloud**: controllo, sicurezza, compliance, integrazione legacy


CDP Public Cloud pone l’accento sull’utilizzo dell’object store del provider cloud, invece di HDFS come avveniva in CDH e HDP. Questo determina una separazione tra calcolo e storage, consentendo a ciascun workload di disporre della propria capacità di elaborazione pur continuando ad accedere agli stessi dati sottostanti.

Poiché le implementazioni di CDH e HDP collocano insieme storage e calcolo, esse non sono adatte a workload transitori. In CDP Public Cloud (così come in CDP Private Cloud), gli amministratori possono registrare tutti gli ambienti di cui hanno bisogno.