

## APACHE HIVE

**Cos'è**: Data Warehouse + SQL-on-Hadoop

**Cosa fa**
- Definisce e governa tabelle, schemi, partizioni
- Gestisce metadati via Hive Metastore
- Traduce query HiveQL in MapReduce, Tez o Spark
- Interroga HDFS, S3, ADLS

**Quando usarlo**
- ETL complessi con molte fasi: join, aggregazioni, dedupliche, spill su disco
- Analisi su grandi volumi di dati (terabyte+)
- Batch notturni programmati
- Quando serve scalabilità orizzontale e fault tolerance
- NON per interrogazioni real-time (latenza troppo alta)

---

## APACHE IMPALA

**Cos'è**: Motore SQL MPP in-memory (Quindi non ha la parte wharehouse)

**Cosa fa**
- Interroga gli stessi dati di Hive (su HDFS/S3)
- Usa gli stessi metadati (Hive Metastore)
- Fornisce SQL interattivo con bassa latenza

**Quando usarlo**
- BI, dashboard, report
- Analisi esplorativa e ad-hoc
- Query puntuali e veloci
- NON per ETL pesanti (limiti di memoria, nessuna fault tolerance)
- NON per batch notturni lunghi (architettura in-memoria, richiede query snelle)

---

## APACHE SQOOP

**Cos'è**: Strumento di data transfer (non motore SQL)

**Cosa fa**
- Importa dati da database relazionali (Oracle, MySQL, PostgreSQL, SQL Server, ecc.) verso Hadoop (HDFS/Hive)
- Esporta dati da Hadoop verso database relazionali
- Basato su MapReduce

**Quando usarlo**
- Ingestione iniziale da DB a Hadoop
- Estrazione da Hadoop verso DB
- NON per query o analisi

---

## TRANSAZIONI E ACID

**Database Relazionali Classici** (Oracle, MySQL, PostgreSQL)
- Architettura integrata: storage + motore SQL + gestore transazioni in un sistema unico
- UPDATE/DELETE puntuali: localizzazione veloce di singole righe via indici
- **ACID garantito**:
  - **A**tomicity: update intera o non accade
  - **C**onsistency: database rimane in stato valido
  - **I**solation: operazioni concorrenti non interferiscono
  - **D**urability: dati committed sono persistenti anche se crash
- Scalabilità: verticale (server potente)
- Caso d'uso: transazioni online (OLTP), e-commerce, CRM

**Hadoop/Hive/Impala**
- Architettura separata: storage (HDFS/S3) + motori SQL
- UPDATE/DELETE implicano riscrivere file interi (molto lento per volumi grandi)
- **ACID non nativo**: due scritture concorrenti = risultato imprevedibile; crash durante scrittura = dati parziali rimangono
- Scalabilità: orizzontale (molti nodi a basso costo)
- Caso d'uso: big data analytics (OLAP), ETL batch, machine learning
- Soluzione moderna: **Delta Lake**, **Iceberg**, **Hudi** aggiungono log transazionali e snapshot per ACID su Hadoop

**Quando scegliere**
- **Relazionali**: transazioni critiche, UPDATE/DELETE frequenti, latenza bassa, volume moderato (GB/TB)
  - Esempi: banca (prelievi atomici), e-commerce (ordini), CRM (contatti aggiornati)
- **Hadoop**: big data, elaborazioni batch, dati immutabili (insert-once), latenza accettabile, volume enorme (TB/PB)
  - Esempi: analytics, ML su terabyte di dati, log analysis, reporting notturni


# Perché non si usa ACID non nativo nelle transazioni bancarie?
Le transazioni bancarie richiedono la massima affidabilità: ogni operazione (es. bonifico, prelievo) deve essere completata interamente o non avvenire affatto, senza possibilità di errori o dati parziali.
Un sistema “ACID non nativo” (come Hadoop/Impala/Hive senza Delta/Iceberg/Hudi) non garantisce atomicità, isolamento e durabilità in modo rigoroso: in caso di crash, scritture concorrenti o errori, i dati potrebbero risultare incompleti o corrotti.
Per questo, in ambito bancario si usano solo database relazionali classici (Oracle, PostgreSQL, MySQL, ecc.) che implementano ACID in modo nativo e robusto.
Impala ha delle somiglianze con i database relazionali classici?
Sì, Impala offre un’interfaccia SQL molto simile (SELECT, JOIN, GROUP BY, ecc.) e permette di interrogare dati strutturati come un database relazionale.
Tuttavia, a differenza dei DB classici:
Non gestisce transazioni ACID su singole righe (no UPDATE/DELETE atomici)
Non ha indici o constraint come PK/FK
I dati sono su file distribuiti (HDFS/S3), non su storage integrato
Ottimizzato per analisi su grandi volumi, non per OLTP
In sintesi: Impala “sembra” un database relazionale per chi scrive SQL, ma sotto è progettato per analisi big data, non per transazioni critiche. Vuoi aggiungere queste spiegazioni al documento?

---

## DISEGNO LOGICO A STRATI

```
┌─────────────────────────┐
│   UTENTI / BI           │
│ (report, dashboard, SQL)│
└────────────┬────────────┘
             │
             ▼
┌─────────────────────────┐
│    MOTORI SQL           │
│ (Impala, Hive, Spark)   │
└────────────┬────────────┘
             │
             ▼
┌─────────────────────────┐
│     METADATI            │
│   (Hive Metastore)      │
└────────────┬────────────┘
             │
             ▼
┌─────────────────────────┐
│      STORAGE            │
│  (HDFS / S3 / ADLS)     │
│  ▶ QUI STANNO LE RIGHE  │
└─────────────────────────┘
```

---

## CASO REALE: AMAZON (ARCHITETTURA IBRIDA)

Amazon usa entrambi i sistemi:

**MySQL/Aurora** (DB relazionale - OLTP)
- Carrello acquisti: UPDATE immediato (ACID)
- Ordini: INSERT + UPDATE stock (transazione atomica)
- Pagamenti: atomicità critica (tutto o nulla)
- Inventario real-time: decremento immediato
- Latenza: millisecondi

**Hadoop/EMR/S3** (Data lake/warehouse - OLAP)
- Raccomandazioni: miliardi di transazioni storiche analizzate
- Analytics e BI: report su vendite, trend, previsioni
- Click-stream analysis: miliardi di click e navigazioni
- Machine learning: terabyte di dati per addestrare modelli
- Data science: A/B test, segmentazione, pricing
- Latenza: secondi/minuti/ore

**Flusso**:
1. Cliente ordina → **MySQL** registra (real-time, ACID)
2. Di notte → **Sqoop** esporta ordini a **S3** (Ossia datastore distribuito)
3. **EMR**(servizio che gestisce cluster hadoop) elabora milioni di ordini
4. Risultati in **Redshift** (DW) o **S3** (data lake)
5. Analytics, ML e BI leggono da Redshift/S3

**Sintesi**: MySQL = sistema operativo (transazioni live); Hadoop = sistema analitico (big data, ML, BI su dati storici).

---

## RIEPILOGO FINALE

| Componente    | Ruolo                                | Possiede/Governa Dati | Latenza           |
|---------------|--------------------------------------|----------------------|------------------- |
| **Storage**   | Memorizza file fisici                | Possiede              | N/A               |
| **Metastore** | Catalogo e governance (tecnica?)     | Governa metadati      | N/A               |
| **Hive**      | DW + query batch                     | Governa (non possiede) | Secondi/minuti   |
| **Impala**    | Query interattivo MPP in-memory      | Governa (non possiede) | Secondi/milli    |
| **Sqoop**     | Data transfer DB ↔ Hadoop            | Trasporta (non governa) | Batch           |

**Governance vs Possesso**:
- Lo **storage possiede** fisicamente i dati (file su HDFS/S3/ADLS)
- Il **data warehouse governa** i dati (metadati, schemi, tabelle, sicurezza, processi)
- I **motori SQL leggono/scrivono** i dati secondo il governo del warehouse

**Nota importante:**
- **Data Warehouse** (Hive, Snowflake) = esegue query SQL e governa tecnicamente
- **Data Catalog** (Alation, Collibra) = documenta significato business (NON esegue query)

# Cloudera runtime

Cloudera Runtime è l'insieme completo degli strumenti open source per storage distribuito, elaborazione batch/streaming, SQL, NoSQL, ML, ingestion e orchestrazione dati.


Cloudera Runtime comprende:

Storage:

HDFS (Hadoop Distributed File System)
Apache Ozone (object store)
Elaborazione Dati:

Apache Hadoop MapReduce (batch processing)
Apache Spark (batch + streaming + ML)
Apache Hive (SQL data warehouse)
Apache Impala (interactive SQL)
Apache Pig (data flow scripting)
Streaming e Real-time:

Apache Kafka (messaging/streaming)
Apache Flink (stream processing)
Spark Streaming
Apache NiFi (data flow automation)
Database NoSQL:

Apache HBase (wide-column store)
Apache Kudu (columnar storage engine)
Resource Management:

Apache YARN (cluster resource manager)
Data Ingestion:

Apache Sqoop (DB ↔ Hadoop transfer)
Apache Flume (log aggregation)
Search e Indexing:

Apache Solr (full-text search)
Coordinamento:

Apache ZooKeeper (distributed coordination)
Workflow:

Apache Oozie (job scheduling/orchestration)
Metadata:

Hive Metastore (catalog centrale)
Machine Learning:

Spark MLlib
In sintesi: Cloudera Runtime è l'insieme completo degli strumenti open source per storage distribuito, elaborazione batch/streaming, SQL, NoSQL, ML, ingestion e orchestrazione dati.


Cloudera Runtime può essere concettualmente paragonato a vSphere nel mondo VMware, in quanto rappresenta il livello di runtime che abilita l’esecuzione dei carichi di lavoro. Tuttavia, mentre vSphere opera a livello infrastrutturale come piattaforma di virtualizzazione, Cloudera Runtime opera a livello applicativo come runtime per workload Big Data e analytics, collocandosi sopra lo strato di virtualizzazione o cloud.

# VMware stack
Hardware
↓
vSphere
↓
VM / OS
↓
Applicazioni

# Cloudera stack
Hardware / Cloud
↓
OS / Container / VM
↓
Cloudera Runtime
↓
Spark / Hive / Hadoop / ML
↓
Data workload

| **Dimensione**               | **Cloudera Runtime (CDP)**                             | **vSphere (VMware)**                          |
| ---------------------------- | ------------------------------------------------------ | ----------------------------------------------|
| **Dominio**                  | Data Platform / Big Data / Analytics                   | Virtualizzazione infrastrutturale             |
| **Livello dello stack**      | Applicativo–dati                                       | Infrastrutturale                              |
| **Funzione principale**      | Eseguire workload dati distribuiti                     | Eseguire macchine virtuali                    |
| **Tipo di workload**         | Spark, Hive, Hadoop, Impala, ML                        | VM generiche (applicazioni, database, servizi)|
| **Astrazione fornita**       | Cluster dati e motori di elaborazione                  | CPU, memoria, storage, rete                   |
| **Gestione risorse**         | Scheduling e resource management (es. YARN)            | Scheduling e resource management (DRS)        |
| **Unità di esecuzione**      | Job, query, applicazioni distribuite                   | Macchine virtuali                             | 
| **Dipendenza dall’OS**       | Richiede un OS sottostante (bare metal, VM, container) | Include un hypervisor che sostituisce l’OS host|
| **Rapporto con l’hardware**  | Indiretto                                              | Diretto                                       |
| **Collocazione tipica**      | Sopra VM / container / cloud                           | Direttamente sopra l’hardware                 |
| **Ruolo nella piattaforma**  | Runtime dei dati                                       | Runtime dell’infrastruttura                   |
| **Ambiente di riferimento**  | CDP (Public Cloud / Data Center)                       | Data center virtualizzato                     |
| **Esempi di componenti**     | Hadoop, Spark, Hive, Impala                            | ESXi, vMotion, HA, DRS                        |
| **Obiettivo architetturale** | Standardizzare l’elaborazione dei dati                 | Standardizzare l’uso dell’hardware            |
| **Governance e sicurezza**   | Integrata tramite SDX (Ranger, Atlas)                  | Demandata a strumenti esterni o superiori     |
| **Relazione reciproca**      | Può girare sopra vSphere                               | Può ospitare Cloudera Runtime                 |

## CDP Public Cloud vs CDP Private Cloud

| **Dimensione**                | **CDP Public Cloud**                                    | **CDP Private Cloud**                                  |
| ----------------------------- | ------------------------------------------------------- | ------------------------------------------------------ |
| **Infrastruttura**            | AWS, Azure, Google Cloud (gestita dal provider)         | On-premise o cloud privato (gestita dall'azienda)      |
| **Deployment**                | SaaS-like, provisioning automatico                      | Installazione manuale su cluster dedicati             |
| **Gestione cluster**          | Automatica (Cloudera gestisce upgrade e patching)       | Manuale (IT interno gestisce tutto)                    |
| **Scalabilità**               | Elastica, scale up/down on-demand                       | Limitata dalla capacità fisica del data center         |
| **Costi**                     | Pay-as-you-go (consumo effettivo)                       | CapEx: hardware + licenze + manutenzione               |
| **Time-to-value**             | Rapido (minuti/ore)                                     | Lento (settimane/mesi per setup)                       |
| **Manutenzione**              | Cloudera gestisce infrastruttura e runtime              | IT interno gestisce hardware, OS, runtime              |
| **Sicurezza dati**            | Multi-tenant, dati su cloud pubblico (cifratura)        | Single-tenant, dati rimangono on-premise               |
| **Compliance**                | Conforme a standard cloud (SOC2, ISO, GDPR)             | Controllo totale per requisiti specifici (HIPAA, PCI)  |
| **Networking**                | VPC, connessioni cloud-native                           | Rete aziendale interna                                 |
| **Disaster Recovery**         | Nativo cloud (multi-region, backup automatici)          | Richiede setup dedicato (backup, replica)              |
| **Flessibilità hardware**     | Provider cloud decide (preset configurazioni)           | Controllo totale su hardware e configurazione          |
| **Workload ideali**           | Analytics, ML, BI con carichi variabili                 | Workload critici, dati sensibili, compliance rigoroso  |
| **Esempi casi d'uso**         | Startup, progetti sperimentali, burst capacity          | Banche, sanità, governativi, legacy integration        |
| **Dipendenza vendor**         | Forte (Cloudera + cloud provider)                       | Moderata (Cloudera software, hardware proprio)         |
| **Aggiornamenti**             | Automatici, gestiti da Cloudera                         | Pianificati e applicati dall'IT interno                |
| **Costo prevedibilità**       | Variabile (dipende dall'uso)                            | Fisso (hardware ammortizzato)                          |
| **Skills richiesti**          | Cloud-native, meno sysadmin                             | Sysadmin, networking, storage management               |

**Scelta strategica:**
- **Public Cloud**: velocità, elasticità, riduzione complessità operativa
- **Private Cloud**: controllo, sicurezza, compliance, integrazione legacy


CDP Public Cloud pone l’accento sull’utilizzo dell’object store del provider cloud, invece di HDFS come avveniva in CDH e HDP. Questo determina una separazione tra calcolo e storage, consentendo a ciascun workload di disporre della propria capacità di elaborazione pur continuando ad accedere agli stessi dati sottostanti.

Poiché le implementazioni di CDH e HDP collocano insieme storage e calcolo, esse non sono adatte a workload transitori. In CDP Public Cloud (così come in CDP Private Cloud), gli amministratori possono registrare tutti gli ambienti di cui hanno bisogno.